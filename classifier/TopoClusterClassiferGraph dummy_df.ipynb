{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "industrial-russian",
   "metadata": {},
   "source": [
    "# Graph Networts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demonstrated-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biological-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import uproot3 as ur\n",
    "# import atlas_mpl_style as ampl\n",
    "# ampl.use_atlas_style()\n",
    "\n",
    "path_prefix = '/global/home/users/mfong/git/LCStudies/'\n",
    "plotpath = path_prefix + 'classifier/Plots/'\n",
    "modelpath = path_prefix + 'classifier/Models/'\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-zimbabwe",
   "metadata": {},
   "source": [
    "# Xiangyang run from here to get dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alternative-state",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB1_0</th>\n",
       "      <th>EMB1_1</th>\n",
       "      <th>EMB1_2</th>\n",
       "      <th>EMB1_3</th>\n",
       "      <th>EMB1_4</th>\n",
       "      <th>EMB1_5</th>\n",
       "      <th>EMB1_6</th>\n",
       "      <th>EMB1_7</th>\n",
       "      <th>EMB1_8</th>\n",
       "      <th>EMB1_9</th>\n",
       "      <th>EMB1_10</th>\n",
       "      <th>EMB1_11</th>\n",
       "      <th>EMB1_12</th>\n",
       "      <th>EMB1_13</th>\n",
       "      <th>EMB1_14</th>\n",
       "      <th>EMB1_15</th>\n",
       "      <th>EMB1_16</th>\n",
       "      <th>EMB1_17</th>\n",
       "      <th>EMB1_18</th>\n",
       "      <th>EMB1_19</th>\n",
       "      <th>EMB1_20</th>\n",
       "      <th>EMB1_21</th>\n",
       "      <th>EMB1_22</th>\n",
       "      <th>EMB1_23</th>\n",
       "      <th>EMB1_24</th>\n",
       "      <th>EMB1_25</th>\n",
       "      <th>EMB1_26</th>\n",
       "      <th>EMB1_27</th>\n",
       "      <th>EMB1_28</th>\n",
       "      <th>EMB1_29</th>\n",
       "      <th>EMB1_30</th>\n",
       "      <th>EMB1_31</th>\n",
       "      <th>EMB1_32</th>\n",
       "      <th>EMB1_33</th>\n",
       "      <th>EMB1_34</th>\n",
       "      <th>EMB1_35</th>\n",
       "      <th>EMB1_36</th>\n",
       "      <th>EMB1_37</th>\n",
       "      <th>EMB1_38</th>\n",
       "      <th>EMB1_39</th>\n",
       "      <th>EMB1_40</th>\n",
       "      <th>EMB1_41</th>\n",
       "      <th>EMB1_42</th>\n",
       "      <th>EMB1_43</th>\n",
       "      <th>EMB1_44</th>\n",
       "      <th>EMB1_45</th>\n",
       "      <th>EMB1_46</th>\n",
       "      <th>EMB1_47</th>\n",
       "      <th>EMB1_48</th>\n",
       "      <th>EMB1_49</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB3_119</th>\n",
       "      <th>EMB3_120</th>\n",
       "      <th>EMB3_121</th>\n",
       "      <th>EMB3_122</th>\n",
       "      <th>EMB3_123</th>\n",
       "      <th>EMB3_124</th>\n",
       "      <th>EMB3_125</th>\n",
       "      <th>EMB3_126</th>\n",
       "      <th>EMB3_127</th>\n",
       "      <th>TileBar0_0</th>\n",
       "      <th>TileBar0_1</th>\n",
       "      <th>TileBar0_2</th>\n",
       "      <th>TileBar0_3</th>\n",
       "      <th>TileBar0_4</th>\n",
       "      <th>TileBar0_5</th>\n",
       "      <th>TileBar0_6</th>\n",
       "      <th>TileBar0_7</th>\n",
       "      <th>TileBar0_8</th>\n",
       "      <th>TileBar0_9</th>\n",
       "      <th>TileBar0_10</th>\n",
       "      <th>TileBar0_11</th>\n",
       "      <th>TileBar0_12</th>\n",
       "      <th>TileBar0_13</th>\n",
       "      <th>TileBar0_14</th>\n",
       "      <th>TileBar0_15</th>\n",
       "      <th>TileBar1_0</th>\n",
       "      <th>TileBar1_1</th>\n",
       "      <th>TileBar1_2</th>\n",
       "      <th>TileBar1_3</th>\n",
       "      <th>TileBar1_4</th>\n",
       "      <th>TileBar1_5</th>\n",
       "      <th>TileBar1_6</th>\n",
       "      <th>TileBar1_7</th>\n",
       "      <th>TileBar1_8</th>\n",
       "      <th>TileBar1_9</th>\n",
       "      <th>TileBar1_10</th>\n",
       "      <th>TileBar1_11</th>\n",
       "      <th>TileBar1_12</th>\n",
       "      <th>TileBar1_13</th>\n",
       "      <th>TileBar1_14</th>\n",
       "      <th>TileBar1_15</th>\n",
       "      <th>TileBar2_0</th>\n",
       "      <th>TileBar2_1</th>\n",
       "      <th>TileBar2_2</th>\n",
       "      <th>TileBar2_3</th>\n",
       "      <th>TileBar2_4</th>\n",
       "      <th>TileBar2_5</th>\n",
       "      <th>TileBar2_6</th>\n",
       "      <th>TileBar2_7</th>\n",
       "      <th>is_p0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973252</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072234</td>\n",
       "      <td>0.764238</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.067689</td>\n",
       "      <td>0.026477</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.178025</td>\n",
       "      <td>0.219936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.046428</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.694705</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.073826</td>\n",
       "      <td>0.287841</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 937 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMB1_0  EMB1_1  EMB1_2  EMB1_3  EMB1_4  EMB1_5  EMB1_6  EMB1_7  EMB1_8  \\\n",
       "0        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      EMB1_9  EMB1_10  EMB1_11  EMB1_12  EMB1_13  EMB1_14  EMB1_15  EMB1_16  \\\n",
       "0        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1995     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1996     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1997     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1998     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1999     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      EMB1_17  EMB1_18  EMB1_19  EMB1_20  EMB1_21  EMB1_22  EMB1_23  EMB1_24  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1995      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1996      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1997      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1998      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1999      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      EMB1_25  EMB1_26  EMB1_27  EMB1_28  EMB1_29  EMB1_30  EMB1_31  EMB1_32  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1995      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1996      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1997      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1998      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1999      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      EMB1_33  EMB1_34  EMB1_35  EMB1_36  EMB1_37  EMB1_38  EMB1_39  EMB1_40  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1995      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1996      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1997      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1998      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1999      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      EMB1_41  EMB1_42  EMB1_43  EMB1_44  EMB1_45  EMB1_46  EMB1_47  EMB1_48  \\\n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1995      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1996      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1997      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1998      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1999      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "      EMB1_49  ...  EMB3_119  EMB3_120  EMB3_121  EMB3_122  EMB3_123  \\\n",
       "0         0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "1         0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "2         0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "3         0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "4         0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "1995      0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "1996      0.0  ...       0.0       0.0  0.000032       0.0       0.0   \n",
       "1997      0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "1998      0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "1999      0.0  ...       0.0       0.0  0.000000       0.0       0.0   \n",
       "\n",
       "      EMB3_124  EMB3_125  EMB3_126  EMB3_127  TileBar0_0  TileBar0_1  \\\n",
       "0          0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "1          0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "2          0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "3          0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "4          0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "...        ...       ...       ...       ...         ...         ...   \n",
       "1995       0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "1996       0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "1997       0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "1998       0.0       0.0       0.0       0.0         0.0    0.000000   \n",
       "1999       0.0       0.0       0.0       0.0         0.0    0.003289   \n",
       "\n",
       "      TileBar0_2  TileBar0_3  TileBar0_4  TileBar0_5  TileBar0_6  TileBar0_7  \\\n",
       "0       0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "1       0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "2       0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "3       0.000000    0.000000     0.00000    0.000000    0.026335    0.000000   \n",
       "4       0.000000    0.024622     0.00000    0.178025    0.219936    0.000000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1995    0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "1996    0.000000    0.000000     0.00191    0.000000    0.000000    0.000000   \n",
       "1997    0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "1998    0.000000    0.000000     0.00000    0.000000    0.000000    0.000000   \n",
       "1999    0.016005    0.000000     0.00000    0.073826    0.287841    0.030483   \n",
       "\n",
       "      TileBar0_8  TileBar0_9  TileBar0_10  TileBar0_11  TileBar0_12  \\\n",
       "0       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "1       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "2       0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "3       0.000000    0.072234     0.764238     0.016248     0.000000   \n",
       "4       0.000000    0.118353     0.431438     0.000000     0.000000   \n",
       "...          ...         ...          ...          ...          ...   \n",
       "1995    0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "1996    0.006119    0.036603     0.000000     0.007777     0.002578   \n",
       "1997    0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "1998    0.000000    0.000000     0.000000     0.000000     0.000000   \n",
       "1999    0.000000    0.025305     0.003675     0.007830     0.000000   \n",
       "\n",
       "      TileBar0_13  TileBar0_14  TileBar0_15  TileBar1_0  TileBar1_1  \\\n",
       "0        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "2        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "3        0.002098     0.067689     0.026477    0.001169    0.000000   \n",
       "4        0.009038     0.000000     0.000000    0.000000    0.000000   \n",
       "...           ...          ...          ...         ...         ...   \n",
       "1995     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1996     0.008802     0.019965     0.000219    0.003530    0.000235   \n",
       "1997     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1998     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1999     0.000000     0.024505     0.000000    0.000000    0.000419   \n",
       "\n",
       "      TileBar1_2  TileBar1_3  TileBar1_4  TileBar1_5  TileBar1_6  TileBar1_7  \\\n",
       "0       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1995    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1996    0.000594    0.000055    0.006055    0.015197    0.046428    0.004145   \n",
       "1997    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1998    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1999    0.021106    0.000000    0.000000    0.000000    0.005083    0.000000   \n",
       "\n",
       "      TileBar1_8  TileBar1_9  TileBar1_10  TileBar1_11  TileBar1_12  \\\n",
       "0        0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "1        0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "2        0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "3        0.00000    0.000000     0.002202     0.000000     0.000000   \n",
       "4        0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "...          ...         ...          ...          ...          ...   \n",
       "1995     0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "1996     0.00122    0.037687     0.694705     0.016177     0.006726   \n",
       "1997     0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "1998     0.00000    0.000000     0.000000     0.000000     0.000000   \n",
       "1999     0.00000    0.018819     0.006645     0.000000     0.000000   \n",
       "\n",
       "      TileBar1_13  TileBar1_14  TileBar1_15  TileBar2_0  TileBar2_1  \\\n",
       "0        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "2        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "3        0.003275     0.015712     0.000000    0.000000    0.000000   \n",
       "4        0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "...           ...          ...          ...         ...         ...   \n",
       "1995     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1996     0.015592     0.019869     0.001952    0.000443    0.001011   \n",
       "1997     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1998     0.000000     0.000000     0.000000    0.000000    0.000000   \n",
       "1999     0.000000     0.042707     0.000000    0.000000    0.000000   \n",
       "\n",
       "      TileBar2_2  TileBar2_3  TileBar2_4  TileBar2_5  TileBar2_6  TileBar2_7  \\\n",
       "0       0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "1       0.000000    0.000000         0.0    0.000000    0.973252    0.026748   \n",
       "2       0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "3       0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "4       0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1995    0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "1996    0.013743    0.003905         0.0    0.000226    0.000064    0.000000   \n",
       "1997    0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "1998    0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "1999    0.000000    0.000000         0.0    0.000000    0.000000    0.000000   \n",
       "\n",
       "      is_p0  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "1995      1  \n",
       "1996      0  \n",
       "1997      0  \n",
       "1998      0  \n",
       "1999      0  \n",
       "\n",
       "[2000 rows x 937 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dummy data\n",
    "dummy_df = pd.read_csv(\"dummy_df.csv\")\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-evening",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutations for doubly connected edges\n",
    "from itertools import permutations\n",
    "import functools\n",
    "import networkx as nx\n",
    "import sonnet as snt\n",
    "\n",
    "from graph_nets import blocks\n",
    "\n",
    "from graph_nets import graphs\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "single-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB1_0        0.0\n",
       "EMB1_1        0.0\n",
       "EMB1_2        0.0\n",
       "EMB1_3        0.0\n",
       "EMB1_4        0.0\n",
       "             ... \n",
       "TileBar2_4    0.0\n",
       "TileBar2_5    0.0\n",
       "TileBar2_6    0.0\n",
       "TileBar2_7    0.0\n",
       "is_p0         0.0\n",
       "Name: 0, Length: 937, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# event0 = df.loc[0]\n",
    "event0 = dummy_df.loc[0]\n",
    "event0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "essential-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fully_connected_edges(nodes):\n",
    "    \"\"\"\n",
    "    returns a list of tuples with (sender_node, reciever_node) for a fully connected graph\n",
    "    ex: [(1,2), (2,1), (0,1)]\n",
    "    \"\"\"\n",
    "    n_nodes = len(nodes)\n",
    "    return list(permutations(range(n_nodes), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "introductory-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(event):\n",
    "     \n",
    "    MIN_VALUE = 0.0\n",
    "    \n",
    "    \n",
    "    col_names = list(event.index)\n",
    "    nodes = [[cell] for cell in event[col_names][event[col_names] > MIN_VALUE]]\n",
    "    if len(nodes) < 1:\n",
    "        return (None, None)\n",
    "    \n",
    "    # since the last column is the classifier index\n",
    "    # remove that in the nodes.\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    solution = nodes[-1]\n",
    "    nodes = nodes[:-1]\n",
    "    n_nodes = len(nodes)\n",
    "\n",
    "    \n",
    "    edge_endpoints = make_fully_connected_edges(nodes)\n",
    "    senders = np.array([x[0] for x in edge_endpoints])\n",
    "    receivers = np.array([x[1] for x in edge_endpoints])\n",
    "    n_edges = len(edge_endpoints)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    \n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": solution\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    \n",
    "    return (input_graph, target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alike-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"has shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "silent-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph, target_graph = make_graph(event0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-milan",
   "metadata": {},
   "source": [
    "## Graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "latin-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the newest dev version of graph_nets (see https://github.com/deepmind/graph_nets/issues/139)\n",
    "# as of 3/25/2021\n",
    "\n",
    "\n",
    "# !pip install git+git://github.com/deepmind/graph_nets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "israeli-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 2\n",
    "def make_mlp_model():\n",
    "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "  The parameters of each new MLP are not shared with others generated by\n",
    "  this function.\n",
    "\n",
    "  Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "  \"\"\"\n",
    "  # the activation function choices:\n",
    "  # swish, relu, relu6, leaky_relu\n",
    "  return snt.Sequential([\n",
    "      snt.nets.MLP([128, 64]*NUM_LAYERS,\n",
    "                    activation=tf.nn.relu,\n",
    "                    activate_final=True, \n",
    "                  #  dropout_rate=DROPOUT_RATE\n",
    "        ),\n",
    "      snt.LayerNorm(axis=-1, create_scale=True, create_offset=False)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "biological-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGraphNetwork(snt.Module):\n",
    "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
    "    def __init__(self, name=\"MLPGraphNetwork\"):\n",
    "        super(MLPGraphNetwork, self).__init__(name=name)\n",
    "        self._network = modules.GraphNetwork(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            node_model_fn=make_mlp_model,\n",
    "            global_model_fn=make_mlp_model\n",
    "            )\n",
    "\n",
    "    def __call__(self, inputs,\n",
    "            edge_model_kwargs=None,\n",
    "            node_model_kwargs=None,\n",
    "            global_model_kwargs=None):\n",
    "        return self._network(inputs,\n",
    "                      edge_model_kwargs=edge_model_kwargs,\n",
    "                      node_model_kwargs=node_model_kwargs,\n",
    "                      global_model_kwargs=global_model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adopted-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128\n",
    "\n",
    "class GlobalClassifierNoEdgeInfo(snt.Module):\n",
    "\n",
    "    def __init__(self, name=\"GlobalClassifierNoEdgeInfo\"):\n",
    "        super(GlobalClassifierNoEdgeInfo, self).__init__(name=name)\n",
    "\n",
    "        self._edge_block = blocks.EdgeBlock(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            use_edges=False,\n",
    "            use_receiver_nodes=True,\n",
    "            use_sender_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='edge_encoder_block')\n",
    "\n",
    "        self._node_encoder_block = blocks.NodeBlock(\n",
    "            node_model_fn=make_mlp_model,\n",
    "            use_received_edges=False,\n",
    "            use_sent_edges=False,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='node_encoder_block'\n",
    "        )\n",
    "\n",
    "        self._global_block = blocks.GlobalBlock(\n",
    "            global_model_fn=make_mlp_model,\n",
    "            use_edges=True,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "        )\n",
    "\n",
    "        self._core = MLPGraphNetwork()\n",
    "        # Transforms the outputs into appropriate shapes.\n",
    "        global_output_size = 1\n",
    "        global_fn =lambda: snt.Sequential([\n",
    "            snt.nets.MLP([LATENT_SIZE, global_output_size],\n",
    "                         name='global_output'), tf.sigmoid])\n",
    "\n",
    "        self._output_transform = modules.GraphIndependent(None, None, global_fn)\n",
    "\n",
    "    def __call__(self, input_op, num_processing_steps):\n",
    "        latent = self._global_block(self._edge_block(self._node_encoder_block(input_op)))\n",
    "        latent0 = latent\n",
    "\n",
    "        output_ops = []\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
    "            latent = self._core(core_input)\n",
    "            output_ops.append(self._output_transform(latent))\n",
    "\n",
    "        return output_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alpha-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlobalClassifierNoEdgeInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chronic-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graphs = model(input_graph, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "impaired-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.36057603]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.40430257]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.43811432]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.42426237]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.43808976]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.41427603]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.41621685]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.41311935]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.41676453]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.41221336]], dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.globals for x in output_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "roman-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "\n",
    "class GlobalLoss:\n",
    "    def __init__(self, real_global_weight, fake_global_weight):\n",
    "        self.w_global_real = real_global_weight\n",
    "        self.w_global_fake = fake_global_weight\n",
    "\n",
    "    def __call__(self, target_op, output_ops):\n",
    "        global_weights = target_op.globals * self.w_global_real \\\n",
    "            + (1 - target_op.globals) * self.w_global_fake\n",
    "        \n",
    "        print(global_weights)\n",
    "        \n",
    "        loss_ops = [\n",
    "            tf.compat.v1.losses.log_loss(target_op.globals, output_op.globals, weights=global_weights)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "        return tf.stack(loss_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "earlier-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_global = GlobalLoss(real_global_weight = 1.0, fake_global_weight = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "brutal-steel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.45646122, 0.5242964 , 0.5804846 , 0.5570454 , 0.58044255,\n",
       "       0.54051274, 0.5437024 , 0.5386171 , 0.5446045 , 0.53713506],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_global(target_graph, output_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-courage",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "organizational-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify acc function\n",
    "\n",
    "def compute_accuracy(target, output):\n",
    "    \"\"\"Calculate model accuracy.\n",
    "\n",
    "    Returns the number of correctly predicted links and the number\n",
    "    of completely solved list sorts (100% correct predictions).\n",
    "\n",
    "    Args:\n",
    "    target: A `graphs.GraphsTuple` that contains the target graph.\n",
    "    output: A `graphs.GraphsTuple` that contains the output graph.\n",
    "\n",
    "    Returns:\n",
    "    correct: A `float` fraction of correctly labeled nodes/edges.\n",
    "    solved: A `float` fraction of graphs that are completely correctly labeled.\n",
    "    \"\"\"\n",
    "    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "    odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "    cs = []\n",
    "    ss = []\n",
    "    for td, od in zip(tdds, odds):\n",
    "        num_elements = td[\"nodes\"].shape[0]\n",
    "        xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "        yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "\n",
    "        xe = np.reshape(\n",
    "            np.argmax(\n",
    "                np.reshape(td[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "            (-1,))\n",
    "        ye = np.reshape(\n",
    "            np.argmax(\n",
    "                np.reshape(od[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "            (-1,))\n",
    "        c = np.concatenate((xn == yn, xe == ye), axis=0)\n",
    "        s = np.all(c)\n",
    "        cs.append(c)\n",
    "        ss.append(s)\n",
    "    correct = np.mean(np.concatenate(cs, axis=0))\n",
    "    solved = np.mean(np.stack(ss))\n",
    "    return correct, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "interim-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(dataset, batch_size):\n",
    "    \"\"\"\n",
    "    Get signature of inputs for the training loop.\n",
    "    The signature is used by the tf.function\n",
    "    \"\"\"\n",
    "\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    for _, data in dataset.iterrows():\n",
    "        dd = make_graph(data)\n",
    "        if dd[0] is not None:\n",
    "            input_list.append(dd[0])\n",
    "            target_list.append(dd[1])\n",
    "            \n",
    "        if len(input_list) == batch_size:\n",
    "            break\n",
    "\n",
    "    inputs = utils_tf.concat(input_list, axis=0)\n",
    "    targets = utils_tf.concat(target_list, axis=0)\n",
    "    input_signature = (\n",
    "      utils_tf.specs_from_graphs_tuple(inputs),\n",
    "      utils_tf.specs_from_graphs_tuple(targets)\n",
    "    )\n",
    "\n",
    "    return input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "practical-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# the signature has to include the batch size\n",
    "\n",
    "input_signature = get_signature(dummy_df, batch_size)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 10\n",
    "num_processing_steps_ge = 10\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = snt.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "# model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "last_iteration = 0\n",
    "generalization_iteration = 0\n",
    "\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []\n",
    "\n",
    "\n",
    "@functools.partial(tf.function, input_signature=input_signature)\n",
    "def update_step(inputs_tr, targets_tr):\n",
    "    print(\"Tracing update_step\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs_tr = model(inputs_tr, num_processing_steps_tr)\n",
    "        loss_ops_tr = loss_function_global(targets_tr, outputs_tr)\n",
    "        loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)\n",
    "\n",
    "    gradients = tape.gradient(loss_op_tr, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "    return outputs_tr, loss_op_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "latin-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and generalization df\n",
    "# df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "df_train, df_test = train_test_split(dummy_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "atlantic-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 797 ms, total: 23 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO this is very slow\n",
    "# make graphs for each event\n",
    "train_graphs = [make_graph(event) for _, event in df_train.iterrows()]\n",
    "test_graphs = [make_graph(event) for _, event in df_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "pretty-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs = [x for x in train_graphs if x[0] is not None]\n",
    "test_graphs = [x for x in test_graphs if x[0] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "geographic-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsave_object(train_graphs, \"Temp/train_graphs.pkl\")\\nsave_object(train_graphs, \"Temp/test_graphs.pkl\")\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save train_graphs and test_graphs objects to file, it takes too long to make\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, \"wb\") as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\"\n",
    "save_object(train_graphs, \"Temp/train_graphs.pkl\")\n",
    "save_object(train_graphs, \"Temp/test_graphs.pkl\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "needed-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_dataset(datasets, batch_size):\n",
    "    if batch_size > 0:\n",
    "        in_list = []\n",
    "        target_list = []\n",
    "        for dataset in datasets:\n",
    "            inputs_tr, targets_tr = dataset\n",
    "            if inputs_tr is None:\n",
    "                continue\n",
    "            in_list.append(inputs_tr)\n",
    "            target_list.append(targets_tr)\n",
    "            if len(in_list) == batch_size:\n",
    "                inputs_tr = utils_tf.concat(in_list, axis=0)\n",
    "                targets_tr = utils_tf.concat(target_list, axis=0)\n",
    "                yield (inputs_tr, targets_tr)\n",
    "                in_list = []\n",
    "                target_list = []\n",
    "    else:\n",
    "        for dataset in datasets:\n",
    "            if dataset is None:\n",
    "                continue\n",
    "            yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ideal-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = loop_dataset(train_graphs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "middle-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "productive-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "horizontal-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tr, target_tr = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "outdoor-merchant",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_9/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_9/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_9/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_9/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_9/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_9/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_8/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_8/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_8/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_8/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_8/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_8/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_7/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_7/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_7/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_7/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_6/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_6/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_6/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_6/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_5/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_5/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_5/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_5/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_4/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_4/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_4/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_4/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/MLPGraphNetwork/graph_network/edge_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_receiver_nodes_to_edges/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_receiver_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/xju/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_sender_nodes_to_edges/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/GlobalClassifierNoEdgeInfo/edge_encoder_block/broadcast_sender_nodes_to_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7798856"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_step(input_tr, target_tr)[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "original-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.5761519506573677\n",
      "Loss value:  0.6627717569470406\n"
     ]
    }
   ],
   "source": [
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 10\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 20\n",
    "\n",
    "# code for training loop:\n",
    "# https://github.com/xju2/root_gnn/blob/tf2/root_gnn/scripts/train_classifier\n",
    "for epoch in range(2):\n",
    "    total_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    for _ in range(num_training_iterations):\n",
    "        input_tr, target_tr = next(training_data)\n",
    "        total_loss += update_step(input_tr, target_tr)[1].numpy()\n",
    "        num_batches += 1\n",
    "        \n",
    "    loss_tr = total_loss/num_batches\n",
    "    print(\"Loss value: \", loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-douglas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
