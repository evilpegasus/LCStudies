{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "molecular-lying",
   "metadata": {},
   "source": [
    "# Graph Networts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "received-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import uproot3 as ur\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()\n",
    "\n",
    "path_prefix = '/home/mfong/git/LCStudies/'\n",
    "plotpath = path_prefix + 'classifier/Plots/'\n",
    "modelpath = path_prefix + 'classifier/Models/'\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "# import our resolution utilities\n",
    "\n",
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "sys.path\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa305ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "answering-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=24220)]) #in MB\n",
    "\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "specialized-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pi0 events: 263891\n",
      "Number of pi+ events: 435967\n",
      "Number of pi- events: 434627\n",
      "Total: 1134485\n"
     ]
    }
   ],
   "source": [
    "# import pi+- vs. pi0 images\n",
    "\n",
    "inputpath = '/clusterfs/ml4hep/mfong/ML4Pions/v7/'    # ml4hep1 machine\n",
    "# inputpath = \"/data0/mfong/v7/\"    # voltan machine\n",
    "#path = '/eos/user/m/mswiatlo/images/'\n",
    "branches = ['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi', 'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt', 'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE', 'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T', 'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY', 'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT', 'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min', 'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max', 'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max', 'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi', 'cluster_cell_centerCellLayer', 'cluster_cellE_norm']\n",
    "rootfiles = [\"pi0\", \"piplus\", \"piminus\"]\n",
    "trees = {\n",
    "    rfile : ur.open(inputpath+rfile+\".root\")['ClusterTree']\n",
    "    for rfile in rootfiles\n",
    "}\n",
    "pdata = {\n",
    "    ifile : itree.pandas.df(branches, flatten=False)\n",
    "    for ifile, itree in trees.items()\n",
    "}\n",
    "\n",
    "np0 = len(pdata['pi0'])\n",
    "npp = len(pdata['piplus'])\n",
    "npm = len(pdata['piminus'])\n",
    "\n",
    "print(\"Number of pi0 events: {}\".format(np0))\n",
    "print(\"Number of pi+ events: {}\".format(npp))\n",
    "print(\"Number of pi- events: {}\".format(npm))\n",
    "print(\"Total: {}\".format(np0+npp+npm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "known-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_shapes = {\n",
    "    'EMB1': (128,4),\n",
    "    'EMB2': (16,16),\n",
    "    'EMB3': (8,16),\n",
    "    'TileBar0': (4,4),\n",
    "    'TileBar1': (4,4),\n",
    "    'TileBar2': (2,4),\n",
    "}\n",
    "\n",
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer)\n",
    "        for layer in layers\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broken-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi',\n",
       "       'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt',\n",
       "       'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE',\n",
       "       'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T',\n",
       "       'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY',\n",
       "       'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT',\n",
       "       'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min',\n",
       "       'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max',\n",
       "       'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max',\n",
       "       'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi',\n",
       "       'cluster_cell_centerCellLayer', 'cluster_cellE_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[\"pi0\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comprehensive-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263891, 512)\n",
      "(263891, 256)\n",
      "(263891, 128)\n",
      "(263891, 16)\n",
      "(263891, 16)\n",
      "(263891, 8)\n",
      "Total number of cells: 936\n"
     ]
    }
   ],
   "source": [
    "n_cells = 0\n",
    "for key in pcells[\"pi0\"]:\n",
    "    print(pcells[\"pi0\"][key].shape)\n",
    "    n_cells += pcells[\"pi0\"][key].shape[1]\n",
    "print(\"Total number of cells: \" + str(n_cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-blame",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-thompson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df for pi0 only\n",
    "df_p0 = pd.DataFrame(np.concatenate([pcells[\"pi0\"][key] for key in pcells[\"pi0\"].keys()], axis = 1))\n",
    "\n",
    "col_names = []\n",
    "for key in pcells[\"pi0\"].keys():\n",
    "    col_names.extend([key + \"_\" + str(i) for i in range(len(pcells[\"pi0\"][key][0]))])\n",
    "df_p0.columns = col_names\n",
    "\n",
    "df_p0[\"is_p0\"] = 1\n",
    "\n",
    "\n",
    "# print(df_p0.shape)\n",
    "# df_p0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rough-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for pipplus and piminus\n",
    "df_pp = pd.DataFrame(np.concatenate([pcells[\"piplus\"][key] for key in pcells[\"piplus\"].keys()], axis = 1))\n",
    "df_pp.columns = col_names\n",
    "df_pp[\"is_p0\"] = 0\n",
    "\n",
    "df_pm = pd.DataFrame(np.concatenate([pcells[\"piminus\"][key] for key in pcells[\"piminus\"].keys()], axis = 1))\n",
    "df_pm.columns = col_names\n",
    "df_pm[\"is_p0\"] = 0\n",
    "\n",
    "# print(df_pp.shape)\n",
    "# df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virgin-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB1_0</th>\n",
       "      <th>EMB1_1</th>\n",
       "      <th>EMB1_2</th>\n",
       "      <th>EMB1_3</th>\n",
       "      <th>EMB1_4</th>\n",
       "      <th>EMB1_5</th>\n",
       "      <th>EMB1_6</th>\n",
       "      <th>EMB1_7</th>\n",
       "      <th>EMB1_8</th>\n",
       "      <th>EMB1_9</th>\n",
       "      <th>EMB1_10</th>\n",
       "      <th>EMB1_11</th>\n",
       "      <th>EMB1_12</th>\n",
       "      <th>EMB1_13</th>\n",
       "      <th>EMB1_14</th>\n",
       "      <th>EMB1_15</th>\n",
       "      <th>EMB1_16</th>\n",
       "      <th>EMB1_17</th>\n",
       "      <th>EMB1_18</th>\n",
       "      <th>EMB1_19</th>\n",
       "      <th>EMB1_20</th>\n",
       "      <th>EMB1_21</th>\n",
       "      <th>EMB1_22</th>\n",
       "      <th>EMB1_23</th>\n",
       "      <th>EMB1_24</th>\n",
       "      <th>EMB1_25</th>\n",
       "      <th>EMB1_26</th>\n",
       "      <th>EMB1_27</th>\n",
       "      <th>EMB1_28</th>\n",
       "      <th>EMB1_29</th>\n",
       "      <th>EMB1_30</th>\n",
       "      <th>EMB1_31</th>\n",
       "      <th>EMB1_32</th>\n",
       "      <th>EMB1_33</th>\n",
       "      <th>EMB1_34</th>\n",
       "      <th>EMB1_35</th>\n",
       "      <th>EMB1_36</th>\n",
       "      <th>EMB1_37</th>\n",
       "      <th>EMB1_38</th>\n",
       "      <th>EMB1_39</th>\n",
       "      <th>EMB1_40</th>\n",
       "      <th>EMB1_41</th>\n",
       "      <th>EMB1_42</th>\n",
       "      <th>EMB1_43</th>\n",
       "      <th>EMB1_44</th>\n",
       "      <th>EMB1_45</th>\n",
       "      <th>EMB1_46</th>\n",
       "      <th>EMB1_47</th>\n",
       "      <th>EMB1_48</th>\n",
       "      <th>EMB1_49</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB3_119</th>\n",
       "      <th>EMB3_120</th>\n",
       "      <th>EMB3_121</th>\n",
       "      <th>EMB3_122</th>\n",
       "      <th>EMB3_123</th>\n",
       "      <th>EMB3_124</th>\n",
       "      <th>EMB3_125</th>\n",
       "      <th>EMB3_126</th>\n",
       "      <th>EMB3_127</th>\n",
       "      <th>TileBar0_0</th>\n",
       "      <th>TileBar0_1</th>\n",
       "      <th>TileBar0_2</th>\n",
       "      <th>TileBar0_3</th>\n",
       "      <th>TileBar0_4</th>\n",
       "      <th>TileBar0_5</th>\n",
       "      <th>TileBar0_6</th>\n",
       "      <th>TileBar0_7</th>\n",
       "      <th>TileBar0_8</th>\n",
       "      <th>TileBar0_9</th>\n",
       "      <th>TileBar0_10</th>\n",
       "      <th>TileBar0_11</th>\n",
       "      <th>TileBar0_12</th>\n",
       "      <th>TileBar0_13</th>\n",
       "      <th>TileBar0_14</th>\n",
       "      <th>TileBar0_15</th>\n",
       "      <th>TileBar1_0</th>\n",
       "      <th>TileBar1_1</th>\n",
       "      <th>TileBar1_2</th>\n",
       "      <th>TileBar1_3</th>\n",
       "      <th>TileBar1_4</th>\n",
       "      <th>TileBar1_5</th>\n",
       "      <th>TileBar1_6</th>\n",
       "      <th>TileBar1_7</th>\n",
       "      <th>TileBar1_8</th>\n",
       "      <th>TileBar1_9</th>\n",
       "      <th>TileBar1_10</th>\n",
       "      <th>TileBar1_11</th>\n",
       "      <th>TileBar1_12</th>\n",
       "      <th>TileBar1_13</th>\n",
       "      <th>TileBar1_14</th>\n",
       "      <th>TileBar1_15</th>\n",
       "      <th>TileBar2_0</th>\n",
       "      <th>TileBar2_1</th>\n",
       "      <th>TileBar2_2</th>\n",
       "      <th>TileBar2_3</th>\n",
       "      <th>TileBar2_4</th>\n",
       "      <th>TileBar2_5</th>\n",
       "      <th>TileBar2_6</th>\n",
       "      <th>TileBar2_7</th>\n",
       "      <th>is_p0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>0.140632</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 937 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMB1_0  EMB1_1  EMB1_2  EMB1_3  EMB1_4  EMB1_5  EMB1_6  EMB1_7  EMB1_8  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   EMB1_9  EMB1_10  EMB1_11  EMB1_12  EMB1_13  EMB1_14  EMB1_15  EMB1_16  \\\n",
       "0     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_17  EMB1_18  EMB1_19  EMB1_20  EMB1_21  EMB1_22  EMB1_23  EMB1_24  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_25  EMB1_26  EMB1_27  EMB1_28  EMB1_29  EMB1_30  EMB1_31  EMB1_32  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_33  EMB1_34  EMB1_35  EMB1_36  EMB1_37  EMB1_38  EMB1_39  EMB1_40  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_41  EMB1_42  EMB1_43  EMB1_44  EMB1_45  EMB1_46  EMB1_47  EMB1_48  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_49  ...  EMB3_119  EMB3_120  EMB3_121  EMB3_122  EMB3_123  EMB3_124  \\\n",
       "0      0.0  ...  0.000009  0.000038  0.000009       0.0       0.0       0.0   \n",
       "1      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "2      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "3      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "4      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "\n",
       "   EMB3_125  EMB3_126  EMB3_127  TileBar0_0  TileBar0_1  TileBar0_2  \\\n",
       "0       0.0       0.0       0.0    0.000224    0.000315    0.001344   \n",
       "1       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "2       0.0       0.0       0.0    0.000000    0.011872    0.005269   \n",
       "3       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "4       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar0_3  TileBar0_4  TileBar0_5  TileBar0_6  TileBar0_7  TileBar0_8  \\\n",
       "0    0.000428    0.002322    0.012944    0.014262    0.002498    0.001551   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.000000    0.628931    0.088836    0.002091    0.000000   \n",
       "3    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar0_9  TileBar0_10  TileBar0_11  TileBar0_12  TileBar0_13  \\\n",
       "0    0.070766     0.140632     0.001669     0.003287     0.004747   \n",
       "1    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2    0.030488     0.019321     0.004342     0.000000     0.000000   \n",
       "3    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   TileBar0_14  TileBar0_15  TileBar1_0  TileBar1_1  TileBar1_2  TileBar1_3  \\\n",
       "0     0.008165     0.000888    0.000054    0.000776    0.001186    0.000146   \n",
       "1     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2     0.000177     0.001947    0.000000    0.019718    0.003629    0.000000   \n",
       "3     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar1_4  TileBar1_5  TileBar1_6  TileBar1_7  TileBar1_8  TileBar1_9  \\\n",
       "0    0.000375    0.006990    0.007225    0.003866    0.001419    0.035971   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.087662    0.022248    0.000901    0.000000    0.006445   \n",
       "3    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar1_10  TileBar1_11  TileBar1_12  TileBar1_13  TileBar1_14  \\\n",
       "0     0.047344     0.003773     0.000361     0.006787     0.003358   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.000219     0.000237     0.000000     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   TileBar1_15  TileBar2_0  TileBar2_1  TileBar2_2  TileBar2_3  TileBar2_4  \\\n",
       "0     0.002189         0.0    0.000625    0.000405    0.000031    0.000024   \n",
       "1     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "2     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "3     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "4     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar2_5  TileBar2_6  TileBar2_7  is_p0  \n",
       "0    0.001023    0.001606         0.0      0  \n",
       "1    0.000000    0.000000         0.0      0  \n",
       "2    0.000000    0.000000         0.0      0  \n",
       "3    0.000000    0.000000         0.0      0  \n",
       "4    0.000000    0.000000         0.0      1  \n",
       "\n",
       "[5 rows x 937 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create final df\n",
    "df = df_p0.append(df_pp.append(df_pm))\n",
    "df = df.sample(frac=1) # Shuffle the df so pi0 are not all first\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-hanging",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facial-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutations for doubly connected edges\n",
    "from itertools import permutations\n",
    "import functools\n",
    "import networkx as nx\n",
    "import sonnet as snt\n",
    "\n",
    "from graph_nets import blocks\n",
    "\n",
    "from graph_nets import graphs\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "banned-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB1_0        0.000000\n",
       "EMB1_1        0.000000\n",
       "EMB1_2        0.000000\n",
       "EMB1_3        0.000000\n",
       "EMB1_4        0.000000\n",
       "                ...   \n",
       "TileBar2_4    0.000024\n",
       "TileBar2_5    0.001023\n",
       "TileBar2_6    0.001606\n",
       "TileBar2_7    0.000000\n",
       "is_p0         0.000000\n",
       "Name: 0, Length: 937, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event0 = df.loc[0]\n",
    "event0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "appropriate-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fully_connected_edges(nodes):\n",
    "    \"\"\"\n",
    "    returns a list of tuples with (sender_node, reciever_node) for a fully connected graph\n",
    "    ex: [(1,2), (2,1), (0,1)]\n",
    "    \"\"\"\n",
    "    n_nodes = len(nodes)\n",
    "    return list(permutations(range(n_nodes), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ceramic-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(event):\n",
    "    \n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    MIN_VALUE = 0.05\n",
    "    solution = \"is_p0\"\n",
    "    \n",
    "    nodes = [[cell] for cell in event[col_names][event[col_names] > MIN_VALUE]]\n",
    "    n_nodes = len(nodes)\n",
    "    if n_nodes < 1:\n",
    "        return (None, None)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "    \n",
    "    edge_endpoints = make_fully_connected_edges(nodes)\n",
    "    senders = np.array([x[0] for x in edge_endpoints])\n",
    "    receivers = np.array([x[1] for x in edge_endpoints])\n",
    "    n_edges = len(edge_endpoints)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    \n",
    "    # TODO distance between cells as edge feature\n",
    "    \n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    \n",
    "    return (input_graph, target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fatty-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"has shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "characteristic-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes has shape (4, 1)\n",
      "edges has shape (12, 1)\n",
      "receivers has shape (12,)\n",
      "senders has shape (12,)\n",
      "globals has shape (1, 1)\n",
      "n_node has shape (1,)\n",
      "n_edge has shape (1,)\n"
     ]
    }
   ],
   "source": [
    "graphs_tuple0_input, graphs_tuple0_target = make_graph(event0)\n",
    "\n",
    "print_graphs_tuple(graphs_tuple0_input, data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "improving-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i in range(100):\n",
    "    graphs.append(make_graph(df.loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "macro-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# [x[0] for x in graphs][0].n_node\n",
    "\n",
    "for test_input, _ in graphs:\n",
    "    if test_input is not None:\n",
    "        print(test_input.n_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "structural-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting functions from example (broken)\n",
    "\n",
    "# def plot_graph_networkx(graph, ax, pos=None):\n",
    "#   node_labels = {node: \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for node, data in graph.nodes(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   edge_labels = {(sender, receiver): \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for sender, receiver, data in graph.edges(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   global_label = (\"{:.3g}\".format(graph.graph[\"features\"][0])\n",
    "#                   if graph.graph[\"features\"] is not None else None)\n",
    "\n",
    "#   if pos is None:\n",
    "#     pos = nx.spring_layout(graph)\n",
    "#   nx.draw_networkx(graph, pos, ax=ax, labels=node_labels)\n",
    "\n",
    "#   if edge_labels:\n",
    "#     nx.draw_networkx_edge_labels(graph, pos, edge_labels, ax=ax)\n",
    "\n",
    "#   if global_label:\n",
    "#     plt.text(0.05, 0.95, global_label, transform=ax.transAxes)\n",
    "\n",
    "#   ax.yaxis.set_visible(False)\n",
    "#   ax.xaxis.set_visible(False)\n",
    "#   return pos\n",
    "\n",
    "# def plot_graphs_tuple(graphs_tuple):\n",
    "#   networkx_graphs = utils_np.graphs_tuple_to_networkxs(graphs_tuple)\n",
    "#   num_graphs = len(networkx_graphs)\n",
    "#   _, axes = plt.subplots(1, num_graphs, figsize=(5*num_graphs, 5))\n",
    "#   if num_graphs == 1:\n",
    "#     axes = axes,\n",
    "#   for graph, ax in zip(networkx_graphs, axes):\n",
    "#     plot_graph_networkx(graph, ax)\n",
    "\n",
    "# plot_graphs_tuple(graphs_tuple0_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-closer",
   "metadata": {},
   "source": [
    "## Graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apparent-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the newest dev version of graph_nets (see https://github.com/deepmind/graph_nets/issues/139)\n",
    "# as of 3/25/2021\n",
    "\n",
    "\n",
    "# !pip install git+git://github.com/deepmind/graph_nets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "local-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 2\n",
    "def make_mlp_model():\n",
    "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "  The parameters of each new MLP are not shared with others generated by\n",
    "  this function.\n",
    "\n",
    "  Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "  \"\"\"\n",
    "  # the activation function choices:\n",
    "  # swish, relu, relu6, leaky_relu\n",
    "  return snt.Sequential([\n",
    "      snt.nets.MLP([128, 64]*NUM_LAYERS,\n",
    "                    activation=tf.nn.relu,\n",
    "                    activate_final=True, \n",
    "                  #  dropout_rate=DROPOUT_RATE\n",
    "        ),\n",
    "      snt.LayerNorm(axis=-1, create_scale=True, create_offset=False)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "composed-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGraphNetwork(snt.Module):\n",
    "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
    "    def __init__(self, name=\"MLPGraphNetwork\"):\n",
    "        super(MLPGraphNetwork, self).__init__(name=name)\n",
    "        self._network = modules.GraphNetwork(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            node_model_fn=make_mlp_model,\n",
    "            global_model_fn=make_mlp_model\n",
    "            )\n",
    "\n",
    "    def __call__(self, inputs,\n",
    "            edge_model_kwargs=None,\n",
    "            node_model_kwargs=None,\n",
    "            global_model_kwargs=None):\n",
    "        return self._network(inputs,\n",
    "                      edge_model_kwargs=edge_model_kwargs,\n",
    "                      node_model_kwargs=node_model_kwargs,\n",
    "                      global_model_kwargs=global_model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "handed-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "class GlobalClassifierNoEdgeInfo(snt.Module):\n",
    "\n",
    "    def __init__(self, name=\"GlobalClassifierNoEdgeInfo\"):\n",
    "        super(GlobalClassifierNoEdgeInfo, self).__init__(name=name)\n",
    "\n",
    "        self._edge_block = blocks.EdgeBlock(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            use_edges=False,              # all edge features are 0.0 right now, use false for now\n",
    "            use_receiver_nodes=True,\n",
    "            use_sender_nodes=True,\n",
    "            use_globals=False,            # can try true later\n",
    "            name='edge_encoder_block')\n",
    "\n",
    "        self._node_encoder_block = blocks.NodeBlock(\n",
    "            node_model_fn=make_mlp_model,\n",
    "            use_received_edges=False,      # if assigning edge features set to true\n",
    "            use_sent_edges=False,          # if assigning edge features set to true\n",
    "            use_nodes=True,\n",
    "            use_globals=False,             # can try true later to see if any effect\n",
    "            name='node_encoder_block'\n",
    "        )\n",
    "\n",
    "        self._global_block = blocks.GlobalBlock(\n",
    "            global_model_fn=make_mlp_model,\n",
    "            use_edges=True,\n",
    "            use_nodes=True,\n",
    "            use_globals=True,\n",
    "        )\n",
    "\n",
    "        self._core = MLPGraphNetwork()\n",
    "        # Transforms the outputs into appropriate shapes.\n",
    "        global_output_size = 1\n",
    "        global_fn = lambda: snt.Sequential([\n",
    "            snt.nets.MLP([LATENT_SIZE, LATENT_SIZE],),\n",
    "            snt.nets.MLP([LATENT_SIZE, LATENT_SIZE],),\n",
    "            snt.nets.MLP([LATENT_SIZE, global_output_size], name='global_output'),       # TODO add more layers, end with size 1\n",
    "            tf.sigmoid\n",
    "        ])\n",
    "\n",
    "        self._output_transform = modules.GraphIndependent(None, None, global_fn)\n",
    "\n",
    "    def __call__(self, input_op, num_processing_steps):\n",
    "        latent = self._global_block(self._edge_block(self._node_encoder_block(input_op)))\n",
    "        latent0 = latent\n",
    "\n",
    "        output_ops = []\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
    "            latent = self._core(core_input)\n",
    "            output_ops.append(self._output_transform(latent))\n",
    "\n",
    "        return output_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "removed-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlobalClassifierNoEdgeInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "compact-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graphs = model(graphs_tuple0_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cosmetic-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5241179]], dtype=float32)>]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.globals for x in output_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "solved-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "\n",
    "class GlobalLoss:\n",
    "    def __init__(self, real_global_weight, fake_global_weight):\n",
    "        self.w_global_real = real_global_weight\n",
    "        self.w_global_fake = fake_global_weight\n",
    "\n",
    "    def __call__(self, target_op, output_ops):\n",
    "        global_weights = target_op.globals * self.w_global_real \\\n",
    "            + (1 - target_op.globals) * self.w_global_fake\n",
    "        \n",
    "        print(global_weights)\n",
    "        \n",
    "        loss_ops = [\n",
    "            tf.compat.v1.losses.log_loss(target_op.globals, output_op.globals, weights=global_weights)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "        return tf.stack(loss_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "mexican-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_global = GlobalLoss(real_global_weight = 1.0, fake_global_weight = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "offshore-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.74258494], dtype=float32)>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_global(graphs_tuple0_target, output_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "missing-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "target_list = []\n",
    "counter = 0\n",
    "index = 0\n",
    "# while counter < 100:\n",
    "#     input_graph, target_graph = train_graphs[index]\n",
    "#     if input_graph is None:\n",
    "#         index += 1\n",
    "#         continue\n",
    "#     target_list.append(target_graph)\n",
    "#     input_list.append(input_graph)\n",
    "#     counter += 1\n",
    "\n",
    "# concated_inputs = utils_tf.concat(input_list, axis=0)\n",
    "# concated_targets = utils_tf.concat(target_graph, axis=0)\n",
    "\n",
    "\n",
    "for data in train_graphs[:1000]:\n",
    "    input_tr, target_tr = data\n",
    "    if input_tr is None:\n",
    "            continue\n",
    "    input_list.append(input_tr)\n",
    "    target_list.append(target_tr)\n",
    "    if len(input_list) >= batch_size:\n",
    "        input_tr = utils_tf.concat(input_list, axis=0)\n",
    "        target_tr = utils_tf.concat(target_list, axis=0)\n",
    "        x = model(input_tr, 1)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-cherry",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "noted-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify acc function\n",
    "\n",
    "# def compute_accuracy(target, output):\n",
    "#     \"\"\"Calculate model accuracy.\n",
    "\n",
    "#     Returns the number of correctly predicted links and the number\n",
    "#     of completely solved list sorts (100% correct predictions).\n",
    "\n",
    "#     Args:\n",
    "#     target: A `graphs.GraphsTuple` that contains the target graph.\n",
    "#     output: A `graphs.GraphsTuple` that contains the output graph.\n",
    "\n",
    "#     Returns:\n",
    "#     correct: A `float` fraction of correctly labeled nodes/edges.\n",
    "#     solved: A `float` fraction of graphs that are completely correctly labeled.\n",
    "#     \"\"\"\n",
    "#     tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "#     odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "#     cs = []\n",
    "#     ss = []\n",
    "#     for td, od in zip(tdds, odds):\n",
    "#         num_elements = td[\"nodes\"].shape[0]\n",
    "#         xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "#         yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "\n",
    "#         xe = np.reshape(\n",
    "#             np.argmax(\n",
    "#                 np.reshape(td[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "#             (-1,))\n",
    "#         ye = np.reshape(\n",
    "#             np.argmax(\n",
    "#                 np.reshape(od[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "#             (-1,))\n",
    "#         c = np.concatenate((xn == yn, xe == ye), axis=0)\n",
    "#         s = np.all(c)\n",
    "#         cs.append(c)\n",
    "#         ss.append(s)\n",
    "#     correct = np.mean(np.concatenate(cs, axis=0))\n",
    "#     solved = np.mean(np.stack(ss))\n",
    "#     return correct, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cloudy-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(dataset, batch_size):\n",
    "    \"\"\"\n",
    "    Get signature of inputs for the training loop.\n",
    "    The signature is used by the tf.function\n",
    "    \"\"\"\n",
    "\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    for _, data in dataset.iterrows():\n",
    "        dd = make_graph(data)\n",
    "        if dd[0] is not None:\n",
    "            input_list.append(dd[0])\n",
    "            target_list.append(dd[1])\n",
    "            \n",
    "        if len(input_list) == batch_size:\n",
    "            break\n",
    "\n",
    "    inputs = utils_tf.concat(input_list, axis=0)\n",
    "    targets = utils_tf.concat(target_list, axis=0)\n",
    "    input_signature = (\n",
    "      utils_tf.specs_from_graphs_tuple(inputs),\n",
    "      utils_tf.specs_from_graphs_tuple(targets)\n",
    "    )\n",
    "    \n",
    "    return input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "several-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "input_signature = get_signature(df, batch_size)\n",
    "\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 2\n",
    "num_processing_steps_ge = 2\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = snt.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "# model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "last_iteration = 0\n",
    "generalization_iteration = 0\n",
    "\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []\n",
    "\n",
    "\n",
    "@functools.partial(tf.function, input_signature=input_signature)\n",
    "def update_step(inputs_tr, targets_tr):\n",
    "    print(\"Tracing update_step\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs_tr = model(inputs_tr, num_processing_steps_tr)\n",
    "        loss_ops_tr = loss_function_global(targets_tr, outputs_tr)\n",
    "        loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)\n",
    "\n",
    "    gradients = tape.gradient(loss_op_tr, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "    return outputs_tr, loss_op_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stupid-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and generalization df\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "square-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values to gaussian\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fit scaler to train set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train.drop(\"is_p0\", axis=1))\n",
    "\n",
    "# scale the train set\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df_train.drop(\"is_p0\", axis=1)))\n",
    "df_train_scaled[\"is_p0\"] = df_train[\"is_p0\"].values\n",
    "df_train_scaled.columns = df_train.columns\n",
    "\n",
    "# scale the test set\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test.drop(\"is_p0\", axis=1)))\n",
    "df_test_scaled[\"is_p0\"] = df_test[\"is_p0\"].values\n",
    "df_test_scaled.columns = df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "figured-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 40s, sys: 14.6 s, total: 5min 55s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO this is very slow (1.5 hours for full 1100000 row dataset)\n",
    "# 5 min for 50000 rows\n",
    "# make graphs for each event\n",
    "train_graphs = [make_graph(event) for _, event in df_train_scaled[:50000].iterrows()]\n",
    "test_graphs = [make_graph(event) for _, event in df_test_scaled[:5000].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save train_graphs and test_graphs objects to file, it takes too long to make\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, \"wb\") as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(train_graphs, \"Temp/train_graphs_scaled.pkl\")\n",
    "save_object(train_graphs, \"Temp/test_graphs_scaled.pkl\")\n",
    "\n",
    "\"\"\"\n",
    "Load the graph dataset from pickle object files\n",
    "\"\"\"\n",
    "# file = open(\"Temp/train_graphs.pkl\",'rb')\n",
    "# train_graphs = pickle.load(file)\n",
    "# file.close()\n",
    "\n",
    "# file = open(\"Temp/test_graphs.pkl\",'rb')\n",
    "# test_graphs = pickle.load(file)\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "instant-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_dataset(datasets, batch_size):\n",
    "    if batch_size > 0:\n",
    "        in_list = []\n",
    "        target_list = []\n",
    "        for dataset in datasets:\n",
    "            inputs_tr, targets_tr = dataset\n",
    "            if inputs_tr is None:\n",
    "                continue\n",
    "            in_list.append(inputs_tr)\n",
    "            target_list.append(targets_tr)\n",
    "            if len(in_list) == batch_size:\n",
    "                inputs_tr = utils_tf.concat(in_list, axis=0)\n",
    "                targets_tr = utils_tf.concat(target_list, axis=0)\n",
    "                yield (inputs_tr, targets_tr)\n",
    "                in_list = []\n",
    "                target_list = []\n",
    "    else:\n",
    "        for dataset in datasets:\n",
    "            if dataset is None:\n",
    "                continue\n",
    "            yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "coordinated-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator that yields a graph of the batch_size concatenated graphs\n",
    "training_data = loop_dataset(train_graphs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "strategic-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tr, target_tr = next(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dated-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907588"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "damaged-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4610453248023987\n",
      "Loss: 0.46114158630371094\n",
      "Loss: 0.4609955847263336\n",
      "Loss: 0.46059614419937134\n",
      "Loss: 0.4599519670009613\n",
      "Loss: 0.45918089151382446\n",
      "Loss: 0.4583708941936493\n",
      "Loss: 0.4576148986816406\n",
      "Loss: 0.45698490738868713\n",
      "Loss: 0.45671215653419495\n",
      "Loss: 0.4567072093486786\n",
      "Loss: 0.45671185851097107\n",
      "Loss: 0.4566919505596161\n",
      "Loss: 0.4566284120082855\n",
      "Loss: 0.45650988817214966\n",
      "Loss: 0.45633697509765625\n",
      "Loss: 0.4561152458190918\n",
      "Loss: 0.4558555781841278\n",
      "Loss: 0.455574095249176\n",
      "Loss: 0.4552818238735199\n",
      "Loss: 0.45498958230018616\n",
      "Loss: 0.45475897192955017\n",
      "Loss: 0.45455238223075867\n",
      "Loss: 0.45436397194862366\n",
      "Loss: 0.45421481132507324\n",
      "Loss: 0.45408591628074646\n",
      "Loss: 0.45397621393203735\n",
      "Loss: 0.45388126373291016\n",
      "Loss: 0.45382919907569885\n",
      "Loss: 0.4537911117076874\n",
      "Loss: 0.4537179172039032\n",
      "Loss: 0.45358729362487793\n",
      "Loss: 0.45342347025871277\n",
      "Loss: 0.4533112049102783\n",
      "Loss: 0.4532068371772766\n",
      "Loss: 0.4531041085720062\n",
      "Loss: 0.45301198959350586\n",
      "Loss: 0.45291003584861755\n",
      "Loss: 0.4528124928474426\n",
      "Loss: 0.45271894335746765\n",
      "Loss: 0.4526293873786926\n",
      "Loss: 0.45255133509635925\n",
      "Loss: 0.45248839259147644\n",
      "Loss: 0.45242634415626526\n",
      "Loss: 0.4523608386516571\n",
      "Loss: 0.4522974193096161\n",
      "Loss: 0.4522411525249481\n",
      "Loss: 0.452169269323349\n",
      "Loss: 0.45209869742393494\n",
      "Loss: 0.45203256607055664\n",
      "Loss: 0.45197102427482605\n",
      "Loss: 0.45190855860710144\n",
      "Loss: 0.4518461227416992\n",
      "Loss: 0.4517941474914551\n",
      "Loss: 0.45174726843833923\n",
      "Loss: 0.45170798897743225\n",
      "Loss: 0.4516640603542328\n",
      "Loss: 0.45161229372024536\n",
      "Loss: 0.45157313346862793\n",
      "Loss: 0.45153409242630005\n",
      "Loss: 0.4514945149421692\n",
      "Loss: 0.4514525532722473\n",
      "Loss: 0.451416939496994\n",
      "Loss: 0.45137983560562134\n",
      "Loss: 0.45134636759757996\n",
      "Loss: 0.4513120651245117\n",
      "Loss: 0.4512798488140106\n",
      "Loss: 0.45125246047973633\n",
      "Loss: 0.4512215554714203\n",
      "Loss: 0.4511856138706207\n",
      "Loss: 0.45115190744400024\n",
      "Loss: 0.4511263072490692\n",
      "Loss: 0.45109835267066956\n",
      "Loss: 0.45107150077819824\n",
      "Loss: 0.4510463774204254\n",
      "Loss: 0.45101800560951233\n",
      "Loss: 0.45098814368247986\n",
      "Loss: 0.450965017080307\n",
      "Loss: 0.4509299397468567\n",
      "Loss: 0.4509093463420868\n",
      "Loss: 0.4508797824382782\n",
      "Loss: 0.450851172208786\n",
      "Loss: 0.45081692934036255\n",
      "Loss: 0.45078951120376587\n",
      "Loss: 0.4507468342781067\n",
      "Loss: 0.45070719718933105\n",
      "Loss: 0.4506552219390869\n",
      "Loss: 0.4505864083766937\n",
      "Loss: 0.4504864811897278\n",
      "Loss: 0.450423926115036\n",
      "Loss: 0.4504179060459137\n",
      "Loss: 0.4502590298652649\n",
      "Loss: 0.4502054750919342\n",
      "Loss: 0.45019206404685974\n",
      "Loss: 0.4501475393772125\n",
      "Loss: 0.4500628113746643\n",
      "Loss: 0.45004016160964966\n",
      "Loss: 0.45009586215019226\n",
      "Loss: 0.45011910796165466\n",
      "Loss: 0.45010051131248474\n",
      "Loss: 0.4500119686126709\n",
      "Loss: 0.44991984963417053\n",
      "Loss: 0.44987136125564575\n",
      "Loss: 0.4498938024044037\n",
      "Loss: 0.4498666822910309\n",
      "Loss: 0.4498121738433838\n",
      "Loss: 0.4497489035129547\n",
      "Loss: 0.44970592856407166\n",
      "Loss: 0.4496884047985077\n",
      "Loss: 0.44968166947364807\n",
      "Loss: 0.4496472477912903\n",
      "Loss: 0.4495096802711487\n",
      "Loss: 0.44964519143104553\n",
      "Loss: 0.44953233003616333\n",
      "Loss: 0.4495117664337158\n",
      "Loss: 0.4496486783027649\n",
      "Loss: 0.44955530762672424\n",
      "Loss: 0.4495149552822113\n",
      "Loss: 0.44951310753822327\n",
      "Loss: 0.4494757354259491\n",
      "Loss: 0.44940948486328125\n",
      "Loss: 0.4494658410549164\n",
      "Loss: 0.44945716857910156\n",
      "Loss: 0.44939857721328735\n",
      "Loss: 0.44930917024612427\n",
      "Loss: 0.44931650161743164\n",
      "Loss: 0.44926711916923523\n",
      "Loss: 0.44926711916923523\n",
      "Loss: 0.44923868775367737\n",
      "Loss: 0.4491632580757141\n",
      "Loss: 0.44913506507873535\n",
      "Loss: 0.4490969181060791\n",
      "Loss: 0.4490525722503662\n",
      "Loss: 0.44903650879859924\n",
      "Loss: 0.44901275634765625\n",
      "Loss: 0.44899311661720276\n",
      "Loss: 0.4489297866821289\n",
      "Loss: 0.4489705562591553\n",
      "Loss: 0.44890156388282776\n",
      "Loss: 0.44886094331741333\n",
      "Loss: 0.4488525986671448\n",
      "Loss: 0.44878265261650085\n",
      "Loss: 0.4486857056617737\n",
      "Loss: 0.4487663209438324\n",
      "Loss: 0.4486598074436188\n",
      "Loss: 0.44858500361442566\n",
      "Loss: 0.4485962986946106\n",
      "Loss: 0.4485590159893036\n",
      "Loss: 0.4484945833683014\n",
      "Loss: 0.4484138488769531\n",
      "Loss: 0.4483306407928467\n",
      "Loss: 0.4482637941837311\n",
      "Loss: 0.44814538955688477\n",
      "Loss: 0.448085218667984\n",
      "Loss: 0.44805121421813965\n",
      "Loss: 0.4479597508907318\n",
      "Loss: 0.4478304982185364\n",
      "Loss: 0.4477613568305969\n",
      "Loss: 0.44770047068595886\n",
      "Loss: 0.4476061463356018\n",
      "Loss: 0.4474835991859436\n",
      "Loss: 0.44732895493507385\n",
      "Loss: 0.4471377432346344\n",
      "Loss: 0.44692903757095337\n",
      "Loss: 0.4467228949069977\n",
      "Loss: 0.446484237909317\n",
      "Loss: 0.4464775025844574\n",
      "Loss: 0.44634199142456055\n",
      "Loss: 0.4459974467754364\n",
      "Loss: 0.44620952010154724\n",
      "Loss: 0.4457162022590637\n",
      "Loss: 0.44583994150161743\n",
      "Loss: 0.44501373171806335\n",
      "Loss: 0.4449525773525238\n",
      "Loss: 0.44451257586479187\n",
      "Loss: 0.4446885585784912\n",
      "Loss: 0.4444875419139862\n",
      "Loss: 0.4440441131591797\n",
      "Loss: 0.44351324439048767\n",
      "Loss: 0.44379639625549316\n",
      "Loss: 0.4438090920448303\n",
      "Loss: 0.4484662115573883\n",
      "Loss: 0.4421338737010956\n",
      "Loss: 0.44856759905815125\n",
      "Loss: 0.4492188096046448\n",
      "Loss: 0.44940873980522156\n",
      "Loss: 0.4487379491329193\n",
      "Loss: 0.44917699694633484\n",
      "Loss: 0.44810962677001953\n",
      "Loss: 0.44792452454566956\n",
      "Loss: 0.44751834869384766\n",
      "Loss: 0.44743308424949646\n",
      "Loss: 0.44769617915153503\n",
      "Loss: 0.44718050956726074\n",
      "Loss: 0.4471644461154938\n",
      "Loss: 0.447314590215683\n",
      "Loss: 0.44716721773147583\n",
      "Loss: 0.4471034109592438\n",
      "Loss: 0.44675111770629883\n",
      "Loss: 0.4470195770263672\n",
      "Loss: 0.4467040002346039\n",
      "Loss: 0.4465753138065338\n",
      "Loss: 0.4464382231235504\n",
      "Loss: 0.4464380443096161\n",
      "Loss: 0.4461231827735901\n",
      "Loss: 0.4460485875606537\n",
      "Loss: 0.44590267539024353\n",
      "Loss: 0.44562968611717224\n",
      "Loss: 0.44554463028907776\n",
      "Loss: 0.4452613890171051\n",
      "Loss: 0.44499656558036804\n",
      "Loss: 0.44422054290771484\n",
      "Loss: 0.4402695596218109\n",
      "Loss: 0.43973374366760254\n",
      "Loss: 0.4409582316875458\n",
      "Loss: 0.4393117427825928\n",
      "Loss: 0.4436560273170471\n",
      "Loss: 0.44398805499076843\n",
      "Loss: 0.438425749540329\n",
      "Loss: 0.4372793734073639\n",
      "Loss: 0.44227296113967896\n",
      "Loss: 0.4385836720466614\n",
      "Loss: 0.4387916624546051\n",
      "Loss: 0.43860021233558655\n",
      "Loss: 0.4373248219490051\n",
      "Loss: 0.43885526061058044\n",
      "Loss: 0.4364650845527649\n",
      "Loss: 0.43713709712028503\n",
      "Loss: 0.4363020062446594\n",
      "Loss: 0.4359603524208069\n",
      "Loss: 0.4361768662929535\n",
      "Loss: 0.43494659662246704\n",
      "Loss: 0.4341756999492645\n",
      "Loss: 0.4339771270751953\n",
      "Loss: 0.43352943658828735\n",
      "Loss: 0.4331377446651459\n",
      "Loss: 0.4321947693824768\n",
      "Loss: 0.43197008967399597\n",
      "Loss: 0.43537431955337524\n",
      "Loss: 0.4364319443702698\n",
      "Loss: 0.43212372064590454\n",
      "Loss: 0.44733235239982605\n",
      "Loss: 0.44820472598075867\n",
      "Loss: 0.4310756325721741\n",
      "Loss: 0.43875908851623535\n",
      "Loss: 0.4350687563419342\n",
      "Loss: 0.43567290902137756\n",
      "Loss: 0.43034791946411133\n",
      "Loss: 0.43491998314857483\n",
      "Loss: 0.42911291122436523\n",
      "Loss: 0.4402712285518646\n",
      "Loss: 0.4353671669960022\n",
      "Loss: 0.4410669803619385\n",
      "Loss: 0.4368824064731598\n",
      "Loss: 0.4420609176158905\n",
      "Loss: 0.449400395154953\n",
      "Loss: 0.44490453600883484\n",
      "Loss: 0.4370032846927643\n",
      "Loss: 0.4339442253112793\n",
      "Loss: 0.4350441098213196\n",
      "Loss: 0.43348726630210876\n",
      "Loss: 0.4305368959903717\n",
      "Loss: 0.43785127997398376\n",
      "Loss: 0.4335269629955292\n",
      "Loss: 0.4430198669433594\n",
      "Loss: 0.44391632080078125\n",
      "Loss: 0.4453616142272949\n",
      "Loss: 0.4377053678035736\n",
      "Loss: 0.4298318028450012\n",
      "Loss: 0.43231964111328125\n",
      "Loss: 0.43752557039260864\n",
      "Loss: 0.4370107650756836\n",
      "Loss: 0.4386472702026367\n",
      "Loss: 0.43636780977249146\n",
      "Loss: 0.43804046511650085\n",
      "Loss: 0.44210195541381836\n",
      "Loss: 0.43404385447502136\n",
      "Loss: 0.4418693482875824\n",
      "Loss: 0.445244699716568\n",
      "Loss: 0.4464204013347626\n",
      "Loss: 0.4375741481781006\n",
      "Loss: 0.42704343795776367\n",
      "Loss: 0.44539976119995117\n",
      "Loss: 0.44560548663139343\n",
      "Loss: 0.4298696517944336\n",
      "Loss: 0.43788883090019226\n",
      "Loss: 0.443364679813385\n",
      "Loss: 0.4463302791118622\n",
      "Loss: 0.44544562697410583\n",
      "Loss: 0.44355425238609314\n",
      "Loss: 0.4414709210395813\n",
      "Loss: 0.4400944709777832\n",
      "Loss: 0.44092264771461487\n",
      "Loss: 0.4421946108341217\n",
      "Loss: 0.4416056275367737\n",
      "Loss: 0.4399746358394623\n",
      "Loss: 0.43902501463890076\n",
      "Loss: 0.4380694031715393\n",
      "Loss: 0.4382766783237457\n",
      "Loss: 0.43913817405700684\n",
      "Loss: 0.43885374069213867\n",
      "Loss: 0.43778467178344727\n",
      "Loss: 0.43795910477638245\n",
      "Loss: 0.43827077746391296\n",
      "Loss: 0.43784481287002563\n",
      "Loss: 0.43784841895103455\n",
      "Loss: 0.4376589357852936\n",
      "Loss: 0.43674325942993164\n",
      "Loss: 0.43599367141723633\n",
      "Loss: 0.4349084496498108\n",
      "Loss: 0.4329220950603485\n",
      "Loss: 0.43585777282714844\n",
      "Loss: 0.42912527918815613\n",
      "Loss: 0.4363071620464325\n",
      "Loss: 0.43918201327323914\n",
      "Loss: 0.43889355659484863\n",
      "Loss: 0.43524765968322754\n",
      "Loss: 0.4295079708099365\n",
      "Loss: 0.44220200181007385\n",
      "Loss: 0.4459288716316223\n",
      "Loss: 0.4289376437664032\n",
      "Loss: 0.43579980731010437\n",
      "Loss: 0.44190025329589844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.44544848799705505\n",
      "Loss: 0.44403859972953796\n",
      "Loss: 0.44055911898612976\n",
      "Loss: 0.43759337067604065\n",
      "Loss: 0.43737897276878357\n",
      "Loss: 0.4388492703437805\n",
      "Loss: 0.43996405601501465\n",
      "Loss: 0.439524382352829\n",
      "Loss: 0.4380801320075989\n",
      "Loss: 0.4365186393260956\n",
      "Loss: 0.4357764720916748\n",
      "Loss: 0.4368588626384735\n",
      "Loss: 0.43747687339782715\n",
      "Loss: 0.4372813403606415\n",
      "Loss: 0.43568140268325806\n",
      "Loss: 0.4355982840061188\n",
      "Loss: 0.4357256591320038\n",
      "Loss: 0.4361606538295746\n",
      "Loss: 0.43610525131225586\n",
      "Loss: 0.43529319763183594\n",
      "Loss: 0.43468141555786133\n",
      "Loss: 0.4342148005962372\n",
      "Loss: 0.43448305130004883\n",
      "Loss: 0.43468475341796875\n",
      "Loss: 0.4344322681427002\n",
      "Loss: 0.43388763070106506\n",
      "Loss: 0.433403879404068\n",
      "Loss: 0.43238577246665955\n",
      "Loss: 0.4315546154975891\n",
      "Loss: 0.4293740391731262\n",
      "Loss: 0.43262630701065063\n",
      "Loss: 0.4293522834777832\n",
      "Loss: 0.42892083525657654\n",
      "Loss: 0.42872077226638794\n",
      "Loss: 0.4277072548866272\n",
      "Loss: 0.42766162753105164\n",
      "Loss: 0.4314729869365692\n",
      "Loss: 0.42631635069847107\n",
      "Loss: 0.42728081345558167\n",
      "Loss: 0.42549243569374084\n",
      "Loss: 0.4267789423465729\n",
      "Loss: 0.4257884919643402\n",
      "Loss: 0.43041181564331055\n",
      "Loss: 0.4276869297027588\n",
      "Loss: 0.42739757895469666\n",
      "Loss: 0.42830991744995117\n",
      "Loss: 0.4256816506385803\n",
      "Loss: 0.42559710144996643\n",
      "Loss: 0.4283258616924286\n",
      "Loss: 0.42629262804985046\n",
      "Loss: 0.4261181056499481\n",
      "Loss: 0.42693111300468445\n",
      "Loss: 0.4263177812099457\n",
      "Loss: 0.425445556640625\n",
      "Loss: 0.4280245304107666\n",
      "Loss: 0.426312655210495\n",
      "Loss: 0.4265553951263428\n",
      "Loss: 0.4259676933288574\n",
      "Loss: 0.425880491733551\n",
      "Loss: 0.42533499002456665\n",
      "Loss: 0.42626506090164185\n",
      "Loss: 0.4266148507595062\n",
      "Loss: 0.42576834559440613\n",
      "Loss: 0.42687129974365234\n",
      "Loss: 0.42560282349586487\n",
      "Loss: 0.4256073534488678\n",
      "Loss: 0.4254051148891449\n",
      "Loss: 0.42586347460746765\n",
      "Loss: 0.4252331852912903\n",
      "Loss: 0.42583855986595154\n",
      "Loss: 0.425821989774704\n",
      "Loss: 0.425229549407959\n",
      "Loss: 0.42581912875175476\n",
      "Loss: 0.42577624320983887\n",
      "Loss: 0.425386905670166\n",
      "Loss: 0.425447940826416\n",
      "Loss: 0.4253826141357422\n",
      "Loss: 0.4250344932079315\n",
      "Loss: 0.4248908460140228\n",
      "Loss: 0.4257994592189789\n",
      "Loss: 0.42500218749046326\n",
      "Loss: 0.4255494177341461\n",
      "Loss: 0.42544203996658325\n",
      "Loss: 0.42517563700675964\n",
      "Loss: 0.424500048160553\n",
      "Loss: 0.4255715012550354\n",
      "Loss: 0.4248717725276947\n",
      "Loss: 0.4247754216194153\n",
      "Loss: 0.4256543219089508\n",
      "Loss: 0.4250221252441406\n",
      "Loss: 0.4244687557220459\n",
      "Loss: 0.4256173074245453\n",
      "Loss: 0.4249531924724579\n",
      "Loss: 0.4243530333042145\n",
      "Loss: 0.4254825711250305\n",
      "Loss: 0.42493611574172974\n",
      "Loss: 0.42381033301353455\n",
      "Loss: 0.4255281984806061\n",
      "Loss: 0.42472514510154724\n",
      "Loss: 0.4238980710506439\n",
      "Loss: 0.42557117342948914\n",
      "Loss: 0.42480728030204773\n",
      "Loss: 0.4236709177494049\n",
      "Loss: 0.4254055917263031\n",
      "Loss: 0.4247381389141083\n",
      "Loss: 0.4232315123081207\n",
      "Loss: 0.4254336357116699\n",
      "Loss: 0.4246235489845276\n",
      "Loss: 0.4230530858039856\n",
      "Loss: 0.42539340257644653\n",
      "Loss: 0.42457881569862366\n",
      "Loss: 0.4227341115474701\n",
      "Loss: 0.42405304312705994\n",
      "Loss: 0.42440661787986755\n",
      "Loss: 0.4220729470252991\n",
      "Loss: 0.4338075816631317\n",
      "Loss: 0.4291023910045624\n",
      "Loss: 0.4279349446296692\n",
      "Loss: 0.4305996596813202\n",
      "Loss: 0.4227808117866516\n",
      "Loss: 0.4272685647010803\n",
      "Loss: 0.4219498634338379\n",
      "Loss: 0.43525075912475586\n",
      "Loss: 0.4251653254032135\n",
      "Loss: 0.43117672204971313\n",
      "Loss: 0.43107327818870544\n",
      "Loss: 0.43122830986976624\n",
      "Loss: 0.4305899739265442\n",
      "Loss: 0.42975932359695435\n",
      "Loss: 0.4352130889892578\n",
      "Loss: 0.4237689673900604\n",
      "Loss: 0.4333224296569824\n",
      "Loss: 0.437009334564209\n",
      "Loss: 0.44146308302879333\n",
      "Loss: 0.4405995309352875\n",
      "Loss: 0.43806192278862\n",
      "Loss: 0.437983900308609\n",
      "Loss: 0.43578240275382996\n",
      "Loss: 0.4368324279785156\n",
      "Loss: 0.43743377923965454\n",
      "Loss: 0.4370301365852356\n",
      "Loss: 0.437296599149704\n",
      "Loss: 0.43598148226737976\n",
      "Loss: 0.435284286737442\n",
      "Loss: 0.4350306987762451\n",
      "Loss: 0.43516770005226135\n",
      "Loss: 0.43496137857437134\n",
      "Loss: 0.43530845642089844\n",
      "Loss: 0.43514424562454224\n",
      "Loss: 0.434518426656723\n",
      "Loss: 0.4344049394130707\n",
      "Loss: 0.43361401557922363\n",
      "Loss: 0.4337310492992401\n",
      "Loss: 0.4336404800415039\n",
      "Loss: 0.43363887071609497\n",
      "Loss: 0.4336114525794983\n",
      "Loss: 0.43230924010276794\n",
      "Loss: 0.4315529763698578\n",
      "Loss: 0.4306733310222626\n",
      "Loss: 0.42934274673461914\n",
      "Loss: 0.4273117184638977\n",
      "Loss: 0.42867952585220337\n",
      "Loss: 0.4318626821041107\n",
      "Loss: 0.4336049258708954\n",
      "Loss: 0.4366453289985657\n",
      "Loss: 0.4354856014251709\n",
      "Loss: 0.43348851799964905\n",
      "Loss: 0.43237096071243286\n",
      "Loss: 0.43132758140563965\n",
      "Loss: 0.43102917075157166\n",
      "Loss: 0.43162956833839417\n",
      "Loss: 0.42946338653564453\n",
      "Loss: 0.4516158103942871\n",
      "Loss: 0.4338587820529938\n",
      "Loss: 0.4352879524230957\n",
      "Loss: 0.4429588317871094\n",
      "Loss: 0.4471568763256073\n",
      "Loss: 0.442864328622818\n",
      "Loss: 0.4390571713447571\n",
      "Loss: 0.43647947907447815\n",
      "Loss: 0.4337298572063446\n",
      "Loss: 0.4373631179332733\n",
      "Loss: 0.4389253258705139\n",
      "Loss: 0.4395983815193176\n",
      "Loss: 0.43875154852867126\n",
      "Loss: 0.4379103183746338\n",
      "Loss: 0.4358128607273102\n",
      "Loss: 0.4343477189540863\n",
      "Loss: 0.4346953332424164\n",
      "Loss: 0.43556639552116394\n",
      "Loss: 0.4364507794380188\n",
      "Loss: 0.43644386529922485\n",
      "Loss: 0.435549259185791\n",
      "Loss: 0.43418699502944946\n",
      "Loss: 0.43370911478996277\n",
      "Loss: 0.433826208114624\n",
      "Loss: 0.4345432221889496\n",
      "Loss: 0.4345208704471588\n",
      "Loss: 0.43373605608940125\n",
      "Loss: 0.4332504868507385\n",
      "Loss: 0.4330717623233795\n",
      "Loss: 0.4331028461456299\n",
      "Loss: 0.43314462900161743\n",
      "Loss: 0.43316397070884705\n",
      "Loss: 0.43297138810157776\n",
      "Loss: 0.4326709806919098\n",
      "Loss: 0.43239933252334595\n",
      "Loss: 0.4323025643825531\n",
      "Loss: 0.4323073923587799\n",
      "Loss: 0.4323280453681946\n",
      "Loss: 0.4321020245552063\n",
      "Loss: 0.43178173899650574\n",
      "Loss: 0.4310261905193329\n",
      "Loss: 0.4307684600353241\n",
      "Loss: 0.43074414134025574\n",
      "Loss: 0.43000683188438416\n",
      "Loss: 0.42995044589042664\n",
      "Loss: 0.4285927414894104\n",
      "Loss: 0.4271090626716614\n",
      "Loss: 0.43241262435913086\n",
      "Loss: 0.43141552805900574\n",
      "Loss: 0.4347773492336273\n",
      "Loss: 0.44073811173439026\n",
      "Loss: 0.4417073726654053\n",
      "Loss: 0.4393623471260071\n",
      "Loss: 0.4365668296813965\n",
      "Loss: 0.4355201721191406\n",
      "Loss: 0.4340244233608246\n",
      "Loss: 0.4346235692501068\n",
      "Loss: 0.43443164229393005\n",
      "Loss: 0.4338940680027008\n",
      "Loss: 0.43344685435295105\n",
      "Loss: 0.4334418475627899\n",
      "Loss: 0.43302980065345764\n",
      "Loss: 0.43366503715515137\n",
      "Loss: 0.43382006883621216\n",
      "Loss: 0.4336977005004883\n",
      "Loss: 0.4337519705295563\n",
      "Loss: 0.4334051311016083\n",
      "Loss: 0.4329589903354645\n",
      "Loss: 0.4326169490814209\n",
      "Loss: 0.4323279857635498\n",
      "Loss: 0.43195438385009766\n",
      "Loss: 0.43193578720092773\n",
      "Loss: 0.4318476617336273\n",
      "Loss: 0.4318080544471741\n",
      "Loss: 0.4317696988582611\n",
      "Loss: 0.4317595660686493\n",
      "Loss: 0.4316409230232239\n",
      "Loss: 0.43170902132987976\n",
      "Loss: 0.431744247674942\n",
      "Loss: 0.4316904544830322\n",
      "Loss: 0.4316217601299286\n",
      "Loss: 0.4315631091594696\n",
      "Loss: 0.43144065141677856\n",
      "Loss: 0.4311642646789551\n",
      "Loss: 0.43057987093925476\n",
      "Loss: 0.4304954707622528\n",
      "Loss: 0.43034037947654724\n",
      "Loss: 0.4300966262817383\n",
      "Loss: 0.430119127035141\n",
      "Loss: 0.4299619197845459\n",
      "Loss: 0.42978373169898987\n",
      "Loss: 0.4295136034488678\n",
      "Loss: 0.4270051419734955\n",
      "Loss: 0.4307214319705963\n",
      "Loss: 0.4316493570804596\n",
      "Loss: 0.43557658791542053\n",
      "Loss: 0.43933987617492676\n",
      "Loss: 0.4395773410797119\n",
      "Loss: 0.43807268142700195\n",
      "Loss: 0.4340638220310211\n",
      "Loss: 0.43366703391075134\n",
      "Loss: 0.4343373775482178\n",
      "Loss: 0.4346866309642792\n",
      "Loss: 0.4352608323097229\n",
      "Loss: 0.4344661831855774\n",
      "Loss: 0.4332399368286133\n",
      "Loss: 0.43245455622673035\n",
      "Loss: 0.4322468936443329\n",
      "Loss: 0.4323202669620514\n",
      "Loss: 0.4328480362892151\n",
      "Loss: 0.4331822395324707\n",
      "Loss: 0.4329175055027008\n",
      "Loss: 0.43239814043045044\n",
      "Loss: 0.43217936158180237\n",
      "Loss: 0.43197932839393616\n",
      "Loss: 0.43199214339256287\n",
      "Loss: 0.4321351945400238\n",
      "Loss: 0.4322715401649475\n",
      "Loss: 0.4321077764034271\n",
      "Loss: 0.4318905770778656\n",
      "Loss: 0.4316905438899994\n",
      "Loss: 0.4315250813961029\n",
      "Loss: 0.43140172958374023\n",
      "Loss: 0.4314349293708801\n",
      "Loss: 0.4314913749694824\n",
      "Loss: 0.43147459626197815\n",
      "Loss: 0.43141433596611023\n",
      "Loss: 0.43133702874183655\n",
      "Loss: 0.43122759461402893\n",
      "Loss: 0.4311716556549072\n",
      "Loss: 0.43119335174560547\n",
      "Loss: 0.4312211573123932\n",
      "Loss: 0.43123307824134827\n",
      "Loss: 0.43123432993888855\n",
      "Loss: 0.4311809539794922\n",
      "Loss: 0.4311281144618988\n",
      "Loss: 0.43110328912734985\n",
      "Loss: 0.43109211325645447\n",
      "Loss: 0.4310935139656067\n",
      "Loss: 0.43110400438308716\n",
      "Loss: 0.43108177185058594\n",
      "Loss: 0.4310533106327057\n",
      "Loss: 0.4310227930545807\n",
      "Loss: 0.43099555373191833\n",
      "Loss: 0.43098244071006775\n",
      "Loss: 0.43098345398902893\n",
      "Loss: 0.4309755265712738\n",
      "Loss: 0.43096333742141724\n",
      "Loss: 0.4309441149234772\n",
      "Loss: 0.4309212863445282\n",
      "Loss: 0.4309022128582001\n",
      "Loss: 0.43089398741722107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4308857023715973\n",
      "Loss: 0.43087682127952576\n",
      "Loss: 0.43086716532707214\n",
      "Loss: 0.4308602511882782\n",
      "Loss: 0.4308500289916992\n",
      "Loss: 0.4308426082134247\n",
      "Loss: 0.43083611130714417\n",
      "Loss: 0.43082910776138306\n",
      "Loss: 0.43082156777381897\n",
      "Loss: 0.43081504106521606\n",
      "Loss: 0.4308067858219147\n",
      "Loss: 0.4307992160320282\n",
      "Loss: 0.4307912290096283\n",
      "Loss: 0.4307463765144348\n",
      "Loss: 0.43044567108154297\n",
      "Loss: 0.4302522838115692\n",
      "Loss: 0.4302145540714264\n",
      "Loss: 0.43021222949028015\n",
      "Loss: 0.4301634728908539\n",
      "Loss: 0.4300857484340668\n",
      "Loss: 0.4299876391887665\n",
      "Loss: 0.42953696846961975\n",
      "Loss: 0.4292953908443451\n",
      "Loss: 0.4292401373386383\n",
      "Loss: 0.4292328357696533\n",
      "Loss: 0.4291853606700897\n",
      "Loss: 0.42911654710769653\n",
      "Loss: 0.4288499057292938\n",
      "Loss: 0.4262668788433075\n",
      "Loss: 0.43281012773513794\n",
      "Loss: 0.43223172426223755\n",
      "Loss: 0.435034841299057\n",
      "Loss: 0.4402187764644623\n",
      "Loss: 0.44090184569358826\n",
      "Loss: 0.43937644362449646\n",
      "Loss: 0.4348908066749573\n",
      "Loss: 0.43414339423179626\n",
      "Loss: 0.43311840295791626\n",
      "Loss: 0.43350887298583984\n",
      "Loss: 0.4354492127895355\n",
      "Loss: 0.4352082908153534\n",
      "Loss: 0.43509531021118164\n",
      "Loss: 0.4340085983276367\n",
      "Loss: 0.43377548456192017\n",
      "Loss: 0.4331434369087219\n",
      "Loss: 0.4335181415081024\n",
      "Loss: 0.43364962935447693\n",
      "Loss: 0.4332147240638733\n",
      "Loss: 0.4332675039768219\n",
      "Loss: 0.43281587958335876\n",
      "Loss: 0.43268510699272156\n",
      "Loss: 0.43221697211265564\n",
      "Loss: 0.43213769793510437\n",
      "Loss: 0.4322132170200348\n",
      "Loss: 0.4321298599243164\n",
      "Loss: 0.4323123097419739\n",
      "Loss: 0.43213969469070435\n",
      "Loss: 0.4319295883178711\n",
      "Loss: 0.43159720301628113\n",
      "Loss: 0.4314112365245819\n",
      "Loss: 0.4314699172973633\n",
      "Loss: 0.43130573630332947\n",
      "Loss: 0.4313342571258545\n",
      "Loss: 0.43125078082084656\n",
      "Loss: 0.4311632215976715\n",
      "Loss: 0.4310474395751953\n",
      "Loss: 0.43092823028564453\n",
      "Loss: 0.4308912456035614\n",
      "Loss: 0.43030738830566406\n",
      "Loss: 0.4303707778453827\n",
      "Loss: 0.43039342761039734\n",
      "Loss: 0.4303850829601288\n",
      "Loss: 0.42993101477622986\n",
      "Loss: 0.4295313060283661\n",
      "Loss: 0.4293517768383026\n",
      "Loss: 0.4292432963848114\n",
      "Loss: 0.4292139708995819\n",
      "Loss: 0.4291907250881195\n",
      "Loss: 0.4292363226413727\n",
      "Loss: 0.42917394638061523\n",
      "Loss: 0.42920494079589844\n",
      "Loss: 0.4290061593055725\n",
      "Loss: 0.42681318521499634\n",
      "Loss: 0.4489103853702545\n",
      "Loss: 0.4334718883037567\n",
      "Loss: 0.4390893578529358\n",
      "Loss: 0.444016695022583\n",
      "Loss: 0.44465571641921997\n",
      "Loss: 0.44391727447509766\n",
      "Loss: 0.4389088749885559\n",
      "Loss: 0.4353877604007721\n",
      "Loss: 0.43693748116493225\n",
      "Loss: 0.43523940443992615\n",
      "Loss: 0.43682727217674255\n",
      "Loss: 0.4381117820739746\n",
      "Loss: 0.43622827529907227\n",
      "Loss: 0.43609681725502014\n",
      "Loss: 0.4346526265144348\n",
      "Loss: 0.43448325991630554\n",
      "Loss: 0.43448376655578613\n",
      "Loss: 0.43452006578445435\n",
      "Loss: 0.4357818067073822\n",
      "Loss: 0.4353233277797699\n",
      "Loss: 0.4347855746746063\n",
      "Loss: 0.433960497379303\n",
      "Loss: 0.4333251416683197\n",
      "Loss: 0.43317294120788574\n",
      "Loss: 0.4330931305885315\n",
      "Loss: 0.4332641065120697\n",
      "Loss: 0.43326225876808167\n",
      "Loss: 0.4329527020454407\n",
      "Loss: 0.4328523278236389\n",
      "Loss: 0.43258604407310486\n",
      "Loss: 0.43243226408958435\n",
      "Loss: 0.43244943022727966\n",
      "Loss: 0.43244919180870056\n",
      "Loss: 0.4324363172054291\n",
      "Loss: 0.4323189854621887\n",
      "Loss: 0.43224191665649414\n",
      "Loss: 0.43212124705314636\n",
      "Loss: 0.4318758547306061\n",
      "Loss: 0.4317193627357483\n",
      "Loss: 0.43158942461013794\n",
      "Loss: 0.4315025508403778\n",
      "Loss: 0.43144121766090393\n",
      "Loss: 0.4313977360725403\n",
      "Loss: 0.43135061860084534\n",
      "Loss: 0.4312179684638977\n",
      "Loss: 0.43112045526504517\n",
      "Loss: 0.4310511648654938\n",
      "Loss: 0.43099212646484375\n",
      "Loss: 0.4309506416320801\n",
      "Loss: 0.43097057938575745\n",
      "Loss: 0.4309554100036621\n",
      "Loss: 0.4308817386627197\n",
      "Loss: 0.43084651231765747\n",
      "Loss: 0.4308205246925354\n",
      "Loss: 0.43078622221946716\n",
      "Loss: 0.43075570464134216\n",
      "Loss: 0.43078580498695374\n",
      "Loss: 0.43079814314842224\n",
      "Loss: 0.43076545000076294\n",
      "Loss: 0.43071627616882324\n",
      "Loss: 0.43070903420448303\n",
      "Loss: 0.4306812286376953\n",
      "Loss: 0.4306267201900482\n",
      "Loss: 0.43052369356155396\n",
      "Loss: 0.43062010407447815\n",
      "Loss: 0.4307004511356354\n",
      "Loss: 0.43067073822021484\n",
      "Loss: 0.43050262331962585\n",
      "Loss: 0.43048912286758423\n",
      "Loss: 0.4305875897407532\n",
      "Loss: 0.4306057393550873\n",
      "Loss: 0.43054085969924927\n",
      "Loss: 0.43038806319236755\n",
      "Loss: 0.4304695129394531\n",
      "Loss: 0.4304969310760498\n",
      "Loss: 0.4304828345775604\n",
      "Loss: 0.4302888512611389\n",
      "Loss: 0.4304523169994354\n",
      "Loss: 0.43042635917663574\n",
      "Loss: 0.4305478036403656\n",
      "Loss: 0.4303950369358063\n",
      "Loss: 0.43041905760765076\n",
      "Loss: 0.4302697777748108\n",
      "Loss: 0.4304482936859131\n",
      "Loss: 0.43031126260757446\n",
      "Loss: 0.4304339587688446\n",
      "Loss: 0.43021494150161743\n",
      "Loss: 0.43045663833618164\n",
      "Loss: 0.43037205934524536\n",
      "Loss: 0.430474191904068\n",
      "Loss: 0.43034178018569946\n",
      "Loss: 0.43029385805130005\n",
      "Loss: 0.4302116334438324\n",
      "Loss: 0.43027740716934204\n",
      "Loss: 0.4302414059638977\n",
      "Loss: 0.43016862869262695\n",
      "Loss: 0.4301302134990692\n",
      "Loss: 0.4301491677761078\n",
      "Loss: 0.430094450712204\n",
      "Loss: 0.4302181303501129\n",
      "Loss: 0.430103600025177\n",
      "Loss: 0.4300737977027893\n",
      "Loss: 0.4301608204841614\n",
      "Loss: 0.43018147349357605\n",
      "Loss: 0.43014732003211975\n",
      "Loss: 0.43008795380592346\n",
      "Loss: 0.43010756373405457\n",
      "Loss: 0.4301447868347168\n",
      "Loss: 0.43010401725769043\n",
      "Loss: 0.4302941858768463\n",
      "Loss: 0.4300456941127777\n",
      "Loss: 0.4300622045993805\n",
      "Loss: 0.42996320128440857\n",
      "Loss: 0.43020230531692505\n",
      "Loss: 0.430029958486557\n",
      "Loss: 0.4301985800266266\n",
      "Loss: 0.42994388937950134\n",
      "Loss: 0.43004241585731506\n",
      "Loss: 0.4299636483192444\n",
      "Loss: 0.4299681782722473\n",
      "Loss: 0.43000054359436035\n",
      "Loss: 0.4299662113189697\n",
      "Loss: 0.4299148619174957\n",
      "Loss: 0.42965051531791687\n",
      "Loss: 0.4298055171966553\n",
      "Loss: 0.4296848475933075\n",
      "Loss: 0.4296826422214508\n",
      "Loss: 0.42960405349731445\n",
      "Loss: 0.4295685887336731\n",
      "Loss: 0.4295840263366699\n",
      "Loss: 0.42939844727516174\n",
      "Loss: 0.4295573830604553\n",
      "Loss: 0.42925140261650085\n",
      "Loss: 0.42938539385795593\n",
      "Loss: 0.42921921610832214\n",
      "Loss: 0.42940232157707214\n",
      "Loss: 0.42915159463882446\n",
      "Loss: 0.42957860231399536\n",
      "Loss: 0.4291245937347412\n",
      "Loss: 0.4295904338359833\n",
      "Loss: 0.42913857102394104\n",
      "Loss: 0.4291628897190094\n",
      "Loss: 0.42866334319114685\n",
      "Loss: 0.429369181394577\n",
      "Loss: 0.42870283126831055\n",
      "Loss: 0.42892247438430786\n",
      "Loss: 0.4284941852092743\n",
      "Loss: 0.4286598265171051\n",
      "Loss: 0.4283563196659088\n",
      "Loss: 0.4284837245941162\n",
      "Loss: 0.4283985197544098\n",
      "Loss: 0.4283529818058014\n",
      "Loss: 0.42823049426078796\n",
      "Loss: 0.42801758646965027\n",
      "Loss: 0.42792877554893494\n",
      "Loss: 0.4279828667640686\n",
      "Loss: 0.42796269059181213\n",
      "Loss: 0.42782852053642273\n",
      "Loss: 0.42788171768188477\n",
      "Loss: 0.4279286563396454\n",
      "Loss: 0.42796969413757324\n",
      "Loss: 0.4277960956096649\n",
      "Loss: 0.42769813537597656\n",
      "Loss: 0.4278857707977295\n",
      "Loss: 0.4278021454811096\n",
      "Loss: 0.4277799725532532\n",
      "Loss: 0.4277559816837311\n",
      "Loss: 0.42752858996391296\n",
      "Loss: 0.4275282025337219\n",
      "Loss: 0.4275638163089752\n",
      "Loss: 0.42725619673728943\n",
      "Loss: 0.4255227744579315\n",
      "Loss: 0.4420461356639862\n",
      "Loss: 0.4326595366001129\n",
      "Loss: 0.4355832040309906\n",
      "Loss: 0.44002652168273926\n",
      "Loss: 0.44232073426246643\n",
      "Loss: 0.43926188349723816\n",
      "Loss: 0.43855246901512146\n",
      "Loss: 0.43405023217201233\n",
      "Loss: 0.4354911744594574\n",
      "Loss: 0.4356409013271332\n",
      "Loss: 0.4347756505012512\n",
      "Loss: 0.43692395091056824\n",
      "Loss: 0.43630725145339966\n",
      "Loss: 0.43380483984947205\n",
      "Loss: 0.4341321885585785\n",
      "Loss: 0.43346744775772095\n",
      "Loss: 0.43245741724967957\n",
      "Loss: 0.43346014618873596\n",
      "Loss: 0.43380412459373474\n",
      "Loss: 0.4331945478916168\n",
      "Loss: 0.43325814604759216\n",
      "Loss: 0.4320478141307831\n",
      "Loss: 0.43268346786499023\n",
      "Loss: 0.4317176938056946\n",
      "Loss: 0.4317290484905243\n",
      "Loss: 0.43188339471817017\n",
      "Loss: 0.4313068389892578\n",
      "Loss: 0.43145376443862915\n",
      "Loss: 0.43106624484062195\n",
      "Loss: 0.4310672879219055\n",
      "Loss: 0.43045854568481445\n",
      "Loss: 0.430548757314682\n",
      "Loss: 0.43006953597068787\n",
      "Loss: 0.430124968290329\n",
      "Loss: 0.43017226457595825\n",
      "Loss: 0.4300598204135895\n",
      "Loss: 0.4299549162387848\n",
      "Loss: 0.4295661151409149\n",
      "Loss: 0.42952805757522583\n",
      "Loss: 0.4295984208583832\n",
      "Loss: 0.4295181930065155\n",
      "Loss: 0.4292125403881073\n",
      "Loss: 0.42905402183532715\n",
      "Loss: 0.42903247475624084\n",
      "Loss: 0.429103821516037\n",
      "Loss: 0.4290767312049866\n",
      "Loss: 0.4287983477115631\n",
      "Loss: 0.4291086196899414\n",
      "Loss: 0.42878714203834534\n",
      "Loss: 0.4292992651462555\n",
      "Loss: 0.42904138565063477\n",
      "Loss: 0.42906761169433594\n",
      "Loss: 0.4291260242462158\n",
      "Loss: 0.4286493957042694\n",
      "Loss: 0.4287247657775879\n",
      "Loss: 0.4287126660346985\n",
      "Loss: 0.4287246763706207\n",
      "Loss: 0.4284277856349945\n",
      "Loss: 0.42830386757850647\n",
      "Loss: 0.4282810688018799\n",
      "Loss: 0.42852869629859924\n",
      "Loss: 0.42824050784111023\n",
      "Loss: 0.4281788766384125\n",
      "Loss: 0.4276794493198395\n",
      "Loss: 0.4278431832790375\n",
      "Loss: 0.42758890986442566\n",
      "Loss: 0.4277295768260956\n",
      "Loss: 0.4275369644165039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4279020428657532\n",
      "Loss: 0.4272925555706024\n",
      "Loss: 0.42729830741882324\n",
      "Loss: 0.4272356927394867\n",
      "Loss: 0.42707759141921997\n",
      "Loss: 0.42702850699424744\n",
      "Loss: 0.42700520157814026\n",
      "Loss: 0.4270939528942108\n",
      "Loss: 0.42723575234413147\n",
      "Loss: 0.4271114766597748\n",
      "Loss: 0.427308052778244\n",
      "Loss: 0.42694613337516785\n",
      "Loss: 0.42721039056777954\n",
      "Loss: 0.4271722435951233\n",
      "Loss: 0.4271012842655182\n",
      "Loss: 0.42742329835891724\n",
      "Loss: 0.4273340702056885\n",
      "Loss: 0.42786332964897156\n",
      "Loss: 0.42699310183525085\n",
      "Loss: 0.4273781478404999\n",
      "Loss: 0.4274516999721527\n",
      "Loss: 0.42731761932373047\n",
      "Loss: 0.42686089873313904\n",
      "Loss: 0.4427924156188965\n",
      "Loss: 0.4347112774848938\n",
      "Loss: 0.4398256838321686\n",
      "Loss: 0.44024354219436646\n",
      "Loss: 0.4473641812801361\n",
      "Loss: 0.4431036114692688\n",
      "Loss: 0.43939897418022156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fef08610b70>]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# repeatedly learning on same set of training data to make sure loss goes down\n",
    "# temp_loss = []\n",
    "\n",
    "for x in range(1000):\n",
    "    temp_curr_loss = update_step(input_tr, target_tr)[1].numpy()\n",
    "    print(f\"Loss: {temp_curr_loss}\")\n",
    "    temp_loss.append(temp_curr_loss)\n",
    "plt.plot(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%time\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 20\n",
    "\n",
    "\n",
    "# for epoch in range(1000):\n",
    "#     total_loss = 0.\n",
    "#     num_batches = 0\n",
    "    \n",
    "#     for _ in range(num_training_iterations):\n",
    "#         input_tr, target_tr = next(training_data)\n",
    "#         total_loss += update_step(input_tr, target_tr)[1].numpy()\n",
    "#         num_batches += 1\n",
    "        \n",
    "#     loss_tr = total_loss / num_batches\n",
    "#     losses_tr.append(loss_tr)\n",
    "#     print(f\"Epoch: {epoch}\\tLoss value: {loss_tr}\")\n",
    "\n",
    "current_loss_list = []\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for data in train_graphs:\n",
    "        input_tr, target_tr = data\n",
    "        if input_tr is None:\n",
    "                continue\n",
    "        input_list.append(input_tr)\n",
    "        target_list.append(target_tr)\n",
    "        if len(input_list) >= batch_size:\n",
    "            input_tr = utils_tf.concat(input_list, axis=0)\n",
    "            target_tr = utils_tf.concat(target_list, axis=0)\n",
    "            \n",
    "            current_loss = update_step(input_tr, target_tr)[1].numpy()\n",
    "            total_loss += current_loss\n",
    "            \n",
    "            if num_batches % 10 == 0:\n",
    "                current_loss_list.append(current_loss)\n",
    "            \n",
    "            num_batches += 1\n",
    "            input_list = []\n",
    "            target_list = []\n",
    "            \n",
    "            # TODO add a checkpoint > save to disk\n",
    "    \n",
    "    loss_tr = total_loss / num_batches\n",
    "    losses_tr.append(loss_tr)\n",
    "    print(f\"Epoch: {epoch}\\tLoss value: {loss_tr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "weird-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(50, 1), dtype=float32)\n",
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(50, 1), dtype=float32)\n",
      "Epoch: 0\tLoss value: 0.49295697572903757\n",
      "Epoch: 1\tLoss value: 0.4878536880321992\n",
      "Epoch: 2\tLoss value: 0.4865094287884541\n",
      "Epoch: 3\tLoss value: 0.4854474787834363\n",
      "Epoch: 4\tLoss value: 0.48516649927848426\n",
      "Epoch: 5\tLoss value: 0.4853911560315352\n",
      "Epoch: 6\tLoss value: 0.485092571301338\n",
      "Epoch: 7\tLoss value: 0.48631673473578235\n",
      "Epoch: 8\tLoss value: 0.484667463975075\n",
      "Epoch: 9\tLoss value: 0.48421433363205346\n",
      "Epoch: 10\tLoss value: 0.48594900018129594\n",
      "Epoch: 11\tLoss value: 0.48769371121357646\n",
      "Epoch: 12\tLoss value: 0.485363860191443\n",
      "Epoch: 13\tLoss value: 0.48416494378676783\n",
      "Epoch: 14\tLoss value: 0.4836915204158196\n",
      "Epoch: 15\tLoss value: 0.4833322110848549\n",
      "Epoch: 16\tLoss value: 0.4836077070847536\n",
      "Epoch: 17\tLoss value: 0.48376728498018706\n",
      "Epoch: 18\tLoss value: 0.48352696975072224\n",
      "Epoch: 19\tLoss value: 0.48349216720996757\n",
      "Epoch: 20\tLoss value: 0.4835755510513599\n",
      "Epoch: 21\tLoss value: 0.48330931733816096\n",
      "Epoch: 22\tLoss value: 0.48371778640991603\n",
      "Epoch: 23\tLoss value: 0.48441963033798413\n",
      "Epoch: 24\tLoss value: 0.48421384930610656\n",
      "Epoch: 25\tLoss value: 0.4835868199972006\n",
      "Epoch: 26\tLoss value: 0.48440785768704536\n",
      "Epoch: 27\tLoss value: 0.4859290302716769\n",
      "Epoch: 28\tLoss value: 0.4851709144237714\n",
      "Epoch: 29\tLoss value: 0.48379814533086923\n",
      "Epoch: 30\tLoss value: 0.48497509678204853\n",
      "Epoch: 31\tLoss value: 0.4836074922635005\n",
      "Epoch: 32\tLoss value: 0.4831192054504003\n",
      "Epoch: 33\tLoss value: 0.48328299005826314\n",
      "Epoch: 34\tLoss value: 0.4833028800670917\n",
      "Epoch: 35\tLoss value: 0.4832471039661994\n",
      "Epoch: 36\tLoss value: 0.48326639899840723\n",
      "Epoch: 37\tLoss value: 0.48333557098339763\n",
      "Epoch: 38\tLoss value: 0.48276302242890384\n",
      "Epoch: 39\tLoss value: 0.48291972261208754\n",
      "Epoch: 40\tLoss value: 0.4829684915603735\n",
      "Epoch: 41\tLoss value: 0.48316815229562615\n",
      "Epoch: 42\tLoss value: 0.48278462963226515\n",
      "Epoch: 43\tLoss value: 0.48272940510358564\n",
      "Epoch: 44\tLoss value: 0.4828490555592072\n",
      "Epoch: 45\tLoss value: 0.48265559890331367\n",
      "Epoch: 46\tLoss value: 0.48272091932785816\n",
      "Epoch: 47\tLoss value: 0.4829267897361364\n",
      "Epoch: 48\tLoss value: 0.4827721982735854\n",
      "Epoch: 49\tLoss value: 0.48273866042112695\n",
      "Epoch: 50\tLoss value: 0.48268644708853503\n",
      "Epoch: 51\tLoss value: 0.48261801469020355\n",
      "Epoch: 52\tLoss value: 0.48259434507443355\n",
      "Epoch: 53\tLoss value: 0.4825828823982141\n",
      "Epoch: 54\tLoss value: 0.4825056667816945\n",
      "Epoch: 55\tLoss value: 0.48259833488708886\n",
      "Epoch: 56\tLoss value: 0.4817424069918119\n",
      "Epoch: 57\tLoss value: 0.47541373320114916\n",
      "Epoch: 58\tLoss value: 0.47311461803240656\n",
      "Epoch: 59\tLoss value: 0.47292823794560557\n",
      "Epoch: 60\tLoss value: 0.47300516801002696\n",
      "Epoch: 61\tLoss value: 0.47262232098823936\n",
      "Epoch: 62\tLoss value: 0.47240064868560205\n",
      "Epoch: 63\tLoss value: 0.47227721559695707\n",
      "Epoch: 64\tLoss value: 0.4724602226110605\n",
      "Epoch: 65\tLoss value: 0.47225162096512624\n",
      "Epoch: 66\tLoss value: 0.47235405613214543\n",
      "Epoch: 67\tLoss value: 0.47231858391028186\n",
      "Epoch: 68\tLoss value: 0.472268143372658\n",
      "Epoch: 69\tLoss value: 0.4720808301216517\n",
      "Epoch: 70\tLoss value: 0.4720804920563331\n",
      "Epoch: 71\tLoss value: 0.4720471985217852\n",
      "Epoch: 72\tLoss value: 0.47214856306711833\n",
      "Epoch: 73\tLoss value: 0.47229937978279896\n",
      "Epoch: 74\tLoss value: 0.47207691654180867\n",
      "Epoch: 75\tLoss value: 0.47204490380409436\n",
      "Epoch: 76\tLoss value: 0.4720261778281285\n",
      "Epoch: 77\tLoss value: 0.472196095264875\n",
      "Epoch: 78\tLoss value: 0.47201145768165587\n",
      "Epoch: 79\tLoss value: 0.4719901554095439\n",
      "Epoch: 80\tLoss value: 0.4721320518163534\n",
      "Epoch: 81\tLoss value: 0.4719335041902004\n",
      "Epoch: 82\tLoss value: 0.47201419270955597\n",
      "Epoch: 83\tLoss value: 0.4720750663830684\n",
      "Epoch: 84\tLoss value: 0.471974389614203\n",
      "Epoch: 85\tLoss value: 0.4721334181687771\n",
      "Epoch: 86\tLoss value: 0.47220548247679683\n",
      "Epoch: 87\tLoss value: 0.4720703613452422\n",
      "Epoch: 88\tLoss value: 0.4721051350312355\n",
      "Epoch: 89\tLoss value: 0.47231257093258394\n",
      "Epoch: 90\tLoss value: 0.4719221964249244\n",
      "Epoch: 91\tLoss value: 0.4718533975038773\n",
      "Epoch: 92\tLoss value: 0.47191846673305216\n",
      "Epoch: 93\tLoss value: 0.47198541849087444\n",
      "Epoch: 94\tLoss value: 0.47202104048851207\n",
      "Epoch: 95\tLoss value: 0.47181117880038725\n",
      "Epoch: 96\tLoss value: 0.4720922745802464\n",
      "Epoch: 97\tLoss value: 0.4719993939460852\n",
      "Epoch: 98\tLoss value: 0.47187537278884495\n",
      "Epoch: 99\tLoss value: 0.47178793311119077\n",
      "Epoch: 100\tLoss value: 0.4717558961036878\n",
      "Epoch: 101\tLoss value: 0.47184684817607586\n",
      "Epoch: 102\tLoss value: 0.47184339511088835\n",
      "Epoch: 103\tLoss value: 0.47200679760712844\n",
      "Epoch: 104\tLoss value: 0.4715119904738206\n",
      "Epoch: 105\tLoss value: 0.47191010386515886\n",
      "Epoch: 106\tLoss value: 0.4720382910508376\n",
      "Epoch: 107\tLoss value: 0.47189181401179386\n",
      "Epoch: 108\tLoss value: 0.4720154504592602\n",
      "Epoch: 109\tLoss value: 0.47188450880539723\n",
      "Epoch: 110\tLoss value: 0.47179135050529086\n",
      "Epoch: 111\tLoss value: 0.4718797136270083\n",
      "Epoch: 112\tLoss value: 0.47227038863377696\n",
      "Epoch: 113\tLoss value: 0.4716238489823464\n",
      "Epoch: 114\tLoss value: 0.47177964993012256\n",
      "Epoch: 115\tLoss value: 0.47201495457918213\n",
      "Epoch: 116\tLoss value: 0.47220046162605284\n",
      "Epoch: 117\tLoss value: 0.471737927320676\n",
      "Epoch: 118\tLoss value: 0.47176068749183264\n",
      "Epoch: 119\tLoss value: 0.471602571224555\n",
      "Epoch: 120\tLoss value: 0.47161869302774084\n",
      "Epoch: 121\tLoss value: 0.47188096110637373\n",
      "Epoch: 122\tLoss value: 0.4717044911934779\n",
      "Epoch: 123\tLoss value: 0.47235898124866\n",
      "Epoch: 124\tLoss value: 0.47160807808240257\n",
      "Epoch: 125\tLoss value: 0.4716221416913546\n",
      "Epoch: 126\tLoss value: 0.4715922506038959\n",
      "Epoch: 127\tLoss value: 0.47157548473431515\n",
      "Epoch: 128\tLoss value: 0.4714974879607176\n",
      "Epoch: 129\tLoss value: 0.471650138206971\n",
      "Epoch: 130\tLoss value: 0.4718425604930291\n",
      "Epoch: 131\tLoss value: 0.47152097038733654\n",
      "Epoch: 132\tLoss value: 0.4715267027035738\n",
      "Epoch: 133\tLoss value: 0.4716707318257063\n",
      "Epoch: 134\tLoss value: 0.47146273814714873\n",
      "Epoch: 135\tLoss value: 0.47189100357202385\n",
      "Epoch: 136\tLoss value: 0.4716297428424542\n",
      "Epoch: 137\tLoss value: 0.4715613959080134\n",
      "Epoch: 138\tLoss value: 0.4716399464240441\n",
      "Epoch: 139\tLoss value: 0.4717146238913903\n",
      "Epoch: 140\tLoss value: 0.47159585766303236\n",
      "Epoch: 141\tLoss value: 0.47155525397031733\n",
      "Epoch: 142\tLoss value: 0.47174263859406496\n",
      "Epoch: 143\tLoss value: 0.4717192333478194\n",
      "Epoch: 144\tLoss value: 0.47202171851427127\n",
      "Epoch: 145\tLoss value: 0.4716315604478885\n",
      "Epoch: 146\tLoss value: 0.4715212264122107\n",
      "Epoch: 147\tLoss value: 0.47163340345407145\n",
      "Epoch: 148\tLoss value: 0.4715149118350102\n",
      "Epoch: 149\tLoss value: 0.4716710289625021\n",
      "Epoch: 150\tLoss value: 0.47134097408025694\n",
      "Epoch: 151\tLoss value: 0.47149279420192425\n",
      "Epoch: 152\tLoss value: 0.47144122218474366\n",
      "Epoch: 153\tLoss value: 0.47150338258498753\n",
      "Epoch: 154\tLoss value: 0.4715045120777228\n",
      "Epoch: 155\tLoss value: 0.47163216361632715\n",
      "Epoch: 156\tLoss value: 0.47342584527455844\n",
      "Epoch: 157\tLoss value: 0.4718217749473376\n",
      "Epoch: 158\tLoss value: 0.47164263419615915\n",
      "Epoch: 159\tLoss value: 0.4717700798694904\n",
      "Epoch: 160\tLoss value: 0.47172416613652157\n",
      "Epoch: 161\tLoss value: 0.4718489795770401\n",
      "Epoch: 162\tLoss value: 0.47178172560838555\n",
      "Epoch: 163\tLoss value: 0.4715960372105623\n",
      "Epoch: 164\tLoss value: 0.47167022344393605\n",
      "Epoch: 165\tLoss value: 0.47149006137481103\n",
      "Epoch: 166\tLoss value: 0.4715181244030977\n",
      "Epoch: 167\tLoss value: 0.4716294751717494\n",
      "Epoch: 168\tLoss value: 0.471257428756127\n",
      "Epoch: 169\tLoss value: 0.4714546717130221\n",
      "Epoch: 170\tLoss value: 0.4714924038984837\n",
      "Epoch: 171\tLoss value: 0.47157996520017964\n",
      "Epoch: 172\tLoss value: 0.47145427703857423\n",
      "Epoch: 173\tLoss value: 0.4715911135306725\n",
      "Epoch: 174\tLoss value: 0.47141575779670325\n",
      "Epoch: 175\tLoss value: 0.4715599101017683\n",
      "Epoch: 176\tLoss value: 0.4713519960794693\n",
      "Epoch: 177\tLoss value: 0.4714579048829201\n",
      "Epoch: 178\tLoss value: 0.4717467801998823\n",
      "Epoch: 179\tLoss value: 0.47144212753344805\n",
      "Epoch: 180\tLoss value: 0.471570582542664\n",
      "Epoch: 181\tLoss value: 0.47134858470696667\n",
      "Epoch: 182\tLoss value: 0.4715284567612868\n",
      "Epoch: 183\tLoss value: 0.47149360179901123\n",
      "Epoch: 184\tLoss value: 0.471423790424298\n",
      "Epoch: 185\tLoss value: 0.4713968835427211\n",
      "Epoch: 186\tLoss value: 0.47155340735728923\n",
      "Epoch: 187\tLoss value: 0.47136073188904004\n",
      "Epoch: 188\tLoss value: 0.4714631237433507\n",
      "Epoch: 189\tLoss value: 0.47139618781896736\n",
      "Epoch: 190\tLoss value: 0.4713358066632197\n",
      "Epoch: 191\tLoss value: 0.4713045911911206\n",
      "Epoch: 192\tLoss value: 0.4712825724711785\n",
      "Epoch: 193\tLoss value: 0.47138069345400885\n",
      "Epoch: 194\tLoss value: 0.4713877548315586\n",
      "Epoch: 195\tLoss value: 0.4713592192148551\n",
      "Epoch: 196\tLoss value: 0.4713686844935784\n",
      "Epoch: 197\tLoss value: 0.4714623317351708\n",
      "Epoch: 198\tLoss value: 0.47128142662537403\n",
      "Epoch: 199\tLoss value: 0.47138258765905333\n",
      "Epoch: 200\tLoss value: 0.471329079407912\n",
      "Epoch: 201\tLoss value: 0.4714445480933556\n",
      "Epoch: 202\tLoss value: 0.4714106443906442\n",
      "Epoch: 203\tLoss value: 0.4713454098884876\n",
      "Epoch: 204\tLoss value: 0.47134052242988195\n",
      "Epoch: 205\tLoss value: 0.4713047096362481\n",
      "Epoch: 206\tLoss value: 0.47131107590137383\n",
      "Epoch: 207\tLoss value: 0.471391901297447\n",
      "Epoch: 208\tLoss value: 0.47128181326083646\n",
      "Epoch: 209\tLoss value: 0.47132681146646155\n",
      "Epoch: 210\tLoss value: 0.4713107655904232\n",
      "Epoch: 211\tLoss value: 0.4712767688127664\n",
      "Epoch: 212\tLoss value: 0.4712773378690084\n",
      "Epoch: 213\tLoss value: 0.4712577267182179\n",
      "Epoch: 214\tLoss value: 0.4713211581034538\n",
      "Epoch: 215\tLoss value: 0.4713516015578539\n",
      "Epoch: 216\tLoss value: 0.47130757591663264\n",
      "Epoch: 217\tLoss value: 0.47131304603356583\n",
      "Epoch: 218\tLoss value: 0.47128707693173333\n",
      "Epoch: 219\tLoss value: 0.47126082374499395\n",
      "Epoch: 220\tLoss value: 0.4714610209831825\n",
      "Epoch: 221\tLoss value: 0.47132635079897367\n",
      "Epoch: 222\tLoss value: 0.4712961968091818\n",
      "Epoch: 223\tLoss value: 0.4714009347023108\n",
      "Epoch: 224\tLoss value: 0.471287392225021\n",
      "Epoch: 225\tLoss value: 0.4712222141485948\n",
      "Epoch: 226\tLoss value: 0.4712379558575459\n",
      "Epoch: 227\tLoss value: 0.47129521602239366\n",
      "Epoch: 228\tLoss value: 0.4711691520458613\n",
      "Epoch: 229\tLoss value: 0.4713517751143529\n",
      "Epoch: 230\tLoss value: 0.47124787834974435\n",
      "Epoch: 231\tLoss value: 0.4712894328129597\n",
      "Epoch: 232\tLoss value: 0.4712139296837342\n",
      "Epoch: 233\tLoss value: 0.4711937301281171\n",
      "Epoch: 234\tLoss value: 0.4711463074806409\n",
      "Epoch: 235\tLoss value: 0.4712565789161584\n",
      "Epoch: 236\tLoss value: 0.4712348924539028\n",
      "Epoch: 237\tLoss value: 0.4712373832555918\n",
      "Epoch: 238\tLoss value: 0.47159256644738023\n",
      "Epoch: 239\tLoss value: 0.4716643582551907\n",
      "Epoch: 240\tLoss value: 0.47239764283864927\n",
      "Epoch: 241\tLoss value: 0.47186565038485406\n",
      "Epoch: 242\tLoss value: 0.4711682276848035\n",
      "Epoch: 243\tLoss value: 0.47137512980363305\n",
      "Epoch: 244\tLoss value: 0.4713380169562804\n",
      "Epoch: 245\tLoss value: 0.47120502762305433\n",
      "Epoch: 246\tLoss value: 0.47118686581269287\n",
      "Epoch: 247\tLoss value: 0.47123899762447063\n",
      "Epoch: 248\tLoss value: 0.4725876624461932\n",
      "Epoch: 249\tLoss value: 0.4719514374549572\n",
      "Epoch: 250\tLoss value: 0.47199059553635425\n",
      "Epoch: 251\tLoss value: 0.47186631162961323\n",
      "Epoch: 252\tLoss value: 0.4719241570815062\n",
      "Epoch: 253\tLoss value: 0.4728389139664479\n",
      "Epoch: 254\tLoss value: 0.47172911384166816\n",
      "Epoch: 255\tLoss value: 0.47244584704056763\n",
      "Epoch: 256\tLoss value: 0.47147336336282586\n",
      "Epoch: 257\tLoss value: 0.4717290828166864\n",
      "Epoch: 258\tLoss value: 0.4716879729124216\n",
      "Epoch: 259\tLoss value: 0.47151470471651125\n",
      "Epoch: 260\tLoss value: 0.4715197057907398\n",
      "Epoch: 261\tLoss value: 0.47137515609080977\n",
      "Epoch: 262\tLoss value: 0.47186514567106197\n",
      "Epoch: 263\tLoss value: 0.47352063414378043\n",
      "Epoch: 264\tLoss value: 0.4717258224120507\n",
      "Epoch: 265\tLoss value: 0.4715856836697994\n",
      "Epoch: 266\tLoss value: 0.47144824990859396\n",
      "Epoch: 267\tLoss value: 0.4718404783041049\n",
      "Epoch: 268\tLoss value: 0.47134660445726834\n",
      "Epoch: 269\tLoss value: 0.4715216722855201\n",
      "Epoch: 270\tLoss value: 0.47161616423191166\n",
      "Epoch: 271\tLoss value: 0.4721764552287566\n",
      "Epoch: 272\tLoss value: 0.47144186343902195\n",
      "Epoch: 273\tLoss value: 0.4713799643822205\n",
      "Epoch: 274\tLoss value: 0.4712526200367854\n",
      "Epoch: 275\tLoss value: 0.47119483513709826\n",
      "Epoch: 276\tLoss value: 0.4712391178424542\n",
      "Epoch: 277\tLoss value: 0.4711612138687036\n",
      "Epoch: 278\tLoss value: 0.4713457378668663\n",
      "Epoch: 279\tLoss value: 0.4721385973539108\n",
      "Epoch: 280\tLoss value: 0.4712282925385695\n",
      "Epoch: 281\tLoss value: 0.4712373979580708\n",
      "Epoch: 282\tLoss value: 0.47128552947288904\n",
      "Epoch: 283\tLoss value: 0.47124612502562696\n",
      "Epoch: 284\tLoss value: 0.47128581031774863\n",
      "Epoch: 285\tLoss value: 0.471466564367979\n",
      "Epoch: 286\tLoss value: 0.4711994609465966\n",
      "Epoch: 287\tLoss value: 0.47182890892028806\n",
      "Epoch: 288\tLoss value: 0.47122426439554266\n",
      "Epoch: 289\tLoss value: 0.4712358225614597\n",
      "Epoch: 290\tLoss value: 0.47134381975883094\n",
      "Epoch: 291\tLoss value: 0.4713674384202713\n",
      "Epoch: 292\tLoss value: 0.47171255450982313\n",
      "Epoch: 293\tLoss value: 0.47189381388517526\n",
      "Epoch: 294\tLoss value: 0.4718394390741984\n",
      "Epoch: 295\tLoss value: 0.4719213010714604\n",
      "Epoch: 296\tLoss value: 0.47137692173322043\n",
      "Epoch: 297\tLoss value: 0.47118680984545974\n",
      "Epoch: 298\tLoss value: 0.4712042832068908\n",
      "Epoch: 299\tLoss value: 0.47149502775607965\n",
      "Epoch: 300\tLoss value: 0.47127872430361234\n",
      "Epoch: 301\tLoss value: 0.47119760118998016\n",
      "Epoch: 302\tLoss value: 0.47135211528875887\n",
      "Epoch: 303\tLoss value: 0.4712822308907142\n",
      "Epoch: 304\tLoss value: 0.4712947324300424\n",
      "Epoch: 305\tLoss value: 0.47126628142136795\n",
      "Epoch: 306\tLoss value: 0.47122455251522555\n",
      "Epoch: 307\tLoss value: 0.4712504859459706\n",
      "Epoch: 308\tLoss value: 0.47119532961111804\n",
      "Epoch: 309\tLoss value: 0.4712888910525884\n",
      "Epoch: 310\tLoss value: 0.4712701769669851\n",
      "Epoch: 311\tLoss value: 0.4712047659433805\n",
      "Epoch: 312\tLoss value: 0.47124361554781596\n",
      "Epoch: 313\tLoss value: 0.4714129813206501\n",
      "Epoch: 314\tLoss value: 0.47151835065621595\n",
      "Epoch: 315\tLoss value: 0.4712542105332399\n",
      "Epoch: 316\tLoss value: 0.47125375231107075\n",
      "Epoch: 317\tLoss value: 0.47119084391838467\n",
      "Epoch: 318\tLoss value: 0.47123485922813413\n",
      "Epoch: 319\tLoss value: 0.4718947282815591\n",
      "Epoch: 320\tLoss value: 0.47132658833112473\n",
      "Epoch: 321\tLoss value: 0.4711205469644987\n",
      "Epoch: 322\tLoss value: 0.47116298333192486\n",
      "Epoch: 323\tLoss value: 0.47112789860138526\n",
      "Epoch: 324\tLoss value: 0.4711912924509782\n",
      "Epoch: 325\tLoss value: 0.47110453510895756\n",
      "Epoch: 326\tLoss value: 0.4711290840002207\n",
      "Epoch: 327\tLoss value: 0.47117972725476975\n",
      "Epoch: 328\tLoss value: 0.47171887079874675\n",
      "Epoch: 329\tLoss value: 0.4724213640506451\n",
      "Epoch: 330\tLoss value: 0.4715683141427162\n",
      "Epoch: 331\tLoss value: 0.4712375209576044\n",
      "Epoch: 332\tLoss value: 0.4715110734792856\n",
      "Epoch: 333\tLoss value: 0.47123739211987226\n",
      "Epoch: 334\tLoss value: 0.4712262349862319\n",
      "Epoch: 335\tLoss value: 0.4712284076519502\n",
      "Epoch: 336\tLoss value: 0.4712173542609582\n",
      "Epoch: 337\tLoss value: 0.47125344138879044\n",
      "Epoch: 338\tLoss value: 0.4717935970807687\n",
      "Epoch: 339\tLoss value: 0.4713754028540391\n",
      "Epoch: 340\tLoss value: 0.47126474854273676\n",
      "Epoch: 341\tLoss value: 0.4712584443275745\n",
      "Epoch: 342\tLoss value: 0.4713192258431361\n",
      "Epoch: 343\tLoss value: 0.4712919447972224\n",
      "Epoch: 344\tLoss value: 0.47131073927268\n",
      "Epoch: 345\tLoss value: 0.4712577687777006\n",
      "Epoch: 346\tLoss value: 0.47129039238660764\n",
      "Epoch: 347\tLoss value: 0.4712395485853538\n",
      "Epoch: 348\tLoss value: 0.47133394537827905\n",
      "Epoch: 349\tLoss value: 0.4712719731147473\n",
      "Epoch: 350\tLoss value: 0.4712503283451765\n",
      "Epoch: 351\tLoss value: 0.47123092633027297\n",
      "Epoch: 352\tLoss value: 0.47120119703121677\n",
      "Epoch: 353\tLoss value: 0.4712228067104633\n",
      "Epoch: 354\tLoss value: 0.47123943937130464\n",
      "Epoch: 355\tLoss value: 0.47126049812023457\n",
      "Epoch: 356\tLoss value: 0.4713197252383599\n",
      "Epoch: 357\tLoss value: 0.47124998652018035\n",
      "Epoch: 358\tLoss value: 0.47121455987294514\n",
      "Epoch: 359\tLoss value: 0.4712973553706438\n",
      "Epoch: 360\tLoss value: 0.47129701987290995\n",
      "Epoch: 361\tLoss value: 0.47129337408603766\n",
      "Epoch: 362\tLoss value: 0.4716579016355368\n",
      "Epoch: 363\tLoss value: 0.47126140056512295\n",
      "Epoch: 364\tLoss value: 0.47126724295127087\n",
      "Epoch: 365\tLoss value: 0.47112787592105376\n",
      "Epoch: 366\tLoss value: 0.47114186736253594\n",
      "Epoch: 367\tLoss value: 0.47146761900339373\n",
      "Epoch: 368\tLoss value: 0.47106214025081733\n",
      "Epoch: 369\tLoss value: 0.471114690334369\n",
      "Epoch: 370\tLoss value: 0.47120376486044663\n",
      "Epoch: 371\tLoss value: 0.47122696613654114\n",
      "Epoch: 372\tLoss value: 0.47126086219763147\n",
      "Epoch: 373\tLoss value: 0.4714832945359059\n",
      "Epoch: 374\tLoss value: 0.4712071696917216\n",
      "Epoch: 375\tLoss value: 0.4712529643987998\n",
      "Epoch: 376\tLoss value: 0.47123369143559385\n",
      "Epoch: 377\tLoss value: 0.4711894616102561\n",
      "Epoch: 378\tLoss value: 0.47124832251133064\n",
      "Epoch: 379\tLoss value: 0.47119385089629734\n",
      "Epoch: 380\tLoss value: 0.4711968491933285\n",
      "Epoch: 381\tLoss value: 0.4714521109140836\n",
      "Epoch: 382\tLoss value: 0.4712428433772845\n",
      "Epoch: 383\tLoss value: 0.47132220161266813\n",
      "Epoch: 384\tLoss value: 0.47116268099882663\n",
      "Epoch: 385\tLoss value: 0.47116117336811164\n",
      "Epoch: 386\tLoss value: 0.47115212969290904\n",
      "Epoch: 387\tLoss value: 0.47114790176733945\n",
      "Epoch: 388\tLoss value: 0.4712791645526886\n",
      "Epoch: 389\tLoss value: 0.4711754169830909\n",
      "Epoch: 390\tLoss value: 0.4711653226766831\n",
      "Epoch: 391\tLoss value: 0.4711543816480881\n",
      "Epoch: 392\tLoss value: 0.4711559097889142\n",
      "Epoch: 393\tLoss value: 0.47143328798122897\n",
      "Epoch: 394\tLoss value: 0.47114211284197294\n",
      "Epoch: 395\tLoss value: 0.47111055918228933\n",
      "Epoch: 396\tLoss value: 0.47112185835838316\n",
      "Epoch: 397\tLoss value: 0.4712324796273158\n",
      "Epoch: 398\tLoss value: 0.4710939963352986\n",
      "Epoch: 399\tLoss value: 0.4711036997575026\n",
      "Epoch: 400\tLoss value: 0.4712904246342488\n",
      "Epoch: 401\tLoss value: 0.4718298612802457\n",
      "Epoch: 402\tLoss value: 0.47159487788493815\n",
      "Epoch: 403\tLoss value: 0.4712816962523338\n",
      "Epoch: 404\tLoss value: 0.4712367303860493\n",
      "Epoch: 405\tLoss value: 0.47144617416919804\n",
      "Epoch: 406\tLoss value: 0.47168060932403955\n",
      "Epoch: 407\tLoss value: 0.47112071853417614\n",
      "Epoch: 408\tLoss value: 0.4711949516259707\n",
      "Epoch: 409\tLoss value: 0.47115908237603993\n",
      "Epoch: 410\tLoss value: 0.4711799693718935\n",
      "Epoch: 411\tLoss value: 0.4711776682046743\n",
      "Epoch: 412\tLoss value: 0.47107223024735084\n",
      "Epoch: 413\tLoss value: 0.4710513293437469\n",
      "Epoch: 414\tLoss value: 0.4711134188603132\n",
      "Epoch: 415\tLoss value: 0.4716286293359903\n",
      "Epoch: 416\tLoss value: 0.4717231471416278\n",
      "Epoch: 417\tLoss value: 0.471368180391116\n",
      "Epoch: 418\tLoss value: 0.47182205887941214\n",
      "Epoch: 419\tLoss value: 0.4716612749221997\n",
      "Epoch: 420\tLoss value: 0.4714717705433185\n",
      "Epoch: 421\tLoss value: 0.47745879968007404\n",
      "Epoch: 422\tLoss value: 0.4715632887681325\n",
      "Epoch: 423\tLoss value: 0.471250142959448\n",
      "Epoch: 424\tLoss value: 0.4712023914777316\n",
      "Epoch: 425\tLoss value: 0.4712753634575086\n",
      "Epoch: 426\tLoss value: 0.47118532688189774\n",
      "Epoch: 427\tLoss value: 0.47119310895601907\n",
      "Epoch: 428\tLoss value: 0.4713118105668288\n",
      "Epoch: 429\tLoss value: 0.471264280692125\n",
      "Epoch: 430\tLoss value: 0.4711525885264079\n",
      "Epoch: 431\tLoss value: 0.47114572344682154\n",
      "Epoch: 432\tLoss value: 0.4711257289311825\n",
      "Epoch: 433\tLoss value: 0.47116398899983136\n",
      "Epoch: 434\tLoss value: 0.4711152476225144\n",
      "Epoch: 435\tLoss value: 0.47112321697748627\n",
      "Epoch: 436\tLoss value: 0.4711032260992588\n",
      "Epoch: 437\tLoss value: 0.4711854216685662\n",
      "Epoch: 438\tLoss value: 0.4712343143805479\n",
      "Epoch: 439\tLoss value: 0.4710935043065976\n",
      "Epoch: 440\tLoss value: 0.4711218974834833\n",
      "Epoch: 441\tLoss value: 0.4710959671399532\n",
      "Epoch: 442\tLoss value: 0.47113495939817185\n",
      "Epoch: 443\tLoss value: 0.471166816674746\n",
      "Epoch: 444\tLoss value: 0.4711488316609309\n",
      "Epoch: 445\tLoss value: 0.4711847450182988\n",
      "Epoch: 446\tLoss value: 0.47113564151983994\n",
      "Epoch: 447\tLoss value: 0.47112317580443164\n",
      "Epoch: 448\tLoss value: 0.4711514571385506\n",
      "Epoch: 449\tLoss value: 0.47110975830982893\n",
      "Epoch: 450\tLoss value: 0.47115125961792775\n",
      "Epoch: 451\tLoss value: 0.47111557957453604\n",
      "Epoch: 452\tLoss value: 0.47108484491323815\n",
      "Epoch: 453\tLoss value: 0.47111900008641755\n",
      "Epoch: 454\tLoss value: 0.4712454802867694\n",
      "Epoch: 455\tLoss value: 0.47111802892807203\n",
      "Epoch: 456\tLoss value: 0.4711368026183202\n",
      "Epoch: 457\tLoss value: 0.47114339275237843\n",
      "Epoch: 458\tLoss value: 0.47113828249466727\n",
      "Epoch: 459\tLoss value: 0.471182752878238\n",
      "Epoch: 460\tLoss value: 0.47115536799797647\n",
      "Epoch: 461\tLoss value: 0.4714952049194238\n",
      "Epoch: 462\tLoss value: 0.4713494569521684\n",
      "Epoch: 463\tLoss value: 0.47177285527571655\n",
      "Epoch: 464\tLoss value: 0.47235054856691605\n",
      "Epoch: 465\tLoss value: 0.47270588202354236\n",
      "Epoch: 466\tLoss value: 0.4721869891117781\n",
      "Epoch: 467\tLoss value: 0.47154788677509013\n",
      "Epoch: 468\tLoss value: 0.4711587235255119\n",
      "Epoch: 469\tLoss value: 0.471274783886396\n",
      "Epoch: 470\tLoss value: 0.4717674355323498\n",
      "Epoch: 471\tLoss value: 0.4716975181225019\n",
      "Epoch: 472\tLoss value: 0.47186547490266656\n",
      "Epoch: 473\tLoss value: 0.4715831263248737\n",
      "Epoch: 474\tLoss value: 0.47151240446628667\n",
      "Epoch: 475\tLoss value: 0.47141752826861844\n",
      "Epoch: 476\tLoss value: 0.4724804740685683\n",
      "Epoch: 477\tLoss value: 0.4717312634602571\n",
      "Epoch: 478\tLoss value: 0.4712687049462245\n",
      "Epoch: 479\tLoss value: 0.47139715925241127\n",
      "Epoch: 480\tLoss value: 0.47125165245471856\n",
      "Epoch: 481\tLoss value: 0.47197979110937854\n",
      "Epoch: 482\tLoss value: 0.4716963551288996\n",
      "Epoch: 483\tLoss value: 0.4715273606471526\n",
      "Epoch: 484\tLoss value: 0.4717069785411541\n",
      "Epoch: 485\tLoss value: 0.4720215503986065\n",
      "Epoch: 486\tLoss value: 0.47178265183399887\n",
      "Epoch: 487\tLoss value: 0.47140093014790463\n",
      "Epoch: 488\tLoss value: 0.4711269335563366\n",
      "Epoch: 489\tLoss value: 0.47118609834940006\n",
      "Epoch: 490\tLoss value: 0.47114375377312684\n",
      "Epoch: 491\tLoss value: 0.47118787854145733\n",
      "Epoch: 492\tLoss value: 0.4713505151027288\n",
      "Epoch: 493\tLoss value: 0.4711904243933849\n",
      "Epoch: 494\tLoss value: 0.47110445722555505\n",
      "Epoch: 495\tLoss value: 0.4711276605190375\n",
      "Epoch: 496\tLoss value: 0.47119062423706054\n",
      "Epoch: 497\tLoss value: 0.47113529920578\n",
      "Epoch: 498\tLoss value: 0.4711387150104229\n",
      "Epoch: 499\tLoss value: 0.4711718318095574\n",
      "Epoch: 500\tLoss value: 0.47105998546649247\n",
      "Epoch: 501\tLoss value: 0.47118560573993584\n",
      "Epoch: 502\tLoss value: 0.4709835994549287\n",
      "Epoch: 503\tLoss value: 0.47157969545095396\n",
      "Epoch: 504\tLoss value: 0.4711320097935505\n",
      "Epoch: 505\tLoss value: 0.4711491707349435\n",
      "Epoch: 506\tLoss value: 0.4710186700331859\n",
      "Epoch: 507\tLoss value: 0.47096228021841785\n",
      "Epoch: 508\tLoss value: 0.47107090537364665\n",
      "Epoch: 509\tLoss value: 0.47117091744374007\n",
      "Epoch: 510\tLoss value: 0.47108767772332216\n",
      "Epoch: 511\tLoss value: 0.47103157593653755\n",
      "Epoch: 512\tLoss value: 0.47100145196303345\n",
      "Epoch: 513\tLoss value: 0.4711130245220967\n",
      "Epoch: 514\tLoss value: 0.4710674094542479\n",
      "Epoch: 515\tLoss value: 0.4709723032132173\n",
      "Epoch: 516\tLoss value: 0.4710676789895082\n",
      "Epoch: 517\tLoss value: 0.47101930985083945\n",
      "Epoch: 518\tLoss value: 0.47117123068907324\n",
      "Epoch: 519\tLoss value: 0.47113941009228044\n",
      "Epoch: 520\tLoss value: 0.4711312975027622\n",
      "Epoch: 521\tLoss value: 0.4710365771635985\n",
      "Epoch: 522\tLoss value: 0.47092735587022244\n",
      "Epoch: 523\tLoss value: 0.4711518459442334\n",
      "Epoch: 524\tLoss value: 0.47102148526754134\n",
      "Epoch: 525\tLoss value: 0.47366026257857297\n",
      "Epoch: 526\tLoss value: 0.4716408786101219\n",
      "Epoch: 527\tLoss value: 0.47125097173910874\n",
      "Epoch: 528\tLoss value: 0.47170281691428945\n",
      "Epoch: 529\tLoss value: 0.47139639875827694\n",
      "Epoch: 530\tLoss value: 0.4712604541044969\n",
      "Epoch: 531\tLoss value: 0.47113969689760454\n",
      "Epoch: 532\tLoss value: 0.4711174161923237\n",
      "Epoch: 533\tLoss value: 0.4710387765138577\n",
      "Epoch: 534\tLoss value: 0.4710381053349911\n",
      "Epoch: 535\tLoss value: 0.47102271993954975\n",
      "Epoch: 536\tLoss value: 0.47120837098512897\n",
      "Epoch: 537\tLoss value: 0.4710427621083382\n",
      "Epoch: 538\tLoss value: 0.4710792618531447\n",
      "Epoch: 539\tLoss value: 0.471448466869501\n",
      "Epoch: 540\tLoss value: 0.47157892688726766\n",
      "Epoch: 541\tLoss value: 0.47124574529819\n",
      "Epoch: 542\tLoss value: 0.47128940573105443\n",
      "Epoch: 543\tLoss value: 0.47114606814506726\n",
      "Epoch: 544\tLoss value: 0.4712167040201334\n",
      "Epoch: 545\tLoss value: 0.47122207277860395\n",
      "Epoch: 546\tLoss value: 0.4711554285501822\n",
      "Epoch: 547\tLoss value: 0.4710894327897292\n",
      "Epoch: 548\tLoss value: 0.4711718598084572\n",
      "Epoch: 549\tLoss value: 0.47104828745890887\n",
      "Epoch: 550\tLoss value: 0.47141830719434297\n",
      "Epoch: 551\tLoss value: 0.47166763965900127\n",
      "Epoch: 552\tLoss value: 0.4711369356742272\n",
      "Epoch: 553\tLoss value: 0.47141073434780806\n",
      "Epoch: 554\tLoss value: 0.4713078854022882\n",
      "Epoch: 555\tLoss value: 0.4711854769327702\n",
      "Epoch: 556\tLoss value: 0.4711937546730042\n",
      "Epoch: 557\tLoss value: 0.4712771155589666\n",
      "Epoch: 558\tLoss value: 0.4712321736262395\n",
      "Epoch: 559\tLoss value: 0.47123346285942275\n",
      "Epoch: 560\tLoss value: 0.47112632509989616\n",
      "Epoch: 561\tLoss value: 0.4711576260664524\n",
      "Epoch: 562\tLoss value: 0.4711454452918126\n",
      "Epoch: 563\tLoss value: 0.47130351063532705\n",
      "Epoch: 564\tLoss value: 0.47111357126480496\n",
      "Epoch: 565\tLoss value: 0.471136694474098\n",
      "Epoch: 566\tLoss value: 0.47115891502453733\n",
      "Epoch: 567\tLoss value: 0.47106667711184574\n",
      "Epoch: 568\tLoss value: 0.4711353274797782\n",
      "Epoch: 569\tLoss value: 0.47123372365266847\n",
      "Epoch: 570\tLoss value: 0.47104799585464674\n",
      "Epoch: 571\tLoss value: 0.47123036623001097\n",
      "Epoch: 572\tLoss value: 0.47118238990123457\n",
      "Epoch: 573\tLoss value: 0.4711919539097028\n",
      "Epoch: 574\tLoss value: 0.47133629652170034\n",
      "Epoch: 575\tLoss value: 0.4711893492172926\n",
      "Epoch: 576\tLoss value: 0.47111733350998314\n",
      "Epoch: 577\tLoss value: 0.4712348695596059\n",
      "Epoch: 578\tLoss value: 0.4711043318418356\n",
      "Epoch: 579\tLoss value: 0.47125729252130555\n",
      "Epoch: 580\tLoss value: 0.47120433614804197\n",
      "Epoch: 581\tLoss value: 0.47109550622793345\n",
      "Epoch: 582\tLoss value: 0.4718527936324095\n",
      "Epoch: 583\tLoss value: 0.47123099773358074\n",
      "Epoch: 584\tLoss value: 0.4711427866495573\n",
      "Epoch: 585\tLoss value: 0.47118317225040535\n",
      "Epoch: 586\tLoss value: 0.47111036138656814\n",
      "Epoch: 587\tLoss value: 0.4710278152808165\n",
      "Epoch: 588\tLoss value: 0.47115904603248987\n",
      "Epoch: 589\tLoss value: 0.47237223845261794\n",
      "Epoch: 590\tLoss value: 0.4715938158524342\n",
      "Epoch: 591\tLoss value: 0.47172951524074264\n",
      "Epoch: 592\tLoss value: 0.4715015856119303\n",
      "Epoch: 593\tLoss value: 0.4712704926270705\n",
      "Epoch: 594\tLoss value: 0.47118503359647895\n",
      "Epoch: 595\tLoss value: 0.47104849219322203\n",
      "Epoch: 596\tLoss value: 0.4710511592718271\n",
      "Epoch: 597\tLoss value: 0.471129138591962\n",
      "Epoch: 598\tLoss value: 0.47112020562856627\n",
      "Epoch: 599\tLoss value: 0.47113705466955136\n",
      "Epoch: 600\tLoss value: 0.471039482935881\n",
      "Epoch: 601\tLoss value: 0.4710670077495086\n",
      "Epoch: 602\tLoss value: 0.471171374137585\n",
      "Epoch: 603\tLoss value: 0.4710597683833196\n",
      "Epoch: 604\tLoss value: 0.4710768912083063\n",
      "Epoch: 605\tLoss value: 0.47105459262163213\n",
      "Epoch: 606\tLoss value: 0.4710364391253545\n",
      "Epoch: 607\tLoss value: 0.4710522937774658\n",
      "Epoch: 608\tLoss value: 0.47101747888785145\n",
      "Epoch: 609\tLoss value: 0.47109187590770235\n",
      "Epoch: 610\tLoss value: 0.47112535403325007\n",
      "Epoch: 611\tLoss value: 0.47100913980068304\n",
      "Epoch: 612\tLoss value: 0.47112623682388893\n",
      "Epoch: 613\tLoss value: 0.47104409129191666\n",
      "Epoch: 614\tLoss value: 0.47103612477962786\n",
      "Epoch: 615\tLoss value: 0.4710558107266059\n",
      "Epoch: 616\tLoss value: 0.4709791385821807\n",
      "Epoch: 617\tLoss value: 0.4710736679419493\n",
      "Epoch: 618\tLoss value: 0.4710445823424902\n",
      "Epoch: 619\tLoss value: 0.4711802055285527\n",
      "Epoch: 620\tLoss value: 0.4711638479049389\n",
      "Epoch: 621\tLoss value: 0.47125212816091683\n",
      "Epoch: 622\tLoss value: 0.47120601094686065\n",
      "Epoch: 623\tLoss value: 0.4711084699630737\n",
      "Epoch: 624\tLoss value: 0.4710193973015516\n",
      "Epoch: 625\tLoss value: 0.4710367399912614\n",
      "Epoch: 626\tLoss value: 0.47107666150117533\n",
      "Epoch: 627\tLoss value: 0.47107079615959757\n",
      "Epoch: 628\tLoss value: 0.4710693264313233\n",
      "Epoch: 629\tLoss value: 0.4710550901828668\n",
      "Epoch: 630\tLoss value: 0.4711097177175375\n",
      "Epoch: 631\tLoss value: 0.471079069070327\n",
      "Epoch: 632\tLoss value: 0.47105976181152537\n",
      "Epoch: 633\tLoss value: 0.47100289916380855\n",
      "Epoch: 634\tLoss value: 0.4710118713745704\n",
      "Epoch: 635\tLoss value: 0.4710576095336523\n",
      "Epoch: 636\tLoss value: 0.4709552301810338\n",
      "Epoch: 637\tLoss value: 0.47113514022949415\n",
      "Epoch: 638\tLoss value: 0.47106885796938186\n",
      "Epoch: 639\tLoss value: 0.47103855603780503\n",
      "Epoch: 640\tLoss value: 0.4710754639674456\n",
      "Epoch: 641\tLoss value: 0.47099480415001893\n",
      "Epoch: 642\tLoss value: 0.47103568324675926\n",
      "Epoch: 643\tLoss value: 0.47101950235855883\n",
      "Epoch: 644\tLoss value: 0.4710522167193584\n",
      "Epoch: 645\tLoss value: 0.47103995277331423\n",
      "Epoch: 646\tLoss value: 0.4710258988539378\n",
      "Epoch: 647\tLoss value: 0.4710477679509383\n",
      "Epoch: 648\tLoss value: 0.4711622807918451\n",
      "Epoch: 649\tLoss value: 0.47103392601013183\n",
      "Epoch: 650\tLoss value: 0.46160064275448137\n",
      "Epoch: 651\tLoss value: 0.44624203972327403\n",
      "Epoch: 652\tLoss value: 0.4399769977270028\n",
      "Epoch: 653\tLoss value: 0.43510119699514826\n",
      "Epoch: 654\tLoss value: 0.432612680823375\n",
      "Epoch: 655\tLoss value: 0.4310842755666146\n",
      "Epoch: 656\tLoss value: 0.431056829614517\n",
      "Epoch: 657\tLoss value: 0.4305544384014912\n",
      "Epoch: 658\tLoss value: 0.42987205042288856\n",
      "Epoch: 659\tLoss value: 0.4295686314503352\n",
      "Epoch: 660\tLoss value: 0.4294108115862577\n",
      "Epoch: 661\tLoss value: 0.4279630757906498\n",
      "Epoch: 662\tLoss value: 0.42758261112066415\n",
      "Epoch: 663\tLoss value: 0.42489275097846985\n",
      "Epoch: 664\tLoss value: 0.42341123142303566\n",
      "Epoch: 665\tLoss value: 0.42306524229355347\n",
      "Epoch: 666\tLoss value: 0.4225835432914587\n",
      "Epoch: 667\tLoss value: 0.42198460528483756\n",
      "Epoch: 668\tLoss value: 0.4213849281347715\n",
      "Epoch: 669\tLoss value: 0.42280429219588256\n",
      "Epoch: 670\tLoss value: 0.4233069198253827\n",
      "Epoch: 671\tLoss value: 0.4216356324079709\n",
      "Epoch: 672\tLoss value: 0.42032744014874485\n",
      "Epoch: 673\tLoss value: 0.4204235713298504\n",
      "Epoch: 674\tLoss value: 0.4205426595149896\n",
      "Epoch: 675\tLoss value: 0.4211986800034841\n",
      "Epoch: 676\tLoss value: 0.42209817140530315\n",
      "Epoch: 677\tLoss value: 0.41959658586061915\n",
      "Epoch: 678\tLoss value: 0.4190653150051068\n",
      "Epoch: 679\tLoss value: 0.4179389983874101\n",
      "Epoch: 680\tLoss value: 0.4189270130334756\n",
      "Epoch: 681\tLoss value: 0.41991943625303413\n",
      "Epoch: 682\tLoss value: 0.41908578366805344\n",
      "Epoch: 683\tLoss value: 0.418397833108902\n",
      "Epoch: 684\tLoss value: 0.4174439935500805\n",
      "Epoch: 685\tLoss value: 0.41706431208512723\n",
      "Epoch: 686\tLoss value: 0.41732626881354895\n",
      "Epoch: 687\tLoss value: 0.41660477431920856\n",
      "Epoch: 688\tLoss value: 0.4169142497808505\n",
      "Epoch: 689\tLoss value: 0.41656558238542996\n",
      "Epoch: 690\tLoss value: 0.4160309239839896\n",
      "Epoch: 691\tLoss value: 0.4162600142069352\n",
      "Epoch: 692\tLoss value: 0.4165744255597775\n",
      "Epoch: 693\tLoss value: 0.41556938794943005\n",
      "Epoch: 694\tLoss value: 0.41636620960174464\n",
      "Epoch: 695\tLoss value: 0.41564231974956317\n",
      "Epoch: 696\tLoss value: 0.4163287519185971\n",
      "Epoch: 697\tLoss value: 0.4169359456728666\n",
      "Epoch: 698\tLoss value: 0.4155581148923972\n",
      "Epoch: 699\tLoss value: 0.4157400535925841\n",
      "Epoch: 700\tLoss value: 0.4152937492346152\n",
      "Epoch: 701\tLoss value: 0.41498861549756466\n",
      "Epoch: 702\tLoss value: 0.41476941457161537\n",
      "Epoch: 703\tLoss value: 0.41532138793896406\n",
      "Epoch: 704\tLoss value: 0.4147196914599492\n",
      "Epoch: 705\tLoss value: 0.4144616923882411\n",
      "Epoch: 706\tLoss value: 0.414760319239054\n",
      "Epoch: 707\tLoss value: 0.414414743857506\n",
      "Epoch: 708\tLoss value: 0.4142205519706775\n",
      "Epoch: 709\tLoss value: 0.4147371860345205\n",
      "Epoch: 710\tLoss value: 0.4142257949174979\n",
      "Epoch: 711\tLoss value: 0.41420267071479405\n",
      "Epoch: 712\tLoss value: 0.4139129338814662\n",
      "Epoch: 713\tLoss value: 0.4139389252051329\n",
      "Epoch: 714\tLoss value: 0.4135583022771738\n",
      "Epoch: 715\tLoss value: 0.4134317848774103\n",
      "Epoch: 716\tLoss value: 0.41323292632897696\n",
      "Epoch: 717\tLoss value: 0.41330902610069664\n",
      "Epoch: 718\tLoss value: 0.41309327342571356\n",
      "Epoch: 719\tLoss value: 0.41299156273022675\n",
      "Epoch: 720\tLoss value: 0.4129341210768773\n",
      "Epoch: 721\tLoss value: 0.4127179398597815\n",
      "Epoch: 722\tLoss value: 0.4125120043143248\n",
      "Epoch: 723\tLoss value: 0.41248772139732653\n",
      "Epoch: 724\tLoss value: 0.4124193456539741\n",
      "Epoch: 725\tLoss value: 0.4117020106009948\n",
      "Epoch: 726\tLoss value: 0.4116192064682643\n",
      "Epoch: 727\tLoss value: 0.41145590607936566\n",
      "Epoch: 728\tLoss value: 0.4110952539933033\n",
      "Epoch: 729\tLoss value: 0.4105778101315865\n",
      "Epoch: 730\tLoss value: 0.40973124843377334\n",
      "Epoch: 731\tLoss value: 0.409264453343856\n",
      "Epoch: 732\tLoss value: 0.4080055084289649\n",
      "Epoch: 733\tLoss value: 0.4067798695503137\n",
      "Epoch: 734\tLoss value: 0.40620159002450795\n",
      "Epoch: 735\tLoss value: 0.4058690875768661\n",
      "Epoch: 736\tLoss value: 0.40464112538557784\n",
      "Epoch: 737\tLoss value: 0.40403279160841915\n",
      "Epoch: 738\tLoss value: 0.4038570577823199\n",
      "Epoch: 739\tLoss value: 0.4033190722343249\n",
      "Epoch: 740\tLoss value: 0.40300002212707814\n",
      "Epoch: 741\tLoss value: 0.4027356029473818\n",
      "Epoch: 742\tLoss value: 0.4022957829481516\n",
      "Epoch: 743\tLoss value: 0.40248526064249185\n",
      "Epoch: 744\tLoss value: 0.40234181604324243\n",
      "Epoch: 745\tLoss value: 0.4017799081863501\n",
      "Epoch: 746\tLoss value: 0.4017054276435803\n",
      "Epoch: 747\tLoss value: 0.40129312307406695\n",
      "Epoch: 748\tLoss value: 0.4015283047541594\n",
      "Epoch: 749\tLoss value: 0.4009446369226162\n",
      "Epoch: 750\tLoss value: 0.4005655418145351\n",
      "Epoch: 751\tLoss value: 0.40049375388866815\n",
      "Epoch: 752\tLoss value: 0.4004560616230353\n",
      "Epoch: 753\tLoss value: 0.4000744295731569\n",
      "Epoch: 754\tLoss value: 0.3998671740446335\n",
      "Epoch: 755\tLoss value: 0.4001324049020425\n",
      "Epoch: 756\tLoss value: 0.40005207740343535\n",
      "Epoch: 757\tLoss value: 0.3997409126238945\n",
      "Epoch: 758\tLoss value: 0.3993436852021095\n",
      "Epoch: 759\tLoss value: 0.3992105312225146\n",
      "Epoch: 760\tLoss value: 0.3990540417341086\n",
      "Epoch: 761\tLoss value: 0.3991451623500922\n",
      "Epoch: 762\tLoss value: 0.3988153639359352\n",
      "Epoch: 763\tLoss value: 0.3985792407469872\n",
      "Epoch: 764\tLoss value: 0.3985903183466349\n",
      "Epoch: 765\tLoss value: 0.3990453149416508\n",
      "Epoch: 766\tLoss value: 0.39831043203671773\n",
      "Epoch: 767\tLoss value: 0.39779188947799876\n",
      "Epoch: 768\tLoss value: 0.39771691757899064\n",
      "Epoch: 769\tLoss value: 0.39790769466987025\n",
      "Epoch: 770\tLoss value: 0.3973693114519119\n",
      "Epoch: 771\tLoss value: 0.3977624372794078\n",
      "Epoch: 772\tLoss value: 0.3970785263562814\n",
      "Epoch: 773\tLoss value: 0.3975391786526411\n",
      "Epoch: 774\tLoss value: 0.3970072006415098\n",
      "Epoch: 775\tLoss value: 0.3973383409396196\n",
      "Epoch: 776\tLoss value: 0.39720527341732614\n",
      "Epoch: 777\tLoss value: 0.3968886740391071\n",
      "Epoch: 778\tLoss value: 0.3968825181783774\n",
      "Epoch: 779\tLoss value: 0.39616391146794344\n",
      "Epoch: 780\tLoss value: 0.3963908609518638\n",
      "Epoch: 781\tLoss value: 0.3960361770483164\n",
      "Epoch: 782\tLoss value: 0.3959333648131444\n",
      "Epoch: 783\tLoss value: 0.39766369350445574\n",
      "Epoch: 784\tLoss value: 0.3971123666793872\n",
      "Epoch: 785\tLoss value: 0.39684014104879817\n",
      "Epoch: 786\tLoss value: 0.39656588477966115\n",
      "Epoch: 787\tLoss value: 0.39605374768758433\n",
      "Epoch: 788\tLoss value: 0.39555520789745524\n",
      "Epoch: 789\tLoss value: 0.3964117730428011\n",
      "Epoch: 790\tLoss value: 0.3954340529900331\n",
      "Epoch: 791\tLoss value: 0.39561041723459195\n",
      "Epoch: 792\tLoss value: 0.3951666572002264\n",
      "Epoch: 793\tLoss value: 0.3963996149179263\n",
      "Epoch: 794\tLoss value: 0.3952844539972452\n",
      "Epoch: 795\tLoss value: 0.394691356359384\n",
      "Epoch: 796\tLoss value: 0.3944276383289924\n",
      "Epoch: 797\tLoss value: 0.3948766237650162\n",
      "Epoch: 798\tLoss value: 0.3955198664848621\n",
      "Epoch: 799\tLoss value: 0.39463968636133734\n",
      "Epoch: 800\tLoss value: 0.39437347652056276\n",
      "Epoch: 801\tLoss value: 0.3945616476734479\n",
      "Epoch: 802\tLoss value: 0.3942813887962928\n",
      "Epoch: 803\tLoss value: 0.3939138468106588\n",
      "Epoch: 804\tLoss value: 0.39367190388532786\n",
      "Epoch: 805\tLoss value: 0.39434362082909313\n",
      "Epoch: 806\tLoss value: 0.3934748230377833\n",
      "Epoch: 807\tLoss value: 0.3932666417115774\n",
      "Epoch: 808\tLoss value: 0.39369139526134883\n",
      "Epoch: 809\tLoss value: 0.39384138111120615\n",
      "Epoch: 810\tLoss value: 0.393035800854365\n",
      "Epoch: 811\tLoss value: 0.39351123825097695\n",
      "Epoch: 812\tLoss value: 0.39334125603620823\n",
      "Epoch: 813\tLoss value: 0.3929939815172782\n",
      "Epoch: 814\tLoss value: 0.3926803975686049\n",
      "Epoch: 815\tLoss value: 0.39273222915637185\n",
      "Epoch: 816\tLoss value: 0.39324791491031647\n",
      "Epoch: 817\tLoss value: 0.39226580914778586\n",
      "Epoch: 818\tLoss value: 0.39247555539394036\n",
      "Epoch: 819\tLoss value: 0.3924164894223213\n",
      "Epoch: 820\tLoss value: 0.3923248077661563\n",
      "Epoch: 821\tLoss value: 0.3925485128469956\n",
      "Epoch: 822\tLoss value: 0.3917178120674231\n",
      "Epoch: 823\tLoss value: 0.39185354246543\n",
      "Epoch: 824\tLoss value: 0.39174739441046347\n",
      "Epoch: 825\tLoss value: 0.3920333328766701\n",
      "Epoch: 826\tLoss value: 0.39169998933107425\n",
      "Epoch: 827\tLoss value: 0.3915301368328241\n",
      "Epoch: 828\tLoss value: 0.3912780965902867\n",
      "Epoch: 829\tLoss value: 0.39149137986776156\n",
      "Epoch: 830\tLoss value: 0.39122934318505803\n",
      "Epoch: 831\tLoss value: 0.39100825557341945\n",
      "Epoch: 832\tLoss value: 0.3901627666522295\n",
      "Epoch: 833\tLoss value: 0.3905503393747868\n",
      "Epoch: 834\tLoss value: 0.39030200641124674\n",
      "Epoch: 835\tLoss value: 0.39032191570752706\n",
      "Epoch: 836\tLoss value: 0.39038278471200893\n",
      "Epoch: 837\tLoss value: 0.39212356180716784\n",
      "Epoch: 838\tLoss value: 0.389607034157484\n",
      "Epoch: 839\tLoss value: 0.38915836066771775\n",
      "Epoch: 840\tLoss value: 0.39105178291216874\n",
      "Epoch: 841\tLoss value: 0.3893293628402245\n",
      "Epoch: 842\tLoss value: 0.3897269418606391\n",
      "Epoch: 843\tLoss value: 0.38907542758263075\n",
      "Epoch: 844\tLoss value: 0.38967438703928237\n",
      "Epoch: 845\tLoss value: 0.3891194040958698\n",
      "Epoch: 846\tLoss value: 0.38896844249505264\n",
      "Epoch: 847\tLoss value: 0.3882613408489105\n",
      "Epoch: 848\tLoss value: 0.38832722009756626\n",
      "Epoch: 849\tLoss value: 0.3884480318197837\n",
      "Epoch: 850\tLoss value: 0.3887294542789459\n",
      "Epoch: 851\tLoss value: 0.3883641669383416\n",
      "Epoch: 852\tLoss value: 0.3883331635670784\n",
      "Epoch: 853\tLoss value: 0.3884266890776463\n",
      "Epoch: 854\tLoss value: 0.38817236583966475\n",
      "Epoch: 855\tLoss value: 0.38795737602771857\n",
      "Epoch: 856\tLoss value: 0.3876278472558046\n",
      "Epoch: 857\tLoss value: 0.38847839220976216\n",
      "Epoch: 858\tLoss value: 0.3887156308614291\n",
      "Epoch: 859\tLoss value: 0.38834414958953856\n",
      "Epoch: 860\tLoss value: 0.38742592135301\n",
      "Epoch: 861\tLoss value: 0.3874600544342628\n",
      "Epoch: 862\tLoss value: 0.38791225133798063\n",
      "Epoch: 863\tLoss value: 0.38863249849814635\n",
      "Epoch: 864\tLoss value: 0.3877495088485571\n",
      "Epoch: 865\tLoss value: 0.38710957038861055\n",
      "Epoch: 866\tLoss value: 0.3869441889799558\n",
      "Epoch: 867\tLoss value: 0.38661971115148985\n",
      "Epoch: 868\tLoss value: 0.3868413826899651\n",
      "Epoch: 869\tLoss value: 0.3869485002144789\n",
      "Epoch: 870\tLoss value: 0.3864984699090322\n",
      "Epoch: 871\tLoss value: 0.38707482506067326\n",
      "Epoch: 872\tLoss value: 0.38604148861689447\n",
      "Epoch: 873\tLoss value: 0.3877828736947133\n",
      "Epoch: 874\tLoss value: 0.38729182871488427\n",
      "Epoch: 875\tLoss value: 0.385840422526384\n",
      "Epoch: 876\tLoss value: 0.38570584922264783\n",
      "Epoch: 877\tLoss value: 0.38606664466552243\n",
      "Epoch: 878\tLoss value: 0.3863039067158332\n",
      "Epoch: 879\tLoss value: 0.3867545115794891\n",
      "Epoch: 880\tLoss value: 0.3856828614305227\n",
      "Epoch: 881\tLoss value: 0.38545952629584534\n",
      "Epoch: 882\tLoss value: 0.3853526628170258\n",
      "Epoch: 883\tLoss value: 0.38549187348439146\n",
      "Epoch: 884\tLoss value: 0.38561503301828337\n",
      "Epoch: 885\tLoss value: 0.38632214416296057\n",
      "Epoch: 886\tLoss value: 0.3861464309386718\n",
      "Epoch: 887\tLoss value: 0.38588344472341046\n",
      "Epoch: 888\tLoss value: 0.3861206520291475\n",
      "Epoch: 889\tLoss value: 0.38545261619946897\n",
      "Epoch: 890\tLoss value: 0.38404944852376594\n",
      "Epoch: 891\tLoss value: 0.38490449314698194\n",
      "Epoch: 892\tLoss value: 0.3845876110669894\n",
      "Epoch: 893\tLoss value: 0.3844329777665627\n",
      "Epoch: 894\tLoss value: 0.3847363721560209\n",
      "Epoch: 895\tLoss value: 0.38531158555776646\n",
      "Epoch: 896\tLoss value: 0.3849399836552449\n",
      "Epoch: 897\tLoss value: 0.38471397527517415\n",
      "Epoch: 898\tLoss value: 0.3842213329596397\n",
      "Epoch: 899\tLoss value: 0.3849737050900092\n",
      "Epoch: 900\tLoss value: 0.3870290264258018\n",
      "Epoch: 901\tLoss value: 0.38406171227112795\n",
      "Epoch: 902\tLoss value: 0.3840528291845933\n",
      "Epoch: 903\tLoss value: 0.3849760304353176\n",
      "Epoch: 904\tLoss value: 0.3842101363188181\n",
      "Epoch: 905\tLoss value: 0.3836034083672059\n",
      "Epoch: 906\tLoss value: 0.38369992290551846\n",
      "Epoch: 907\tLoss value: 0.3832289111843476\n",
      "Epoch: 908\tLoss value: 0.38391599918787295\n",
      "Epoch: 909\tLoss value: 0.38264088358634557\n",
      "Epoch: 910\tLoss value: 0.38752329629201154\n",
      "Epoch: 911\tLoss value: 0.38362308444120946\n",
      "Epoch: 912\tLoss value: 0.3834507192021761\n",
      "Epoch: 913\tLoss value: 0.38310133648224365\n",
      "Epoch: 914\tLoss value: 0.3853906787205965\n",
      "Epoch: 915\tLoss value: 0.3836098396930939\n",
      "Epoch: 916\tLoss value: 0.38342171325133395\n",
      "Epoch: 917\tLoss value: 0.3823296124736468\n",
      "Epoch: 918\tLoss value: 0.38280304144590327\n",
      "Epoch: 919\tLoss value: 0.3824944476974316\n",
      "Epoch: 920\tLoss value: 0.3826959297443048\n",
      "Epoch: 921\tLoss value: 0.38311908785349286\n",
      "Epoch: 922\tLoss value: 0.38183872178578987\n",
      "Epoch: 923\tLoss value: 0.38247273270900434\n",
      "Epoch: 924\tLoss value: 0.3818371594487092\n",
      "Epoch: 925\tLoss value: 0.3831823790531892\n",
      "Epoch: 926\tLoss value: 0.3830275538028815\n",
      "Epoch: 927\tLoss value: 0.38116296120179005\n",
      "Epoch: 928\tLoss value: 0.38144008578398286\n",
      "Epoch: 929\tLoss value: 0.38143069974887067\n",
      "Epoch: 930\tLoss value: 0.3822705000027632\n",
      "Epoch: 931\tLoss value: 0.38165155017987273\n",
      "Epoch: 932\tLoss value: 0.3816854293071307\n",
      "Epoch: 933\tLoss value: 0.3811815390449304\n",
      "Epoch: 934\tLoss value: 0.38253756501735786\n",
      "Epoch: 935\tLoss value: 0.3817291671037674\n",
      "Epoch: 936\tLoss value: 0.3810106889712505\n",
      "Epoch: 937\tLoss value: 0.3823217335725442\n",
      "Epoch: 938\tLoss value: 0.3819425058212036\n",
      "Epoch: 939\tLoss value: 0.38157902349264194\n",
      "Epoch: 940\tLoss value: 0.382091134419808\n",
      "Epoch: 941\tLoss value: 0.38135284495659366\n",
      "Epoch: 942\tLoss value: 0.3812895371363713\n",
      "Epoch: 943\tLoss value: 0.3831878061630787\n",
      "Epoch: 944\tLoss value: 0.381220675492898\n",
      "Epoch: 945\tLoss value: 0.38197410157093636\n",
      "Epoch: 946\tLoss value: 0.3814188013015649\n",
      "Epoch: 947\tLoss value: 0.3823681380962714\n",
      "Epoch: 948\tLoss value: 0.38165610854442306\n",
      "Epoch: 949\tLoss value: 0.38165634671847026\n",
      "Epoch: 950\tLoss value: 0.38294791102409365\n",
      "Epoch: 951\tLoss value: 0.38167934387158126\n",
      "Epoch: 952\tLoss value: 0.38078656028478575\n",
      "Epoch: 953\tLoss value: 0.38111204356719286\n",
      "Epoch: 954\tLoss value: 0.38045800717213213\n",
      "Epoch: 955\tLoss value: 0.3790031497447919\n",
      "Epoch: 956\tLoss value: 0.38040443292030923\n",
      "Epoch: 957\tLoss value: 0.3808437325557073\n",
      "Epoch: 958\tLoss value: 0.38014483484702233\n",
      "Epoch: 959\tLoss value: 0.38132299189384167\n",
      "Epoch: 960\tLoss value: 0.38095168156501574\n",
      "Epoch: 961\tLoss value: 0.37984171787897747\n",
      "Epoch: 962\tLoss value: 0.3793036812849534\n",
      "Epoch: 963\tLoss value: 0.3793499447290714\n",
      "Epoch: 964\tLoss value: 0.379763175707597\n",
      "Epoch: 965\tLoss value: 0.3792238090282831\n",
      "Epoch: 966\tLoss value: 0.38015855078513805\n",
      "Epoch: 967\tLoss value: 0.3814510174898001\n",
      "Epoch: 968\tLoss value: 0.3802539796706958\n",
      "Epoch: 969\tLoss value: 0.380147179770164\n",
      "Epoch: 970\tLoss value: 0.38019075154494014\n",
      "Epoch: 971\tLoss value: 0.3799491169055303\n",
      "Epoch: 972\tLoss value: 0.3788536962484702\n",
      "Epoch: 973\tLoss value: 0.3791914957226851\n",
      "Epoch: 974\tLoss value: 0.3807989571186212\n",
      "Epoch: 975\tLoss value: 0.3789723319502977\n",
      "Epoch: 976\tLoss value: 0.3786647072663674\n",
      "Epoch: 977\tLoss value: 0.37859064417007643\n",
      "Epoch: 978\tLoss value: 0.3786327160398165\n",
      "Epoch: 979\tLoss value: 0.378259241160674\n",
      "Epoch: 980\tLoss value: 0.378943353723257\n",
      "Epoch: 981\tLoss value: 0.3795523432890574\n",
      "Epoch: 982\tLoss value: 0.3788363065475073\n",
      "Epoch: 983\tLoss value: 0.38255027885620413\n",
      "Epoch: 984\tLoss value: 0.37810371274367355\n",
      "Epoch: 985\tLoss value: 0.37906347659917977\n",
      "Epoch: 986\tLoss value: 0.37932501607980484\n",
      "Epoch: 987\tLoss value: 0.3773228621482849\n",
      "Epoch: 988\tLoss value: 0.38002672969530793\n",
      "Epoch: 989\tLoss value: 0.3780356840674694\n",
      "Epoch: 990\tLoss value: 0.37739992956320445\n",
      "Epoch: 991\tLoss value: 0.37950909249293496\n",
      "Epoch: 992\tLoss value: 0.3787971716813552\n",
      "Epoch: 993\tLoss value: 0.3789471786297285\n",
      "Epoch: 994\tLoss value: 0.37730387712900454\n",
      "Epoch: 995\tLoss value: 0.37770879187645057\n",
      "Epoch: 996\tLoss value: 0.37887488563855487\n",
      "Epoch: 997\tLoss value: 0.3775717040972832\n",
      "Epoch: 998\tLoss value: 0.3794356552606974\n",
      "Epoch: 999\tLoss value: 0.37993867787031027\n",
      "CPU times: user 16h 4min 43s, sys: 4h 1min 11s, total: 20h 5min 54s\n",
      "Wall time: 20h 19min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "fuzzy-montgomery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbc20a73940>]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(current_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "expected-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb84afdabb0>]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
