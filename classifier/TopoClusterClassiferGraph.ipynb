{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "molecular-lying",
   "metadata": {},
   "source": [
    "# Graph Networts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dated-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "received-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import uproot3 as ur\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()\n",
    "\n",
    "path_prefix = '/global/home/users/mfong/git/LCStudies/'\n",
    "plotpath = path_prefix + 'classifier/Plots/'\n",
    "modelpath = path_prefix + 'classifier/Models/'\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "# import our resolution utilities\n",
    "\n",
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "sys.path\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "answering-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pi0 events: 263891\n",
      "Number of pi+ events: 435967\n",
      "Number of pi- events: 434627\n",
      "Total: 1134485\n"
     ]
    }
   ],
   "source": [
    "# import pi+- vs. pi0 images\n",
    "\n",
    "inputpath = '/clusterfs/ml4hep/mfong/ML4Pions/v7/'\n",
    "#path = '/eos/user/m/mswiatlo/images/'\n",
    "branches = ['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi', 'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt', 'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE', 'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T', 'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY', 'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT', 'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min', 'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max', 'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max', 'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi', 'cluster_cell_centerCellLayer', 'cluster_cellE_norm']\n",
    "rootfiles = [\"pi0\", \"piplus\", \"piminus\"]\n",
    "trees = {\n",
    "    rfile : ur.open(inputpath+rfile+\".root\")['ClusterTree']\n",
    "    for rfile in rootfiles\n",
    "}\n",
    "pdata = {\n",
    "    ifile : itree.pandas.df(branches, flatten=False)\n",
    "    for ifile, itree in trees.items()\n",
    "}\n",
    "\n",
    "np0 = len(pdata['pi0'])\n",
    "npp = len(pdata['piplus'])\n",
    "npm = len(pdata['piminus'])\n",
    "\n",
    "print(\"Number of pi0 events: {}\".format(np0))\n",
    "print(\"Number of pi+ events: {}\".format(npp))\n",
    "print(\"Number of pi- events: {}\".format(npm))\n",
    "print(\"Total: {}\".format(np0+npp+npm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "known-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_shapes = {\n",
    "    'EMB1': (128,4),\n",
    "    'EMB2': (16,16),\n",
    "    'EMB3': (8,16),\n",
    "    'TileBar0': (4,4),\n",
    "    'TileBar1': (4,4),\n",
    "    'TileBar2': (2,4),\n",
    "}\n",
    "\n",
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer)\n",
    "        for layer in layers\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broken-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi',\n",
       "       'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt',\n",
       "       'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE',\n",
       "       'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T',\n",
       "       'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY',\n",
       "       'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT',\n",
       "       'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min',\n",
       "       'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max',\n",
       "       'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max',\n",
       "       'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi',\n",
       "       'cluster_cell_centerCellLayer', 'cluster_cellE_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[\"pi0\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comprehensive-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263891, 512)\n",
      "(263891, 256)\n",
      "(263891, 128)\n",
      "(263891, 16)\n",
      "(263891, 16)\n",
      "(263891, 8)\n"
     ]
    }
   ],
   "source": [
    "for key in pcells[\"pi0\"]:\n",
    "    print(pcells[\"pi0\"][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "starting-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of cells per event\n",
    "512+256+128+16+16+8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-blame",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-thompson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df for pi0 only\n",
    "df_p0 = pd.DataFrame(np.concatenate([pcells[\"pi0\"][key] for key in pcells[\"pi0\"].keys()], axis = 1))\n",
    "\n",
    "col_names = []\n",
    "for key in pcells[\"pi0\"].keys():\n",
    "    col_names.extend([key + \"_\" + str(i) for i in range(len(pcells[\"pi0\"][key][0]))])\n",
    "df_p0.columns = col_names\n",
    "\n",
    "df_p0[\"is_p0\"] = 1\n",
    "\n",
    "\n",
    "# print(df_p0.shape)\n",
    "# df_p0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rough-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for pipplus and piminus\n",
    "df_pp = pd.DataFrame(np.concatenate([pcells[\"piplus\"][key] for key in pcells[\"piplus\"].keys()], axis = 1))\n",
    "df_pp.columns = col_names\n",
    "df_pp[\"is_p0\"] = 0\n",
    "\n",
    "df_pm = pd.DataFrame(np.concatenate([pcells[\"piminus\"][key] for key in pcells[\"piminus\"].keys()], axis = 1))\n",
    "df_pm.columns = col_names\n",
    "df_pm[\"is_p0\"] = 0\n",
    "\n",
    "# print(df_pp.shape)\n",
    "# df_pp.head()\n",
    "\n",
    "# TODO piplus as 1 pipminus as -1 pi0 as 0???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virgin-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB1_0</th>\n",
       "      <th>EMB1_1</th>\n",
       "      <th>EMB1_2</th>\n",
       "      <th>EMB1_3</th>\n",
       "      <th>EMB1_4</th>\n",
       "      <th>EMB1_5</th>\n",
       "      <th>EMB1_6</th>\n",
       "      <th>EMB1_7</th>\n",
       "      <th>EMB1_8</th>\n",
       "      <th>EMB1_9</th>\n",
       "      <th>EMB1_10</th>\n",
       "      <th>EMB1_11</th>\n",
       "      <th>EMB1_12</th>\n",
       "      <th>EMB1_13</th>\n",
       "      <th>EMB1_14</th>\n",
       "      <th>EMB1_15</th>\n",
       "      <th>EMB1_16</th>\n",
       "      <th>EMB1_17</th>\n",
       "      <th>EMB1_18</th>\n",
       "      <th>EMB1_19</th>\n",
       "      <th>EMB1_20</th>\n",
       "      <th>EMB1_21</th>\n",
       "      <th>EMB1_22</th>\n",
       "      <th>EMB1_23</th>\n",
       "      <th>EMB1_24</th>\n",
       "      <th>EMB1_25</th>\n",
       "      <th>EMB1_26</th>\n",
       "      <th>EMB1_27</th>\n",
       "      <th>EMB1_28</th>\n",
       "      <th>EMB1_29</th>\n",
       "      <th>EMB1_30</th>\n",
       "      <th>EMB1_31</th>\n",
       "      <th>EMB1_32</th>\n",
       "      <th>EMB1_33</th>\n",
       "      <th>EMB1_34</th>\n",
       "      <th>EMB1_35</th>\n",
       "      <th>EMB1_36</th>\n",
       "      <th>EMB1_37</th>\n",
       "      <th>EMB1_38</th>\n",
       "      <th>EMB1_39</th>\n",
       "      <th>EMB1_40</th>\n",
       "      <th>EMB1_41</th>\n",
       "      <th>EMB1_42</th>\n",
       "      <th>EMB1_43</th>\n",
       "      <th>EMB1_44</th>\n",
       "      <th>EMB1_45</th>\n",
       "      <th>EMB1_46</th>\n",
       "      <th>EMB1_47</th>\n",
       "      <th>EMB1_48</th>\n",
       "      <th>EMB1_49</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB3_119</th>\n",
       "      <th>EMB3_120</th>\n",
       "      <th>EMB3_121</th>\n",
       "      <th>EMB3_122</th>\n",
       "      <th>EMB3_123</th>\n",
       "      <th>EMB3_124</th>\n",
       "      <th>EMB3_125</th>\n",
       "      <th>EMB3_126</th>\n",
       "      <th>EMB3_127</th>\n",
       "      <th>TileBar0_0</th>\n",
       "      <th>TileBar0_1</th>\n",
       "      <th>TileBar0_2</th>\n",
       "      <th>TileBar0_3</th>\n",
       "      <th>TileBar0_4</th>\n",
       "      <th>TileBar0_5</th>\n",
       "      <th>TileBar0_6</th>\n",
       "      <th>TileBar0_7</th>\n",
       "      <th>TileBar0_8</th>\n",
       "      <th>TileBar0_9</th>\n",
       "      <th>TileBar0_10</th>\n",
       "      <th>TileBar0_11</th>\n",
       "      <th>TileBar0_12</th>\n",
       "      <th>TileBar0_13</th>\n",
       "      <th>TileBar0_14</th>\n",
       "      <th>TileBar0_15</th>\n",
       "      <th>TileBar1_0</th>\n",
       "      <th>TileBar1_1</th>\n",
       "      <th>TileBar1_2</th>\n",
       "      <th>TileBar1_3</th>\n",
       "      <th>TileBar1_4</th>\n",
       "      <th>TileBar1_5</th>\n",
       "      <th>TileBar1_6</th>\n",
       "      <th>TileBar1_7</th>\n",
       "      <th>TileBar1_8</th>\n",
       "      <th>TileBar1_9</th>\n",
       "      <th>TileBar1_10</th>\n",
       "      <th>TileBar1_11</th>\n",
       "      <th>TileBar1_12</th>\n",
       "      <th>TileBar1_13</th>\n",
       "      <th>TileBar1_14</th>\n",
       "      <th>TileBar1_15</th>\n",
       "      <th>TileBar2_0</th>\n",
       "      <th>TileBar2_1</th>\n",
       "      <th>TileBar2_2</th>\n",
       "      <th>TileBar2_3</th>\n",
       "      <th>TileBar2_4</th>\n",
       "      <th>TileBar2_5</th>\n",
       "      <th>TileBar2_6</th>\n",
       "      <th>TileBar2_7</th>\n",
       "      <th>is_p0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>0.140632</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134481</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071595</td>\n",
       "      <td>0.762828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.106541</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134485 rows × 937 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EMB1_0  EMB1_1  EMB1_2  EMB1_3  EMB1_4  EMB1_5  EMB1_6  EMB1_7  \\\n",
       "0           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1134480     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1134481     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1134482     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1134483     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1134484     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "         EMB1_8  EMB1_9  EMB1_10  EMB1_11  EMB1_12  EMB1_13  EMB1_14  EMB1_15  \\\n",
       "0           0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1           0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2           0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3           0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4           0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...         ...     ...      ...      ...      ...      ...      ...      ...   \n",
       "1134480     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134481     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134482     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134483     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134484     0.0     0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         EMB1_16  EMB1_17  EMB1_18  EMB1_19  EMB1_20  EMB1_21  EMB1_22  \\\n",
       "0            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1134480      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134481      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134482      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134483      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134484      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         EMB1_23  EMB1_24  EMB1_25  EMB1_26  EMB1_27  EMB1_28  EMB1_29  \\\n",
       "0            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1134480      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134481      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134482      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134483      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134484      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         EMB1_30  EMB1_31  EMB1_32  EMB1_33  EMB1_34  EMB1_35  EMB1_36  \\\n",
       "0            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1134480      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134481      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134482      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134483      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134484      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         EMB1_37  EMB1_38  EMB1_39  EMB1_40  EMB1_41  EMB1_42  EMB1_43  \\\n",
       "0            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1134480      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134481      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134482      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134483      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1134484      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "         EMB1_44  EMB1_45  EMB1_46  EMB1_47  EMB1_48  EMB1_49  ...  EMB3_119  \\\n",
       "0            0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000009   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "...          ...      ...      ...      ...      ...      ...  ...       ...   \n",
       "1134480      0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "1134481      0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "1134482      0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "1134483      0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "1134484      0.0      0.0      0.0      0.0      0.0      0.0  ...  0.000000   \n",
       "\n",
       "         EMB3_120  EMB3_121  EMB3_122  EMB3_123  EMB3_124  EMB3_125  EMB3_126  \\\n",
       "0        0.000038  0.000009       0.0       0.0       0.0       0.0       0.0   \n",
       "1        0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "2        0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "3        0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "4        0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1134480  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "1134481  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "1134482  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "1134483  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "1134484  0.000000  0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "         EMB3_127  TileBar0_0  TileBar0_1  TileBar0_2  TileBar0_3  TileBar0_4  \\\n",
       "0             0.0    0.000224    0.000315    0.001344    0.000428    0.002322   \n",
       "1             0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2             0.0    0.000000    0.011872    0.005269    0.000000    0.000000   \n",
       "3             0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4             0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "1134480       0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134481       0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134482       0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134483       0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134484       0.0    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         TileBar0_5  TileBar0_6  TileBar0_7  TileBar0_8  TileBar0_9  \\\n",
       "0          0.012944    0.014262    0.002498    0.001551    0.070766   \n",
       "1          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2          0.628931    0.088836    0.002091    0.000000    0.030488   \n",
       "3          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1134480    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134481    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134482    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134483    0.011533    0.003547    0.003322    0.000000    0.071595   \n",
       "1134484    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         TileBar0_10  TileBar0_11  TileBar0_12  TileBar0_13  TileBar0_14  \\\n",
       "0           0.140632     0.001669     0.003287     0.004747     0.008165   \n",
       "1           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2           0.019321     0.004342     0.000000     0.000000     0.000177   \n",
       "3           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1134480     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134481     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134482     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134483     0.762828     0.000000     0.000000     0.003029     0.106541   \n",
       "1134484     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "         TileBar0_15  TileBar1_0  TileBar1_1  TileBar1_2  TileBar1_3  \\\n",
       "0           0.000888    0.000054    0.000776    0.001186    0.000146   \n",
       "1           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2           0.001947    0.000000    0.019718    0.003629    0.000000   \n",
       "3           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4           0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "1134480     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134481     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134482     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134483     0.004679    0.000000    0.000000    0.000000    0.000000   \n",
       "1134484     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         TileBar1_4  TileBar1_5  TileBar1_6  TileBar1_7  TileBar1_8  \\\n",
       "0          0.000375    0.006990    0.007225    0.003866    0.001419   \n",
       "1          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2          0.000000    0.087662    0.022248    0.000901    0.000000   \n",
       "3          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4          0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1134480    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134481    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134482    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134483    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1134484    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "         TileBar1_9  TileBar1_10  TileBar1_11  TileBar1_12  TileBar1_13  \\\n",
       "0          0.035971     0.047344     0.003773     0.000361     0.006787   \n",
       "1          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2          0.006445     0.000219     0.000237     0.000000     0.000000   \n",
       "3          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4          0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "1134480    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134481    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134482    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1134483    0.006976     0.017990     0.001190     0.000000     0.000898   \n",
       "1134484    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "         TileBar1_14  TileBar1_15  TileBar2_0  TileBar2_1  TileBar2_2  \\\n",
       "0           0.003358     0.002189         0.0    0.000625    0.000405   \n",
       "1           0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "2           0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "3           0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "4           0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "...              ...          ...         ...         ...         ...   \n",
       "1134480     0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "1134481     0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "1134482     0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "1134483     0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "1134484     0.000000     0.000000         0.0    0.000000    0.000000   \n",
       "\n",
       "         TileBar2_3  TileBar2_4  TileBar2_5  TileBar2_6  TileBar2_7  is_p0  \n",
       "0          0.000031    0.000024    0.001023    0.001606         0.0      0  \n",
       "1          0.000000    0.000000    0.000000    0.000000         0.0      0  \n",
       "2          0.000000    0.000000    0.000000    0.000000         0.0      0  \n",
       "3          0.000000    0.000000    0.000000    0.000000         0.0      0  \n",
       "4          0.000000    0.000000    0.000000    0.000000         0.0      1  \n",
       "...             ...         ...         ...         ...         ...    ...  \n",
       "1134480    0.000000    0.000000    0.000000    0.000000         0.0      1  \n",
       "1134481    0.000000    0.000000    0.000000    0.000000         0.0      1  \n",
       "1134482    0.000000    0.000000    0.000000    0.000000         0.0      1  \n",
       "1134483    0.000000    0.000000    0.000000    0.000000         0.0      0  \n",
       "1134484    0.000000    0.000000    0.000000    0.000000         0.0      1  \n",
       "\n",
       "[1134485 rows x 937 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create final df\n",
    "df = df_p0.append(df_pp.append(df_pm))\n",
    "df = df.sample(frac=1) # Shuffle the df so pi0 are not all first\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-hanging",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facial-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutations for doubly connected edges\n",
    "from itertools import permutations\n",
    "import functools\n",
    "import networkx as nx\n",
    "import sonnet as snt\n",
    "\n",
    "from graph_nets import blocks\n",
    "\n",
    "from graph_nets import graphs\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "banned-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB1_0        0.000000\n",
       "EMB1_1        0.000000\n",
       "EMB1_2        0.000000\n",
       "EMB1_3        0.000000\n",
       "EMB1_4        0.000000\n",
       "                ...   \n",
       "TileBar2_4    0.000024\n",
       "TileBar2_5    0.001023\n",
       "TileBar2_6    0.001606\n",
       "TileBar2_7    0.000000\n",
       "is_p0         0.000000\n",
       "Name: 0, Length: 937, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# event0 = df.loc[0]\n",
    "event0 = df.loc[0]\n",
    "event0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "appropriate-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fully_connected_edges(nodes):\n",
    "    \"\"\"\n",
    "    returns a list of tuples with (sender_node, reciever_node) for a fully connected graph\n",
    "    ex: [(1,2), (2,1), (0,1)]\n",
    "    \"\"\"\n",
    "    n_nodes = len(nodes)\n",
    "    return list(permutations(range(n_nodes), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceramic-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(event):\n",
    "    \n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    MIN_VALUE = 0.001\n",
    "    solution = \"is_p0\"\n",
    "    \n",
    "    nodes = [[cell] for cell in event[col_names][event[col_names] > MIN_VALUE]]\n",
    "    n_nodes = len(nodes)\n",
    "    if n_nodes < 1:\n",
    "        return (None, None)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "    \n",
    "    edge_endpoints = make_fully_connected_edges(nodes)\n",
    "    senders = np.array([x[0] for x in edge_endpoints])\n",
    "    receivers = np.array([x[1] for x in edge_endpoints])\n",
    "    n_edges = len(edge_endpoints)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    \n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    \n",
    "    return (input_graph, target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fatty-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"has shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "characteristic-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes has shape (67, 1)\n",
      "edges has shape (4422, 1)\n",
      "receivers has shape (4422,)\n",
      "senders has shape (4422,)\n",
      "globals has shape (1, 1)\n",
      "n_node has shape (1,)\n",
      "n_edge has shape (1,)\n"
     ]
    }
   ],
   "source": [
    "graphs_tuple0_input, graphs_tuple0_target = make_graph(event0)\n",
    "\n",
    "print_graphs_tuple(graphs_tuple0_input, data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "structural-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting functions from example (broken)\n",
    "\n",
    "# def plot_graph_networkx(graph, ax, pos=None):\n",
    "#   node_labels = {node: \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for node, data in graph.nodes(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   edge_labels = {(sender, receiver): \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for sender, receiver, data in graph.edges(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   global_label = (\"{:.3g}\".format(graph.graph[\"features\"][0])\n",
    "#                   if graph.graph[\"features\"] is not None else None)\n",
    "\n",
    "#   if pos is None:\n",
    "#     pos = nx.spring_layout(graph)\n",
    "#   nx.draw_networkx(graph, pos, ax=ax, labels=node_labels)\n",
    "\n",
    "#   if edge_labels:\n",
    "#     nx.draw_networkx_edge_labels(graph, pos, edge_labels, ax=ax)\n",
    "\n",
    "#   if global_label:\n",
    "#     plt.text(0.05, 0.95, global_label, transform=ax.transAxes)\n",
    "\n",
    "#   ax.yaxis.set_visible(False)\n",
    "#   ax.xaxis.set_visible(False)\n",
    "#   return pos\n",
    "\n",
    "# def plot_graphs_tuple(graphs_tuple):\n",
    "#   networkx_graphs = utils_np.graphs_tuple_to_networkxs(graphs_tuple)\n",
    "#   num_graphs = len(networkx_graphs)\n",
    "#   _, axes = plt.subplots(1, num_graphs, figsize=(5*num_graphs, 5))\n",
    "#   if num_graphs == 1:\n",
    "#     axes = axes,\n",
    "#   for graph, ax in zip(networkx_graphs, axes):\n",
    "#     plot_graph_networkx(graph, ax)\n",
    "\n",
    "# plot_graphs_tuple(graphs_tuple0_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-closer",
   "metadata": {},
   "source": [
    "## Graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "apparent-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the newest dev version of graph_nets (see https://github.com/deepmind/graph_nets/issues/139)\n",
    "# as of 3/25/2021\n",
    "\n",
    "\n",
    "# !pip install git+git://github.com/deepmind/graph_nets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "local-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 2\n",
    "def make_mlp_model():\n",
    "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "  The parameters of each new MLP are not shared with others generated by\n",
    "  this function.\n",
    "\n",
    "  Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "  \"\"\"\n",
    "  # the activation function choices:\n",
    "  # swish, relu, relu6, leaky_relu\n",
    "  return snt.Sequential([\n",
    "      snt.nets.MLP([128, 64]*NUM_LAYERS,\n",
    "                    activation=tf.nn.relu,\n",
    "                    activate_final=True, \n",
    "                  #  dropout_rate=DROPOUT_RATE\n",
    "        ),\n",
    "      snt.LayerNorm(axis=-1, create_scale=True, create_offset=False)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "composed-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGraphNetwork(snt.Module):\n",
    "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
    "    def __init__(self, name=\"MLPGraphNetwork\"):\n",
    "        super(MLPGraphNetwork, self).__init__(name=name)\n",
    "        self._network = modules.GraphNetwork(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            node_model_fn=make_mlp_model,\n",
    "            global_model_fn=make_mlp_model\n",
    "            )\n",
    "\n",
    "    def __call__(self, inputs,\n",
    "            edge_model_kwargs=None,\n",
    "            node_model_kwargs=None,\n",
    "            global_model_kwargs=None):\n",
    "        return self._network(inputs,\n",
    "                      edge_model_kwargs=edge_model_kwargs,\n",
    "                      node_model_kwargs=node_model_kwargs,\n",
    "                      global_model_kwargs=global_model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "handed-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128\n",
    "\n",
    "class GlobalClassifierNoEdgeInfo(snt.Module):\n",
    "\n",
    "    def __init__(self, name=\"GlobalClassifierNoEdgeInfo\"):\n",
    "        super(GlobalClassifierNoEdgeInfo, self).__init__(name=name)\n",
    "\n",
    "        self._edge_block = blocks.EdgeBlock(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            use_edges=False,\n",
    "            use_receiver_nodes=True,\n",
    "            use_sender_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='edge_encoder_block')\n",
    "\n",
    "        self._node_encoder_block = blocks.NodeBlock(\n",
    "            node_model_fn=make_mlp_model,\n",
    "            use_received_edges=False,\n",
    "            use_sent_edges=False,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "            name='node_encoder_block'\n",
    "        )\n",
    "\n",
    "        self._global_block = blocks.GlobalBlock(\n",
    "            global_model_fn=make_mlp_model,\n",
    "            use_edges=True,\n",
    "            use_nodes=True,\n",
    "            use_globals=False,\n",
    "        )\n",
    "\n",
    "        self._core = MLPGraphNetwork()\n",
    "        # Transforms the outputs into appropriate shapes.\n",
    "        global_output_size = 1\n",
    "        global_fn =lambda: snt.Sequential([\n",
    "            snt.nets.MLP([LATENT_SIZE, global_output_size],\n",
    "                         name='global_output'), tf.sigmoid])\n",
    "\n",
    "        self._output_transform = modules.GraphIndependent(None, None, global_fn)\n",
    "\n",
    "    def __call__(self, input_op, num_processing_steps):\n",
    "        latent = self._global_block(self._edge_block(self._node_encoder_block(input_op)))\n",
    "        latent0 = latent\n",
    "\n",
    "        output_ops = []\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
    "            latent = self._core(core_input)\n",
    "            output_ops.append(self._output_transform(latent))\n",
    "\n",
    "        return output_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "removed-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlobalClassifierNoEdgeInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "compact-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graphs = model(graphs_tuple0_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cosmetic-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6277563]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.54467916]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5448466]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.53598255]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.52298105]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49340445]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5009495]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49806276]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49751532]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49268764]], dtype=float32)>]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.globals for x in output_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "solved-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "\n",
    "class GlobalLoss:\n",
    "    def __init__(self, real_global_weight, fake_global_weight):\n",
    "        self.w_global_real = real_global_weight\n",
    "        self.w_global_fake = fake_global_weight\n",
    "\n",
    "    def __call__(self, target_op, output_ops):\n",
    "        global_weights = target_op.globals * self.w_global_real \\\n",
    "            + (1 - target_op.globals) * self.w_global_fake\n",
    "        \n",
    "        print(global_weights)\n",
    "        \n",
    "        loss_ops = [\n",
    "            tf.compat.v1.losses.log_loss(target_op.globals, output_op.globals, weights=global_weights)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "        return tf.stack(loss_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "mexican-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_global = GlobalLoss(real_global_weight = 1.0, fake_global_weight = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "offshore-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.98820627, 0.78675276, 0.7871206 , 0.76783293, 0.74019885,\n",
       "       0.6800421 , 0.6950478 , 0.6892799 , 0.68818986, 0.67862815],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_global(graphs_tuple0_target, output_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-cherry",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "noted-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify acc function\n",
    "\n",
    "def compute_accuracy(target, output):\n",
    "    \"\"\"Calculate model accuracy.\n",
    "\n",
    "    Returns the number of correctly predicted links and the number\n",
    "    of completely solved list sorts (100% correct predictions).\n",
    "\n",
    "    Args:\n",
    "    target: A `graphs.GraphsTuple` that contains the target graph.\n",
    "    output: A `graphs.GraphsTuple` that contains the output graph.\n",
    "\n",
    "    Returns:\n",
    "    correct: A `float` fraction of correctly labeled nodes/edges.\n",
    "    solved: A `float` fraction of graphs that are completely correctly labeled.\n",
    "    \"\"\"\n",
    "    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "    odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "    cs = []\n",
    "    ss = []\n",
    "    for td, od in zip(tdds, odds):\n",
    "        num_elements = td[\"nodes\"].shape[0]\n",
    "        xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "        yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "\n",
    "        xe = np.reshape(\n",
    "            np.argmax(\n",
    "                np.reshape(td[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "            (-1,))\n",
    "        ye = np.reshape(\n",
    "            np.argmax(\n",
    "                np.reshape(od[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "            (-1,))\n",
    "        c = np.concatenate((xn == yn, xe == ye), axis=0)\n",
    "        s = np.all(c)\n",
    "        cs.append(c)\n",
    "        ss.append(s)\n",
    "    correct = np.mean(np.concatenate(cs, axis=0))\n",
    "    solved = np.mean(np.stack(ss))\n",
    "    return correct, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cloudy-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(dataset, batch_size):\n",
    "    \"\"\"\n",
    "    Get signature of inputs for the training loop.\n",
    "    The signature is used by the tf.function\n",
    "    \"\"\"\n",
    "\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    for _, data in dataset.iterrows():\n",
    "        dd = make_graph(data)\n",
    "        if dd[0] is not None:\n",
    "            input_list.append(dd[0])\n",
    "            target_list.append(dd[1])\n",
    "            \n",
    "        if len(input_list) == batch_size:\n",
    "            break\n",
    "\n",
    "    inputs = utils_tf.concat(input_list, axis=0)\n",
    "    targets = utils_tf.concat(target_list, axis=0)\n",
    "    input_signature = (\n",
    "      utils_tf.specs_from_graphs_tuple(inputs),\n",
    "      utils_tf.specs_from_graphs_tuple(targets)\n",
    "    )\n",
    "    \n",
    "    return input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "several-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "input_signature = get_signature(df, batch_size)\n",
    "\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 10\n",
    "num_processing_steps_ge = 10\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = snt.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "# model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "last_iteration = 0\n",
    "generalization_iteration = 0\n",
    "\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []\n",
    "\n",
    "\n",
    "@functools.partial(tf.function, input_signature=input_signature)\n",
    "def update_step(inputs_tr, targets_tr):\n",
    "    print(\"Tracing update_step\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs_tr = model(inputs_tr, num_processing_steps_tr)\n",
    "        loss_ops_tr = loss_function_global(targets_tr, outputs_tr)\n",
    "        loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)\n",
    "\n",
    "    gradients = tape.gradient(loss_op_tr, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "    return outputs_tr, loss_op_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "stupid-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and generalization df\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO this is very slow\n",
    "# make graphs for each event\n",
    "train_graphs = [make_graph(event) for _, event in df_train.iterrows()]\n",
    "test_graphs = [make_graph(event) for _, event in df_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_graphs and test_graphs objects to file, it takes too long to make\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, \"wb\") as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(train_graphs, \"Temp/train_graphs.pkl\")\n",
    "save_object(train_graphs, \"Temp/test_graphs.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "instant-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_dataset(datasets, batch_size):\n",
    "    if batch_size > 0:\n",
    "        in_list = []\n",
    "        target_list = []\n",
    "        for dataset in datasets:\n",
    "            inputs_tr, targets_tr = dataset\n",
    "            if inputs_tr is None:\n",
    "                continue\n",
    "            in_list.append(inputs_tr)\n",
    "            target_list.append(targets_tr)\n",
    "            if len(in_list) == batch_size:\n",
    "                inputs_tr = utils_tf.concat(in_list, axis=0)\n",
    "                targets_tr = utils_tf.concat(target_list, axis=0)\n",
    "                yield (inputs_tr, targets_tr)\n",
    "                in_list = []\n",
    "                target_list = []\n",
    "    else:\n",
    "        for dataset in datasets:\n",
    "            if dataset is None:\n",
    "                continue\n",
    "            yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "coordinated-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = loop_dataset(train_graphs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "strategic-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tr, target_tr = next(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "damaged-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015334407"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_step(input_tr, target_tr)[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "facial-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.505082505941391\n",
      "Loss value:  0.5170837674289942\n",
      "Loss value:  0.46566524282097815\n",
      "Loss value:  0.5274575479328633\n",
      "Loss value:  0.5646846294403076\n",
      "Loss value:  0.42001342177391054\n",
      "Loss value:  0.4980553433299065\n",
      "Loss value:  0.5022776640951634\n",
      "Loss value:  0.4656680032610893\n",
      "Loss value:  0.5311625823378563\n",
      "Loss value:  0.49907453507184985\n",
      "Loss value:  0.5414944395422936\n",
      "Loss value:  0.48490761741995814\n",
      "Loss value:  0.46850149109959605\n",
      "Loss value:  0.5166179910302162\n",
      "Loss value:  0.4762681171298027\n",
      "Loss value:  0.4779835008084774\n",
      "Loss value:  0.455800648778677\n",
      "Loss value:  0.49538333937525747\n",
      "Loss value:  0.4731521438807249\n",
      "Loss value:  0.4202917978167534\n",
      "Loss value:  0.46936828792095187\n",
      "Loss value:  0.524476470053196\n",
      "Loss value:  0.48846646696329116\n",
      "Loss value:  0.5484722226858139\n",
      "Loss value:  0.5557841017842293\n",
      "Loss value:  0.4679871782660484\n",
      "Loss value:  0.48612009435892106\n",
      "Loss value:  0.5485726922750473\n",
      "Loss value:  0.5094091579318046\n",
      "Loss value:  0.5355802282691002\n",
      "Loss value:  0.5339563556015492\n",
      "Loss value:  0.5097624614834786\n",
      "Loss value:  0.5114916741847992\n",
      "Loss value:  0.5213626503944397\n",
      "Loss value:  0.47121853455901147\n",
      "Loss value:  0.46047611311078074\n",
      "Loss value:  0.5352908819913864\n",
      "Loss value:  0.5454564034938812\n",
      "Loss value:  0.4483408108353615\n",
      "Loss value:  0.4623617187142372\n",
      "Loss value:  0.5102049693465233\n",
      "Loss value:  0.41057904064655304\n",
      "Loss value:  0.4920513302087784\n",
      "Loss value:  0.43910248428583143\n",
      "Loss value:  0.44280345290899276\n",
      "Loss value:  0.504129382967949\n",
      "Loss value:  0.5014745786786079\n",
      "Loss value:  0.49242743477225304\n",
      "Loss value:  0.5225131914019585\n",
      "Loss value:  0.4972019724547863\n",
      "Loss value:  0.5130071856081486\n",
      "Loss value:  0.45561688393354416\n",
      "Loss value:  0.40219777040183546\n",
      "Loss value:  0.4601545222103596\n",
      "Loss value:  0.5029435638338328\n",
      "Loss value:  0.47953262850642203\n",
      "Loss value:  0.4876477673649788\n",
      "Loss value:  0.5080842658877373\n",
      "Loss value:  0.4831292763352394\n",
      "Loss value:  0.5315555348992348\n",
      "Loss value:  0.3940967932343483\n",
      "Loss value:  0.5402722962200641\n",
      "Loss value:  0.4932446375489235\n",
      "Loss value:  0.4446530506014824\n",
      "Loss value:  0.4957360714673996\n",
      "Loss value:  0.4602510020136833\n",
      "Loss value:  0.5109083458781243\n",
      "Loss value:  0.5418023705482483\n",
      "Loss value:  0.48654226809740064\n",
      "Loss value:  0.4856904253363609\n",
      "Loss value:  0.49539500176906587\n",
      "Loss value:  0.5337842330336571\n",
      "Loss value:  0.4905110262334347\n",
      "Loss value:  0.49241098910570147\n",
      "Loss value:  0.5009637206792832\n",
      "Loss value:  0.4481034234166145\n",
      "Loss value:  0.5343313291668892\n",
      "Loss value:  0.45663685351610184\n",
      "Loss value:  0.5092979870736599\n",
      "Loss value:  0.4662454813718796\n",
      "Loss value:  0.4276786491274834\n",
      "Loss value:  0.4461383201181889\n",
      "Loss value:  0.4748080939054489\n",
      "Loss value:  0.5131988026201725\n",
      "Loss value:  0.48818607330322267\n",
      "Loss value:  0.47650467306375505\n",
      "Loss value:  0.5003433421254158\n",
      "Loss value:  0.5065195113420486\n",
      "Loss value:  0.4083776645362377\n",
      "Loss value:  0.4163610406219959\n",
      "Loss value:  0.43844032399356364\n",
      "Loss value:  0.49854173958301545\n",
      "Loss value:  0.5132618814706802\n",
      "Loss value:  0.4799760401248932\n",
      "Loss value:  0.4740962415933609\n",
      "Loss value:  0.5060383036732674\n",
      "Loss value:  0.5026557378470897\n",
      "Loss value:  0.48678454384207726\n",
      "Loss value:  0.5111816748976707\n",
      "Loss value:  0.49390158951282503\n",
      "Loss value:  0.5275476247072219\n",
      "Loss value:  0.48767841011285784\n",
      "Loss value:  0.5115784667432308\n",
      "Loss value:  0.5074494063854218\n",
      "Loss value:  0.48574781268835066\n",
      "Loss value:  0.46470132023096083\n",
      "Loss value:  0.5273644521832466\n",
      "Loss value:  0.537639431655407\n",
      "Loss value:  0.4539797633886337\n",
      "Loss value:  0.48851069137454034\n",
      "Loss value:  0.49262742698192596\n",
      "Loss value:  0.47299407571554186\n",
      "Loss value:  0.46507118120789526\n",
      "Loss value:  0.515992347896099\n",
      "Loss value:  0.5073386818170548\n",
      "Loss value:  0.48935451321303847\n",
      "Loss value:  0.47039002776145933\n",
      "Loss value:  0.4582647100090981\n",
      "Loss value:  0.4707604557275772\n",
      "Loss value:  0.5400183692574501\n",
      "Loss value:  0.503311350941658\n",
      "Loss value:  0.5087016999721528\n",
      "Loss value:  0.44776956364512444\n",
      "Loss value:  0.5078839756548404\n",
      "Loss value:  0.4294126033782959\n",
      "Loss value:  0.5308471955358982\n",
      "Loss value:  0.48069323897361754\n",
      "Loss value:  0.4902190029621124\n",
      "Loss value:  0.4726294130086899\n",
      "Loss value:  0.436985482275486\n",
      "Loss value:  0.5004954129457474\n",
      "Loss value:  0.4798001378774643\n",
      "Loss value:  0.5212345898151398\n",
      "Loss value:  0.4959233865141869\n",
      "Loss value:  0.4698011979460716\n",
      "Loss value:  0.4674805343151093\n",
      "Loss value:  0.5521837547421455\n",
      "Loss value:  0.5006765186786651\n",
      "Loss value:  0.46938291043043134\n",
      "Loss value:  0.439159444719553\n",
      "Loss value:  0.5152356207370759\n",
      "Loss value:  0.46012852489948275\n",
      "Loss value:  0.4717355489730835\n",
      "Loss value:  0.46382186710834505\n",
      "Loss value:  0.5321975164115429\n",
      "Loss value:  0.49030011594295503\n",
      "Loss value:  0.5045778602361679\n",
      "Loss value:  0.4648520365357399\n",
      "Loss value:  0.46865344122052194\n",
      "Loss value:  0.4665972001850605\n",
      "Loss value:  0.4916412360966206\n",
      "Loss value:  0.507476082444191\n",
      "Loss value:  0.5163993701338768\n",
      "Loss value:  0.4854815132915974\n",
      "Loss value:  0.5253801062703133\n",
      "Loss value:  0.512854841351509\n",
      "Loss value:  0.4894789673388004\n",
      "Loss value:  0.49227751344442366\n",
      "Loss value:  0.4202057771384716\n",
      "Loss value:  0.39293461441993716\n",
      "Loss value:  0.4719121754169464\n",
      "Loss value:  0.48356608748435975\n",
      "Loss value:  0.5586239486932755\n",
      "Loss value:  0.4972749620676041\n",
      "Loss value:  0.5007962994277477\n",
      "Loss value:  0.4414214126765728\n",
      "Loss value:  0.48952570408582685\n",
      "Loss value:  0.43555365726351736\n",
      "Loss value:  0.49127164036035537\n",
      "Loss value:  0.5504116646945476\n",
      "Loss value:  0.5223472312092781\n",
      "Loss value:  0.5258175686001778\n",
      "Loss value:  0.5284589871764183\n",
      "Loss value:  0.5125061012804508\n",
      "Loss value:  0.49139301627874377\n",
      "Loss value:  0.47942403331398964\n",
      "Loss value:  0.4350923843681812\n",
      "Loss value:  0.48511041328310966\n",
      "Loss value:  0.5007871299982071\n",
      "Loss value:  0.46333502382040026\n",
      "Loss value:  0.4995060324668884\n",
      "Loss value:  0.4475101724267006\n",
      "Loss value:  0.5446756541728973\n",
      "Loss value:  0.4376241475343704\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-5bbc7d1a6c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_training_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 10\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 20\n",
    "\n",
    "# code for training loop:\n",
    "# https://github.com/xju2/root_gnn/blob/tf2/root_gnn/scripts/train_classifier\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    for _ in range(num_training_iterations):\n",
    "        input_tr, target_tr = next(training_data)\n",
    "        total_loss += update_step(input_tr, target_tr)[1].numpy()\n",
    "        num_batches += 1\n",
    "        \n",
    "    loss_tr = total_loss/num_batches\n",
    "    print(\"Loss value: \", loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.globals for x in model(inputs_ge, num_processing_steps_ge)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
