{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "molecular-lying",
   "metadata": {},
   "source": [
    "# Graph Networts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "received-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import uproot3 as ur\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()\n",
    "\n",
    "path_prefix = '/home/mfong/git/LCStudies/'\n",
    "plotpath = path_prefix + 'classifier/Plots/'\n",
    "modelpath = path_prefix + 'classifier/Models/'\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/atlas_mpl_style/__init__.py:163: UserWarning: No LaTeX installation found -- atlas-mpl-style is falling back to usetex=False\n",
      "  _warn.warn(\n"
     ]
    }
   ],
   "source": [
    "# import our resolution utilities\n",
    "\n",
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "sys.path\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa305ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "answering-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=24220)]) #in MB\n",
    "\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "specialized-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pi0 events: 263891\n",
      "Number of pi+ events: 435967\n",
      "Number of pi- events: 434627\n",
      "Total: 1134485\n"
     ]
    }
   ],
   "source": [
    "# import pi+- vs. pi0 images\n",
    "\n",
    "inputpath = '/clusterfs/ml4hep/mfong/ML4Pions/v7/'    # ml4hep1 machine\n",
    "# inputpath = \"/data0/mfong/v7/\"    # voltan machine\n",
    "#path = '/eos/user/m/mswiatlo/images/'\n",
    "branches = ['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi', 'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt', 'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE', 'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T', 'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY', 'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT', 'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min', 'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max', 'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max', 'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi', 'cluster_cell_centerCellLayer', 'cluster_cellE_norm']\n",
    "rootfiles = [\"pi0\", \"piplus\", \"piminus\"]\n",
    "trees = {\n",
    "    rfile : ur.open(inputpath+rfile+\".root\")['ClusterTree']\n",
    "    for rfile in rootfiles\n",
    "}\n",
    "pdata = {\n",
    "    ifile : itree.pandas.df(branches, flatten=False)\n",
    "    for ifile, itree in trees.items()\n",
    "}\n",
    "\n",
    "np0 = len(pdata['pi0'])\n",
    "npp = len(pdata['piplus'])\n",
    "npm = len(pdata['piminus'])\n",
    "\n",
    "print(\"Number of pi0 events: {}\".format(np0))\n",
    "print(\"Number of pi+ events: {}\".format(npp))\n",
    "print(\"Number of pi- events: {}\".format(npm))\n",
    "print(\"Total: {}\".format(np0+npp+npm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "known-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_shapes = {\n",
    "    'EMB1': (128,4),\n",
    "    'EMB2': (16,16),\n",
    "    'EMB3': (8,16),\n",
    "    'TileBar0': (4,4),\n",
    "    'TileBar1': (4,4),\n",
    "    'TileBar2': (2,4),\n",
    "}\n",
    "\n",
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer)\n",
    "        for layer in layers\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broken-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['runNumber', 'eventNumber', 'truthE', 'truthPt', 'truthEta', 'truthPhi',\n",
       "       'clusterIndex', 'nCluster', 'clusterE', 'clusterECalib', 'clusterPt',\n",
       "       'clusterEta', 'clusterPhi', 'cluster_nCells', 'cluster_sumCellE',\n",
       "       'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T',\n",
       "       'cluster_ENG_CALIB_DEAD_TOT', 'cluster_EM_PROBABILITY',\n",
       "       'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT', 'cluster_DM_WEIGHT',\n",
       "       'cluster_CENTER_MAG', 'cluster_FIRST_ENG_DENS', 'cluster_cell_dR_min',\n",
       "       'cluster_cell_dR_max', 'cluster_cell_dEta_min', 'cluster_cell_dEta_max',\n",
       "       'cluster_cell_dPhi_min', 'cluster_cell_dPhi_max',\n",
       "       'cluster_cell_centerCellEta', 'cluster_cell_centerCellPhi',\n",
       "       'cluster_cell_centerCellLayer', 'cluster_cellE_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata[\"pi0\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comprehensive-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263891, 512)\n",
      "(263891, 256)\n",
      "(263891, 128)\n",
      "(263891, 16)\n",
      "(263891, 16)\n",
      "(263891, 8)\n",
      "Total number of cells: 936\n"
     ]
    }
   ],
   "source": [
    "n_cells = 0\n",
    "for key in pcells[\"pi0\"]:\n",
    "    print(pcells[\"pi0\"][key].shape)\n",
    "    n_cells += pcells[\"pi0\"][key].shape[1]\n",
    "print(\"Total number of cells: \" + str(n_cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-blame",
   "metadata": {},
   "source": [
    "## Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-thompson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df for pi0 only\n",
    "df_p0 = pd.DataFrame(np.concatenate([pcells[\"pi0\"][key] for key in pcells[\"pi0\"].keys()], axis = 1))\n",
    "\n",
    "col_names = []\n",
    "for key in pcells[\"pi0\"].keys():\n",
    "    col_names.extend([key + \"_\" + str(i) for i in range(len(pcells[\"pi0\"][key][0]))])\n",
    "df_p0.columns = col_names\n",
    "\n",
    "df_p0[\"is_p0\"] = 1\n",
    "\n",
    "\n",
    "# print(df_p0.shape)\n",
    "# df_p0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rough-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for pipplus and piminus\n",
    "df_pp = pd.DataFrame(np.concatenate([pcells[\"piplus\"][key] for key in pcells[\"piplus\"].keys()], axis = 1))\n",
    "df_pp.columns = col_names\n",
    "df_pp[\"is_p0\"] = 0\n",
    "\n",
    "df_pm = pd.DataFrame(np.concatenate([pcells[\"piminus\"][key] for key in pcells[\"piminus\"].keys()], axis = 1))\n",
    "df_pm.columns = col_names\n",
    "df_pm[\"is_p0\"] = 0\n",
    "\n",
    "# print(df_pp.shape)\n",
    "# df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virgin-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB1_0</th>\n",
       "      <th>EMB1_1</th>\n",
       "      <th>EMB1_2</th>\n",
       "      <th>EMB1_3</th>\n",
       "      <th>EMB1_4</th>\n",
       "      <th>EMB1_5</th>\n",
       "      <th>EMB1_6</th>\n",
       "      <th>EMB1_7</th>\n",
       "      <th>EMB1_8</th>\n",
       "      <th>EMB1_9</th>\n",
       "      <th>EMB1_10</th>\n",
       "      <th>EMB1_11</th>\n",
       "      <th>EMB1_12</th>\n",
       "      <th>EMB1_13</th>\n",
       "      <th>EMB1_14</th>\n",
       "      <th>EMB1_15</th>\n",
       "      <th>EMB1_16</th>\n",
       "      <th>EMB1_17</th>\n",
       "      <th>EMB1_18</th>\n",
       "      <th>EMB1_19</th>\n",
       "      <th>EMB1_20</th>\n",
       "      <th>EMB1_21</th>\n",
       "      <th>EMB1_22</th>\n",
       "      <th>EMB1_23</th>\n",
       "      <th>EMB1_24</th>\n",
       "      <th>EMB1_25</th>\n",
       "      <th>EMB1_26</th>\n",
       "      <th>EMB1_27</th>\n",
       "      <th>EMB1_28</th>\n",
       "      <th>EMB1_29</th>\n",
       "      <th>EMB1_30</th>\n",
       "      <th>EMB1_31</th>\n",
       "      <th>EMB1_32</th>\n",
       "      <th>EMB1_33</th>\n",
       "      <th>EMB1_34</th>\n",
       "      <th>EMB1_35</th>\n",
       "      <th>EMB1_36</th>\n",
       "      <th>EMB1_37</th>\n",
       "      <th>EMB1_38</th>\n",
       "      <th>EMB1_39</th>\n",
       "      <th>EMB1_40</th>\n",
       "      <th>EMB1_41</th>\n",
       "      <th>EMB1_42</th>\n",
       "      <th>EMB1_43</th>\n",
       "      <th>EMB1_44</th>\n",
       "      <th>EMB1_45</th>\n",
       "      <th>EMB1_46</th>\n",
       "      <th>EMB1_47</th>\n",
       "      <th>EMB1_48</th>\n",
       "      <th>EMB1_49</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB3_119</th>\n",
       "      <th>EMB3_120</th>\n",
       "      <th>EMB3_121</th>\n",
       "      <th>EMB3_122</th>\n",
       "      <th>EMB3_123</th>\n",
       "      <th>EMB3_124</th>\n",
       "      <th>EMB3_125</th>\n",
       "      <th>EMB3_126</th>\n",
       "      <th>EMB3_127</th>\n",
       "      <th>TileBar0_0</th>\n",
       "      <th>TileBar0_1</th>\n",
       "      <th>TileBar0_2</th>\n",
       "      <th>TileBar0_3</th>\n",
       "      <th>TileBar0_4</th>\n",
       "      <th>TileBar0_5</th>\n",
       "      <th>TileBar0_6</th>\n",
       "      <th>TileBar0_7</th>\n",
       "      <th>TileBar0_8</th>\n",
       "      <th>TileBar0_9</th>\n",
       "      <th>TileBar0_10</th>\n",
       "      <th>TileBar0_11</th>\n",
       "      <th>TileBar0_12</th>\n",
       "      <th>TileBar0_13</th>\n",
       "      <th>TileBar0_14</th>\n",
       "      <th>TileBar0_15</th>\n",
       "      <th>TileBar1_0</th>\n",
       "      <th>TileBar1_1</th>\n",
       "      <th>TileBar1_2</th>\n",
       "      <th>TileBar1_3</th>\n",
       "      <th>TileBar1_4</th>\n",
       "      <th>TileBar1_5</th>\n",
       "      <th>TileBar1_6</th>\n",
       "      <th>TileBar1_7</th>\n",
       "      <th>TileBar1_8</th>\n",
       "      <th>TileBar1_9</th>\n",
       "      <th>TileBar1_10</th>\n",
       "      <th>TileBar1_11</th>\n",
       "      <th>TileBar1_12</th>\n",
       "      <th>TileBar1_13</th>\n",
       "      <th>TileBar1_14</th>\n",
       "      <th>TileBar1_15</th>\n",
       "      <th>TileBar2_0</th>\n",
       "      <th>TileBar2_1</th>\n",
       "      <th>TileBar2_2</th>\n",
       "      <th>TileBar2_3</th>\n",
       "      <th>TileBar2_4</th>\n",
       "      <th>TileBar2_5</th>\n",
       "      <th>TileBar2_6</th>\n",
       "      <th>TileBar2_7</th>\n",
       "      <th>is_p0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>0.140632</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087662</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 937 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMB1_0  EMB1_1  EMB1_2  EMB1_3  EMB1_4  EMB1_5  EMB1_6  EMB1_7  EMB1_8  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   EMB1_9  EMB1_10  EMB1_11  EMB1_12  EMB1_13  EMB1_14  EMB1_15  EMB1_16  \\\n",
       "0     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_17  EMB1_18  EMB1_19  EMB1_20  EMB1_21  EMB1_22  EMB1_23  EMB1_24  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_25  EMB1_26  EMB1_27  EMB1_28  EMB1_29  EMB1_30  EMB1_31  EMB1_32  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_33  EMB1_34  EMB1_35  EMB1_36  EMB1_37  EMB1_38  EMB1_39  EMB1_40  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_41  EMB1_42  EMB1_43  EMB1_44  EMB1_45  EMB1_46  EMB1_47  EMB1_48  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   EMB1_49  ...  EMB3_119  EMB3_120  EMB3_121  EMB3_122  EMB3_123  EMB3_124  \\\n",
       "0      0.0  ...  0.000009  0.000038  0.000009       0.0       0.0       0.0   \n",
       "1      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "2      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "3      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "4      0.0  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "\n",
       "   EMB3_125  EMB3_126  EMB3_127  TileBar0_0  TileBar0_1  TileBar0_2  \\\n",
       "0       0.0       0.0       0.0    0.000224    0.000315    0.001344   \n",
       "1       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "2       0.0       0.0       0.0    0.000000    0.011872    0.005269   \n",
       "3       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "4       0.0       0.0       0.0    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar0_3  TileBar0_4  TileBar0_5  TileBar0_6  TileBar0_7  TileBar0_8  \\\n",
       "0    0.000428    0.002322    0.012944    0.014262    0.002498    0.001551   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.000000    0.628931    0.088836    0.002091    0.000000   \n",
       "3    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar0_9  TileBar0_10  TileBar0_11  TileBar0_12  TileBar0_13  \\\n",
       "0    0.070766     0.140632     0.001669     0.003287     0.004747   \n",
       "1    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2    0.030488     0.019321     0.004342     0.000000     0.000000   \n",
       "3    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4    0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   TileBar0_14  TileBar0_15  TileBar1_0  TileBar1_1  TileBar1_2  TileBar1_3  \\\n",
       "0     0.008165     0.000888    0.000054    0.000776    0.001186    0.000146   \n",
       "1     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2     0.000177     0.001947    0.000000    0.019718    0.003629    0.000000   \n",
       "3     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4     0.000000     0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar1_4  TileBar1_5  TileBar1_6  TileBar1_7  TileBar1_8  TileBar1_9  \\\n",
       "0    0.000375    0.006990    0.007225    0.003866    0.001419    0.035971   \n",
       "1    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.087662    0.022248    0.000901    0.000000    0.006445   \n",
       "3    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar1_10  TileBar1_11  TileBar1_12  TileBar1_13  TileBar1_14  \\\n",
       "0     0.047344     0.003773     0.000361     0.006787     0.003358   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.000219     0.000237     0.000000     0.000000     0.000000   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "   TileBar1_15  TileBar2_0  TileBar2_1  TileBar2_2  TileBar2_3  TileBar2_4  \\\n",
       "0     0.002189         0.0    0.000625    0.000405    0.000031    0.000024   \n",
       "1     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "2     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "3     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "4     0.000000         0.0    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   TileBar2_5  TileBar2_6  TileBar2_7  is_p0  \n",
       "0    0.001023    0.001606         0.0      0  \n",
       "1    0.000000    0.000000         0.0      0  \n",
       "2    0.000000    0.000000         0.0      0  \n",
       "3    0.000000    0.000000         0.0      0  \n",
       "4    0.000000    0.000000         0.0      1  \n",
       "\n",
       "[5 rows x 937 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create final df\n",
    "df = df_p0.append(df_pp.append(df_pm))\n",
    "df = df.sample(frac=1) # Shuffle the df so pi0 are not all first\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-hanging",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facial-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutations for doubly connected edges\n",
    "from itertools import permutations\n",
    "import functools\n",
    "import networkx as nx\n",
    "import sonnet as snt\n",
    "\n",
    "from graph_nets import blocks\n",
    "\n",
    "from graph_nets import graphs\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "banned-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMB1_0        0.000000\n",
       "EMB1_1        0.000000\n",
       "EMB1_2        0.000000\n",
       "EMB1_3        0.000000\n",
       "EMB1_4        0.000000\n",
       "                ...   \n",
       "TileBar2_4    0.000024\n",
       "TileBar2_5    0.001023\n",
       "TileBar2_6    0.001606\n",
       "TileBar2_7    0.000000\n",
       "is_p0         0.000000\n",
       "Name: 0, Length: 937, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event0 = df.loc[0]\n",
    "event0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "appropriate-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fully_connected_edges(nodes):\n",
    "    \"\"\"\n",
    "    returns a list of tuples with (sender_node, reciever_node) for a fully connected graph\n",
    "    ex: [(1,2), (2,1), (0,1)]\n",
    "    \"\"\"\n",
    "    n_nodes = len(nodes)\n",
    "    return list(permutations(range(n_nodes), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ceramic-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(event):\n",
    "    \n",
    "    n_nodes = 0\n",
    "    nodes = []\n",
    "    MIN_VALUE = 0.05\n",
    "    solution = \"is_p0\"\n",
    "    \n",
    "    nodes = [[cell] for cell in event[col_names][event[col_names] > MIN_VALUE]]\n",
    "    n_nodes = len(nodes)\n",
    "    if n_nodes < 1:\n",
    "        return (None, None)\n",
    "    nodes = np.array(nodes, dtype=np.float32)\n",
    "    \n",
    "    edge_endpoints = make_fully_connected_edges(nodes)\n",
    "    senders = np.array([x[0] for x in edge_endpoints])\n",
    "    receivers = np.array([x[1] for x in edge_endpoints])\n",
    "    n_edges = len(edge_endpoints)\n",
    "    edges = np.expand_dims(np.array([0.0]*n_edges, dtype=np.float32), axis=1)\n",
    "\n",
    "    \n",
    "    input_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([n_nodes], dtype=np.float32)\n",
    "    }\n",
    "    target_datadict = {\n",
    "        \"n_node\": n_nodes,\n",
    "        \"n_edge\": n_edges,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"senders\": senders,\n",
    "        \"receivers\": receivers,\n",
    "        \"globals\": np.array([event[solution]], dtype=np.float32)\n",
    "    }\n",
    "    input_graph = utils_tf.data_dicts_to_graphs_tuple([input_datadict])\n",
    "    target_graph = utils_tf.data_dicts_to_graphs_tuple([target_datadict])\n",
    "    \n",
    "    return (input_graph, target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fatty-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graphs_tuple(g, data=True):\n",
    "    for field_name in graphs.ALL_FIELDS:\n",
    "        per_replica_sample = getattr(g, field_name)\n",
    "        if per_replica_sample is None:\n",
    "            print(field_name, \"EMPTY\")\n",
    "        else:\n",
    "            print(field_name, \"has shape\", per_replica_sample.shape)\n",
    "            if data and  field_name != \"edges\":\n",
    "                print(per_replica_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "characteristic-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes has shape (4, 1)\n",
      "edges has shape (12, 1)\n",
      "receivers has shape (12,)\n",
      "senders has shape (12,)\n",
      "globals has shape (1, 1)\n",
      "n_node has shape (1,)\n",
      "n_edge has shape (1,)\n"
     ]
    }
   ],
   "source": [
    "graphs_tuple0_input, graphs_tuple0_target = make_graph(event0)\n",
    "\n",
    "print_graphs_tuple(graphs_tuple0_input, data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "improving-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i in range(100):\n",
    "    graphs.append(make_graph(df.loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "macro-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([42], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([12], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([20], shape=(1,), dtype=int32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6], shape=(1,), dtype=int32)\n",
      "tf.Tensor([30], shape=(1,), dtype=int32)\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tf.Tensor([56], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# [x[0] for x in graphs][0].n_node\n",
    "\n",
    "for test_input, _ in graphs:\n",
    "    if test_input is not None:\n",
    "        print(test_input.n_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "structural-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting functions from example (broken)\n",
    "\n",
    "# def plot_graph_networkx(graph, ax, pos=None):\n",
    "#   node_labels = {node: \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for node, data in graph.nodes(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   edge_labels = {(sender, receiver): \"{:.3g}\".format(data[\"features\"][0])\n",
    "#                  for sender, receiver, data in graph.edges(data=True)\n",
    "#                  if data[\"features\"] is not None}\n",
    "#   global_label = (\"{:.3g}\".format(graph.graph[\"features\"][0])\n",
    "#                   if graph.graph[\"features\"] is not None else None)\n",
    "\n",
    "#   if pos is None:\n",
    "#     pos = nx.spring_layout(graph)\n",
    "#   nx.draw_networkx(graph, pos, ax=ax, labels=node_labels)\n",
    "\n",
    "#   if edge_labels:\n",
    "#     nx.draw_networkx_edge_labels(graph, pos, edge_labels, ax=ax)\n",
    "\n",
    "#   if global_label:\n",
    "#     plt.text(0.05, 0.95, global_label, transform=ax.transAxes)\n",
    "\n",
    "#   ax.yaxis.set_visible(False)\n",
    "#   ax.xaxis.set_visible(False)\n",
    "#   return pos\n",
    "\n",
    "# def plot_graphs_tuple(graphs_tuple):\n",
    "#   networkx_graphs = utils_np.graphs_tuple_to_networkxs(graphs_tuple)\n",
    "#   num_graphs = len(networkx_graphs)\n",
    "#   _, axes = plt.subplots(1, num_graphs, figsize=(5*num_graphs, 5))\n",
    "#   if num_graphs == 1:\n",
    "#     axes = axes,\n",
    "#   for graph, ax in zip(networkx_graphs, axes):\n",
    "#     plot_graph_networkx(graph, ax)\n",
    "\n",
    "# plot_graphs_tuple(graphs_tuple0_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-closer",
   "metadata": {},
   "source": [
    "## Graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apparent-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the newest dev version of graph_nets (see https://github.com/deepmind/graph_nets/issues/139)\n",
    "# as of 3/25/2021\n",
    "\n",
    "\n",
    "# !pip install git+git://github.com/deepmind/graph_nets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "local-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 2\n",
    "def make_mlp_model():\n",
    "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "  The parameters of each new MLP are not shared with others generated by\n",
    "  this function.\n",
    "\n",
    "  Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "  \"\"\"\n",
    "  # the activation function choices:\n",
    "  # swish, relu, relu6, leaky_relu\n",
    "  return snt.Sequential([\n",
    "      snt.nets.MLP([128, 64]*NUM_LAYERS,\n",
    "                    activation=tf.nn.relu,\n",
    "                    activate_final=True, \n",
    "                  #  dropout_rate=DROPOUT_RATE\n",
    "        ),\n",
    "      snt.LayerNorm(axis=-1, create_scale=True, create_offset=False)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "composed-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGraphNetwork(snt.Module):\n",
    "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
    "    def __init__(self, name=\"MLPGraphNetwork\"):\n",
    "        super(MLPGraphNetwork, self).__init__(name=name)\n",
    "        self._network = modules.GraphNetwork(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            node_model_fn=make_mlp_model,\n",
    "            global_model_fn=make_mlp_model\n",
    "            )\n",
    "\n",
    "    def __call__(self, inputs,\n",
    "            edge_model_kwargs=None,\n",
    "            node_model_kwargs=None,\n",
    "            global_model_kwargs=None):\n",
    "        return self._network(inputs,\n",
    "                      edge_model_kwargs=edge_model_kwargs,\n",
    "                      node_model_kwargs=node_model_kwargs,\n",
    "                      global_model_kwargs=global_model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "handed-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 128\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "class GlobalClassifierNoEdgeInfo(snt.Module):\n",
    "\n",
    "    def __init__(self, name=\"GlobalClassifierNoEdgeInfo\"):\n",
    "        super(GlobalClassifierNoEdgeInfo, self).__init__(name=name)\n",
    "\n",
    "        self._edge_block = blocks.EdgeBlock(\n",
    "            edge_model_fn=make_mlp_model,\n",
    "            use_edges=False,              # all edge features are 0.0 right now, use false for now\n",
    "            use_receiver_nodes=True,\n",
    "            use_sender_nodes=True,\n",
    "            use_globals=False,            # can try true later\n",
    "            name='edge_encoder_block')\n",
    "\n",
    "        self._node_encoder_block = blocks.NodeBlock(\n",
    "            node_model_fn=make_mlp_model,\n",
    "            use_received_edges=False,      # if assigning edge features set to true\n",
    "            use_sent_edges=False,          # if assigning edge features set to true\n",
    "            use_nodes=True,\n",
    "            use_globals=False,             # can try true later to see if any effect\n",
    "            name='node_encoder_block'\n",
    "        )\n",
    "\n",
    "        self._global_block = blocks.GlobalBlock(\n",
    "            global_model_fn=make_mlp_model,\n",
    "            use_edges=True,\n",
    "            use_nodes=True,\n",
    "            use_globals=True,\n",
    "        )\n",
    "\n",
    "        self._core = MLPGraphNetwork()\n",
    "        # Transforms the outputs into appropriate shapes.\n",
    "        global_output_size = 1\n",
    "        global_fn = lambda: snt.Sequential([\n",
    "            snt.nets.MLP([LATENT_SIZE, global_output_size], name='global_output'),       # TODO add more layers, end with size 1\n",
    "            tf.sigmoid\n",
    "        ])\n",
    "\n",
    "        self._output_transform = modules.GraphIndependent(None, None, global_fn)\n",
    "\n",
    "    def __call__(self, input_op, num_processing_steps):\n",
    "        latent = self._global_block(self._edge_block(self._node_encoder_block(input_op)))\n",
    "        latent0 = latent\n",
    "\n",
    "        output_ops = []\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
    "            latent = self._core(core_input)\n",
    "            output_ops.append(self._output_transform(latent))\n",
    "\n",
    "        return output_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "removed-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlobalClassifierNoEdgeInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "compact-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graphs = model(graphs_tuple0_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cosmetic-valuable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5559923]], dtype=float32)>]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.globals for x in output_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "solved-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "\n",
    "class GlobalLoss:\n",
    "    def __init__(self, real_global_weight, fake_global_weight):\n",
    "        self.w_global_real = real_global_weight\n",
    "        self.w_global_fake = fake_global_weight\n",
    "\n",
    "    def __call__(self, target_op, output_ops):\n",
    "        global_weights = target_op.globals * self.w_global_real \\\n",
    "            + (1 - target_op.globals) * self.w_global_fake\n",
    "        \n",
    "        print(global_weights)\n",
    "        \n",
    "        loss_ops = [\n",
    "            tf.compat.v1.losses.log_loss(target_op.globals, output_op.globals, weights=global_weights)\n",
    "            for output_op in output_ops\n",
    "        ]\n",
    "        return tf.stack(loss_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "mexican-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_global = GlobalLoss(real_global_weight = 1.0, fake_global_weight = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "offshore-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.8119132], dtype=float32)>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function_global(graphs_tuple0_target, output_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "missing-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "target_list = []\n",
    "counter = 0\n",
    "index = 0\n",
    "# while counter < 100:\n",
    "#     input_graph, target_graph = train_graphs[index]\n",
    "#     if input_graph is None:\n",
    "#         index += 1\n",
    "#         continue\n",
    "#     target_list.append(target_graph)\n",
    "#     input_list.append(input_graph)\n",
    "#     counter += 1\n",
    "\n",
    "# concated_inputs = utils_tf.concat(input_list, axis=0)\n",
    "# concated_targets = utils_tf.concat(target_graph, axis=0)\n",
    "\n",
    "\n",
    "for data in train_graphs[:1000]:\n",
    "    input_tr, target_tr = data\n",
    "    if input_tr is None:\n",
    "            continue\n",
    "    input_list.append(input_tr)\n",
    "    target_list.append(target_tr)\n",
    "    if len(input_list) >= batch_size:\n",
    "        input_tr = utils_tf.concat(input_list, axis=0)\n",
    "        target_tr = utils_tf.concat(target_list, axis=0)\n",
    "        x = model(input_tr, 1)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "alpha-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_tf.concat(target_list, axis=0).globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fantastic-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'globals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-c6e8293585b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_function_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-183-bf16516d93cf>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, target_op, output_ops)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         loss_ops = [\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moutput_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-183-bf16516d93cf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         loss_ops = [\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moutput_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         ]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'globals'"
     ]
    }
   ],
   "source": [
    "loss_function_global(model(input_tr, 1)[-1], utils_tf.concat(target_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "burning-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.48329577],\n",
       "       [3.3163548 ],\n",
       "       [0.751511  ],\n",
       "       [4.6038504 ]], dtype=float32)>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_tf.get_graph(input_tr, index = 0).nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "pending-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=float32, numpy=\n",
       "array([[0.39807805],\n",
       "       [0.81405723],\n",
       "       [1.6258401 ],\n",
       "       [4.9596205 ],\n",
       "       [1.8701465 ],\n",
       "       [0.7057205 ]], dtype=float32)>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_tf.get_graph(input_tr, index = 1).nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "educational-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.33847168]], dtype=float32)>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(utils_tf.get_graph(input_tr, index = 0), 4)[-1].globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "spoken-glossary",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1, 1) and (2, 1) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-824cd5525331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(labels, predictions, weights, epsilon, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     losses = -math_ops.multiply(\n\u001b[1;32m    490\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \"\"\"\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1, 1) and (2, 1) are incompatible"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.losses.log_loss(utils_tf.concat(target_list, axis=0).globals, model(input_tr, 1)[-1].globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "opened-google",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.26044545],\n",
       "       [0.24761927]], dtype=float32)>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tr, 1)[-1].globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "extra-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.26017097],\n",
       "       [0.2465775 ]], dtype=float32)>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tr, 2)[-1].globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "official-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.26044542],\n",
       "       [0.24761927]], dtype=float32)>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_tr, 4)[0].globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-cherry",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "noted-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify acc function\n",
    "\n",
    "# def compute_accuracy(target, output):\n",
    "#     \"\"\"Calculate model accuracy.\n",
    "\n",
    "#     Returns the number of correctly predicted links and the number\n",
    "#     of completely solved list sorts (100% correct predictions).\n",
    "\n",
    "#     Args:\n",
    "#     target: A `graphs.GraphsTuple` that contains the target graph.\n",
    "#     output: A `graphs.GraphsTuple` that contains the output graph.\n",
    "\n",
    "#     Returns:\n",
    "#     correct: A `float` fraction of correctly labeled nodes/edges.\n",
    "#     solved: A `float` fraction of graphs that are completely correctly labeled.\n",
    "#     \"\"\"\n",
    "#     tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "#     odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "#     cs = []\n",
    "#     ss = []\n",
    "#     for td, od in zip(tdds, odds):\n",
    "#         num_elements = td[\"nodes\"].shape[0]\n",
    "#         xn = np.argmax(td[\"nodes\"], axis=-1)\n",
    "#         yn = np.argmax(od[\"nodes\"], axis=-1)\n",
    "\n",
    "#         xe = np.reshape(\n",
    "#             np.argmax(\n",
    "#                 np.reshape(td[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "#             (-1,))\n",
    "#         ye = np.reshape(\n",
    "#             np.argmax(\n",
    "#                 np.reshape(od[\"edges\"], (num_elements, num_elements, 2)), axis=-1),\n",
    "#             (-1,))\n",
    "#         c = np.concatenate((xn == yn, xe == ye), axis=0)\n",
    "#         s = np.all(c)\n",
    "#         cs.append(c)\n",
    "#         ss.append(s)\n",
    "#     correct = np.mean(np.concatenate(cs, axis=0))\n",
    "#     solved = np.mean(np.stack(ss))\n",
    "#     return correct, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cloudy-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(dataset, batch_size):\n",
    "    \"\"\"\n",
    "    Get signature of inputs for the training loop.\n",
    "    The signature is used by the tf.function\n",
    "    \"\"\"\n",
    "\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    for _, data in dataset.iterrows():\n",
    "        dd = make_graph(data)\n",
    "        if dd[0] is not None:\n",
    "            input_list.append(dd[0])\n",
    "            target_list.append(dd[1])\n",
    "            \n",
    "        if len(input_list) == batch_size:\n",
    "            break\n",
    "\n",
    "    inputs = utils_tf.concat(input_list, axis=0)\n",
    "    targets = utils_tf.concat(target_list, axis=0)\n",
    "    input_signature = (\n",
    "      utils_tf.specs_from_graphs_tuple(inputs),\n",
    "      utils_tf.specs_from_graphs_tuple(targets)\n",
    "    )\n",
    "    \n",
    "    return input_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "several-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "input_signature = get_signature(df, batch_size)\n",
    "\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 2\n",
    "num_processing_steps_ge = 2\n",
    "\n",
    "\n",
    "learning_rate = 5e-4\n",
    "optimizer = snt.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "# model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "last_iteration = 0\n",
    "generalization_iteration = 0\n",
    "\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []\n",
    "\n",
    "\n",
    "@functools.partial(tf.function, input_signature=input_signature)\n",
    "def update_step(inputs_tr, targets_tr):\n",
    "    print(\"Tracing update_step\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs_tr = model(inputs_tr, num_processing_steps_tr)\n",
    "        loss_ops_tr = loss_function_global(targets_tr, outputs_tr)\n",
    "        loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)\n",
    "\n",
    "    gradients = tape.gradient(loss_op_tr, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "    return outputs_tr, loss_op_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stupid-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and generalization df\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "square-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values to gaussian\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fit scaler to train set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train.drop(\"is_p0\", axis=1))\n",
    "\n",
    "# scale the train set\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df_train.drop(\"is_p0\", axis=1)))\n",
    "df_train_scaled[\"is_p0\"] = df_train[\"is_p0\"].values\n",
    "df_train_scaled.columns = df_train.columns\n",
    "\n",
    "# scale the test set\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test.drop(\"is_p0\", axis=1)))\n",
    "df_test_scaled[\"is_p0\"] = df_test[\"is_p0\"].values\n",
    "df_test_scaled.columns = df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "figured-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 40s, sys: 14.6 s, total: 5min 55s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO this is very slow (1.5 hours for full 1100000 row dataset)\n",
    "# 5 min for 50000 rows\n",
    "# make graphs for each event\n",
    "train_graphs = [make_graph(event) for _, event in df_train_scaled[:50000].iterrows()]\n",
    "test_graphs = [make_graph(event) for _, event in df_test_scaled[:5000].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save train_graphs and test_graphs objects to file, it takes too long to make\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, \"wb\") as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(train_graphs, \"Temp/train_graphs_scaled.pkl\")\n",
    "save_object(train_graphs, \"Temp/test_graphs_scaled.pkl\")\n",
    "\n",
    "\"\"\"\n",
    "Load the graph dataset from pickle object files\n",
    "\"\"\"\n",
    "# file = open(\"Temp/train_graphs.pkl\",'rb')\n",
    "# train_graphs = pickle.load(file)\n",
    "# file.close()\n",
    "\n",
    "# file = open(\"Temp/test_graphs.pkl\",'rb')\n",
    "# test_graphs = pickle.load(file)\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "instant-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_dataset(datasets, batch_size):\n",
    "    if batch_size > 0:\n",
    "        in_list = []\n",
    "        target_list = []\n",
    "        for dataset in datasets:\n",
    "            inputs_tr, targets_tr = dataset\n",
    "            if inputs_tr is None:\n",
    "                continue\n",
    "            in_list.append(inputs_tr)\n",
    "            target_list.append(targets_tr)\n",
    "            if len(in_list) == batch_size:\n",
    "                inputs_tr = utils_tf.concat(in_list, axis=0)\n",
    "                targets_tr = utils_tf.concat(target_list, axis=0)\n",
    "                yield (inputs_tr, targets_tr)\n",
    "                in_list = []\n",
    "                target_list = []\n",
    "    else:\n",
    "        for dataset in datasets:\n",
    "            if dataset is None:\n",
    "                continue\n",
    "            yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "coordinated-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator that yields a graph of the batch_size concatenated graphs\n",
    "training_data = loop_dataset(train_graphs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "strategic-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tr, target_tr = next(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dated-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907588"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "damaged-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4610453248023987\n",
      "Loss: 0.46114158630371094\n",
      "Loss: 0.4609955847263336\n",
      "Loss: 0.46059614419937134\n",
      "Loss: 0.4599519670009613\n",
      "Loss: 0.45918089151382446\n",
      "Loss: 0.4583708941936493\n",
      "Loss: 0.4576148986816406\n",
      "Loss: 0.45698490738868713\n",
      "Loss: 0.45671215653419495\n",
      "Loss: 0.4567072093486786\n",
      "Loss: 0.45671185851097107\n",
      "Loss: 0.4566919505596161\n",
      "Loss: 0.4566284120082855\n",
      "Loss: 0.45650988817214966\n",
      "Loss: 0.45633697509765625\n",
      "Loss: 0.4561152458190918\n",
      "Loss: 0.4558555781841278\n",
      "Loss: 0.455574095249176\n",
      "Loss: 0.4552818238735199\n",
      "Loss: 0.45498958230018616\n",
      "Loss: 0.45475897192955017\n",
      "Loss: 0.45455238223075867\n",
      "Loss: 0.45436397194862366\n",
      "Loss: 0.45421481132507324\n",
      "Loss: 0.45408591628074646\n",
      "Loss: 0.45397621393203735\n",
      "Loss: 0.45388126373291016\n",
      "Loss: 0.45382919907569885\n",
      "Loss: 0.4537911117076874\n",
      "Loss: 0.4537179172039032\n",
      "Loss: 0.45358729362487793\n",
      "Loss: 0.45342347025871277\n",
      "Loss: 0.4533112049102783\n",
      "Loss: 0.4532068371772766\n",
      "Loss: 0.4531041085720062\n",
      "Loss: 0.45301198959350586\n",
      "Loss: 0.45291003584861755\n",
      "Loss: 0.4528124928474426\n",
      "Loss: 0.45271894335746765\n",
      "Loss: 0.4526293873786926\n",
      "Loss: 0.45255133509635925\n",
      "Loss: 0.45248839259147644\n",
      "Loss: 0.45242634415626526\n",
      "Loss: 0.4523608386516571\n",
      "Loss: 0.4522974193096161\n",
      "Loss: 0.4522411525249481\n",
      "Loss: 0.452169269323349\n",
      "Loss: 0.45209869742393494\n",
      "Loss: 0.45203256607055664\n",
      "Loss: 0.45197102427482605\n",
      "Loss: 0.45190855860710144\n",
      "Loss: 0.4518461227416992\n",
      "Loss: 0.4517941474914551\n",
      "Loss: 0.45174726843833923\n",
      "Loss: 0.45170798897743225\n",
      "Loss: 0.4516640603542328\n",
      "Loss: 0.45161229372024536\n",
      "Loss: 0.45157313346862793\n",
      "Loss: 0.45153409242630005\n",
      "Loss: 0.4514945149421692\n",
      "Loss: 0.4514525532722473\n",
      "Loss: 0.451416939496994\n",
      "Loss: 0.45137983560562134\n",
      "Loss: 0.45134636759757996\n",
      "Loss: 0.4513120651245117\n",
      "Loss: 0.4512798488140106\n",
      "Loss: 0.45125246047973633\n",
      "Loss: 0.4512215554714203\n",
      "Loss: 0.4511856138706207\n",
      "Loss: 0.45115190744400024\n",
      "Loss: 0.4511263072490692\n",
      "Loss: 0.45109835267066956\n",
      "Loss: 0.45107150077819824\n",
      "Loss: 0.4510463774204254\n",
      "Loss: 0.45101800560951233\n",
      "Loss: 0.45098814368247986\n",
      "Loss: 0.450965017080307\n",
      "Loss: 0.4509299397468567\n",
      "Loss: 0.4509093463420868\n",
      "Loss: 0.4508797824382782\n",
      "Loss: 0.450851172208786\n",
      "Loss: 0.45081692934036255\n",
      "Loss: 0.45078951120376587\n",
      "Loss: 0.4507468342781067\n",
      "Loss: 0.45070719718933105\n",
      "Loss: 0.4506552219390869\n",
      "Loss: 0.4505864083766937\n",
      "Loss: 0.4504864811897278\n",
      "Loss: 0.450423926115036\n",
      "Loss: 0.4504179060459137\n",
      "Loss: 0.4502590298652649\n",
      "Loss: 0.4502054750919342\n",
      "Loss: 0.45019206404685974\n",
      "Loss: 0.4501475393772125\n",
      "Loss: 0.4500628113746643\n",
      "Loss: 0.45004016160964966\n",
      "Loss: 0.45009586215019226\n",
      "Loss: 0.45011910796165466\n",
      "Loss: 0.45010051131248474\n",
      "Loss: 0.4500119686126709\n",
      "Loss: 0.44991984963417053\n",
      "Loss: 0.44987136125564575\n",
      "Loss: 0.4498938024044037\n",
      "Loss: 0.4498666822910309\n",
      "Loss: 0.4498121738433838\n",
      "Loss: 0.4497489035129547\n",
      "Loss: 0.44970592856407166\n",
      "Loss: 0.4496884047985077\n",
      "Loss: 0.44968166947364807\n",
      "Loss: 0.4496472477912903\n",
      "Loss: 0.4495096802711487\n",
      "Loss: 0.44964519143104553\n",
      "Loss: 0.44953233003616333\n",
      "Loss: 0.4495117664337158\n",
      "Loss: 0.4496486783027649\n",
      "Loss: 0.44955530762672424\n",
      "Loss: 0.4495149552822113\n",
      "Loss: 0.44951310753822327\n",
      "Loss: 0.4494757354259491\n",
      "Loss: 0.44940948486328125\n",
      "Loss: 0.4494658410549164\n",
      "Loss: 0.44945716857910156\n",
      "Loss: 0.44939857721328735\n",
      "Loss: 0.44930917024612427\n",
      "Loss: 0.44931650161743164\n",
      "Loss: 0.44926711916923523\n",
      "Loss: 0.44926711916923523\n",
      "Loss: 0.44923868775367737\n",
      "Loss: 0.4491632580757141\n",
      "Loss: 0.44913506507873535\n",
      "Loss: 0.4490969181060791\n",
      "Loss: 0.4490525722503662\n",
      "Loss: 0.44903650879859924\n",
      "Loss: 0.44901275634765625\n",
      "Loss: 0.44899311661720276\n",
      "Loss: 0.4489297866821289\n",
      "Loss: 0.4489705562591553\n",
      "Loss: 0.44890156388282776\n",
      "Loss: 0.44886094331741333\n",
      "Loss: 0.4488525986671448\n",
      "Loss: 0.44878265261650085\n",
      "Loss: 0.4486857056617737\n",
      "Loss: 0.4487663209438324\n",
      "Loss: 0.4486598074436188\n",
      "Loss: 0.44858500361442566\n",
      "Loss: 0.4485962986946106\n",
      "Loss: 0.4485590159893036\n",
      "Loss: 0.4484945833683014\n",
      "Loss: 0.4484138488769531\n",
      "Loss: 0.4483306407928467\n",
      "Loss: 0.4482637941837311\n",
      "Loss: 0.44814538955688477\n",
      "Loss: 0.448085218667984\n",
      "Loss: 0.44805121421813965\n",
      "Loss: 0.4479597508907318\n",
      "Loss: 0.4478304982185364\n",
      "Loss: 0.4477613568305969\n",
      "Loss: 0.44770047068595886\n",
      "Loss: 0.4476061463356018\n",
      "Loss: 0.4474835991859436\n",
      "Loss: 0.44732895493507385\n",
      "Loss: 0.4471377432346344\n",
      "Loss: 0.44692903757095337\n",
      "Loss: 0.4467228949069977\n",
      "Loss: 0.446484237909317\n",
      "Loss: 0.4464775025844574\n",
      "Loss: 0.44634199142456055\n",
      "Loss: 0.4459974467754364\n",
      "Loss: 0.44620952010154724\n",
      "Loss: 0.4457162022590637\n",
      "Loss: 0.44583994150161743\n",
      "Loss: 0.44501373171806335\n",
      "Loss: 0.4449525773525238\n",
      "Loss: 0.44451257586479187\n",
      "Loss: 0.4446885585784912\n",
      "Loss: 0.4444875419139862\n",
      "Loss: 0.4440441131591797\n",
      "Loss: 0.44351324439048767\n",
      "Loss: 0.44379639625549316\n",
      "Loss: 0.4438090920448303\n",
      "Loss: 0.4484662115573883\n",
      "Loss: 0.4421338737010956\n",
      "Loss: 0.44856759905815125\n",
      "Loss: 0.4492188096046448\n",
      "Loss: 0.44940873980522156\n",
      "Loss: 0.4487379491329193\n",
      "Loss: 0.44917699694633484\n",
      "Loss: 0.44810962677001953\n",
      "Loss: 0.44792452454566956\n",
      "Loss: 0.44751834869384766\n",
      "Loss: 0.44743308424949646\n",
      "Loss: 0.44769617915153503\n",
      "Loss: 0.44718050956726074\n",
      "Loss: 0.4471644461154938\n",
      "Loss: 0.447314590215683\n",
      "Loss: 0.44716721773147583\n",
      "Loss: 0.4471034109592438\n",
      "Loss: 0.44675111770629883\n",
      "Loss: 0.4470195770263672\n",
      "Loss: 0.4467040002346039\n",
      "Loss: 0.4465753138065338\n",
      "Loss: 0.4464382231235504\n",
      "Loss: 0.4464380443096161\n",
      "Loss: 0.4461231827735901\n",
      "Loss: 0.4460485875606537\n",
      "Loss: 0.44590267539024353\n",
      "Loss: 0.44562968611717224\n",
      "Loss: 0.44554463028907776\n",
      "Loss: 0.4452613890171051\n",
      "Loss: 0.44499656558036804\n",
      "Loss: 0.44422054290771484\n",
      "Loss: 0.4402695596218109\n",
      "Loss: 0.43973374366760254\n",
      "Loss: 0.4409582316875458\n",
      "Loss: 0.4393117427825928\n",
      "Loss: 0.4436560273170471\n",
      "Loss: 0.44398805499076843\n",
      "Loss: 0.438425749540329\n",
      "Loss: 0.4372793734073639\n",
      "Loss: 0.44227296113967896\n",
      "Loss: 0.4385836720466614\n",
      "Loss: 0.4387916624546051\n",
      "Loss: 0.43860021233558655\n",
      "Loss: 0.4373248219490051\n",
      "Loss: 0.43885526061058044\n",
      "Loss: 0.4364650845527649\n",
      "Loss: 0.43713709712028503\n",
      "Loss: 0.4363020062446594\n",
      "Loss: 0.4359603524208069\n",
      "Loss: 0.4361768662929535\n",
      "Loss: 0.43494659662246704\n",
      "Loss: 0.4341756999492645\n",
      "Loss: 0.4339771270751953\n",
      "Loss: 0.43352943658828735\n",
      "Loss: 0.4331377446651459\n",
      "Loss: 0.4321947693824768\n",
      "Loss: 0.43197008967399597\n",
      "Loss: 0.43537431955337524\n",
      "Loss: 0.4364319443702698\n",
      "Loss: 0.43212372064590454\n",
      "Loss: 0.44733235239982605\n",
      "Loss: 0.44820472598075867\n",
      "Loss: 0.4310756325721741\n",
      "Loss: 0.43875908851623535\n",
      "Loss: 0.4350687563419342\n",
      "Loss: 0.43567290902137756\n",
      "Loss: 0.43034791946411133\n",
      "Loss: 0.43491998314857483\n",
      "Loss: 0.42911291122436523\n",
      "Loss: 0.4402712285518646\n",
      "Loss: 0.4353671669960022\n",
      "Loss: 0.4410669803619385\n",
      "Loss: 0.4368824064731598\n",
      "Loss: 0.4420609176158905\n",
      "Loss: 0.449400395154953\n",
      "Loss: 0.44490453600883484\n",
      "Loss: 0.4370032846927643\n",
      "Loss: 0.4339442253112793\n",
      "Loss: 0.4350441098213196\n",
      "Loss: 0.43348726630210876\n",
      "Loss: 0.4305368959903717\n",
      "Loss: 0.43785127997398376\n",
      "Loss: 0.4335269629955292\n",
      "Loss: 0.4430198669433594\n",
      "Loss: 0.44391632080078125\n",
      "Loss: 0.4453616142272949\n",
      "Loss: 0.4377053678035736\n",
      "Loss: 0.4298318028450012\n",
      "Loss: 0.43231964111328125\n",
      "Loss: 0.43752557039260864\n",
      "Loss: 0.4370107650756836\n",
      "Loss: 0.4386472702026367\n",
      "Loss: 0.43636780977249146\n",
      "Loss: 0.43804046511650085\n",
      "Loss: 0.44210195541381836\n",
      "Loss: 0.43404385447502136\n",
      "Loss: 0.4418693482875824\n",
      "Loss: 0.445244699716568\n",
      "Loss: 0.4464204013347626\n",
      "Loss: 0.4375741481781006\n",
      "Loss: 0.42704343795776367\n",
      "Loss: 0.44539976119995117\n",
      "Loss: 0.44560548663139343\n",
      "Loss: 0.4298696517944336\n",
      "Loss: 0.43788883090019226\n",
      "Loss: 0.443364679813385\n",
      "Loss: 0.4463302791118622\n",
      "Loss: 0.44544562697410583\n",
      "Loss: 0.44355425238609314\n",
      "Loss: 0.4414709210395813\n",
      "Loss: 0.4400944709777832\n",
      "Loss: 0.44092264771461487\n",
      "Loss: 0.4421946108341217\n",
      "Loss: 0.4416056275367737\n",
      "Loss: 0.4399746358394623\n",
      "Loss: 0.43902501463890076\n",
      "Loss: 0.4380694031715393\n",
      "Loss: 0.4382766783237457\n",
      "Loss: 0.43913817405700684\n",
      "Loss: 0.43885374069213867\n",
      "Loss: 0.43778467178344727\n",
      "Loss: 0.43795910477638245\n",
      "Loss: 0.43827077746391296\n",
      "Loss: 0.43784481287002563\n",
      "Loss: 0.43784841895103455\n",
      "Loss: 0.4376589357852936\n",
      "Loss: 0.43674325942993164\n",
      "Loss: 0.43599367141723633\n",
      "Loss: 0.4349084496498108\n",
      "Loss: 0.4329220950603485\n",
      "Loss: 0.43585777282714844\n",
      "Loss: 0.42912527918815613\n",
      "Loss: 0.4363071620464325\n",
      "Loss: 0.43918201327323914\n",
      "Loss: 0.43889355659484863\n",
      "Loss: 0.43524765968322754\n",
      "Loss: 0.4295079708099365\n",
      "Loss: 0.44220200181007385\n",
      "Loss: 0.4459288716316223\n",
      "Loss: 0.4289376437664032\n",
      "Loss: 0.43579980731010437\n",
      "Loss: 0.44190025329589844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.44544848799705505\n",
      "Loss: 0.44403859972953796\n",
      "Loss: 0.44055911898612976\n",
      "Loss: 0.43759337067604065\n",
      "Loss: 0.43737897276878357\n",
      "Loss: 0.4388492703437805\n",
      "Loss: 0.43996405601501465\n",
      "Loss: 0.439524382352829\n",
      "Loss: 0.4380801320075989\n",
      "Loss: 0.4365186393260956\n",
      "Loss: 0.4357764720916748\n",
      "Loss: 0.4368588626384735\n",
      "Loss: 0.43747687339782715\n",
      "Loss: 0.4372813403606415\n",
      "Loss: 0.43568140268325806\n",
      "Loss: 0.4355982840061188\n",
      "Loss: 0.4357256591320038\n",
      "Loss: 0.4361606538295746\n",
      "Loss: 0.43610525131225586\n",
      "Loss: 0.43529319763183594\n",
      "Loss: 0.43468141555786133\n",
      "Loss: 0.4342148005962372\n",
      "Loss: 0.43448305130004883\n",
      "Loss: 0.43468475341796875\n",
      "Loss: 0.4344322681427002\n",
      "Loss: 0.43388763070106506\n",
      "Loss: 0.433403879404068\n",
      "Loss: 0.43238577246665955\n",
      "Loss: 0.4315546154975891\n",
      "Loss: 0.4293740391731262\n",
      "Loss: 0.43262630701065063\n",
      "Loss: 0.4293522834777832\n",
      "Loss: 0.42892083525657654\n",
      "Loss: 0.42872077226638794\n",
      "Loss: 0.4277072548866272\n",
      "Loss: 0.42766162753105164\n",
      "Loss: 0.4314729869365692\n",
      "Loss: 0.42631635069847107\n",
      "Loss: 0.42728081345558167\n",
      "Loss: 0.42549243569374084\n",
      "Loss: 0.4267789423465729\n",
      "Loss: 0.4257884919643402\n",
      "Loss: 0.43041181564331055\n",
      "Loss: 0.4276869297027588\n",
      "Loss: 0.42739757895469666\n",
      "Loss: 0.42830991744995117\n",
      "Loss: 0.4256816506385803\n",
      "Loss: 0.42559710144996643\n",
      "Loss: 0.4283258616924286\n",
      "Loss: 0.42629262804985046\n",
      "Loss: 0.4261181056499481\n",
      "Loss: 0.42693111300468445\n",
      "Loss: 0.4263177812099457\n",
      "Loss: 0.425445556640625\n",
      "Loss: 0.4280245304107666\n",
      "Loss: 0.426312655210495\n",
      "Loss: 0.4265553951263428\n",
      "Loss: 0.4259676933288574\n",
      "Loss: 0.425880491733551\n",
      "Loss: 0.42533499002456665\n",
      "Loss: 0.42626506090164185\n",
      "Loss: 0.4266148507595062\n",
      "Loss: 0.42576834559440613\n",
      "Loss: 0.42687129974365234\n",
      "Loss: 0.42560282349586487\n",
      "Loss: 0.4256073534488678\n",
      "Loss: 0.4254051148891449\n",
      "Loss: 0.42586347460746765\n",
      "Loss: 0.4252331852912903\n",
      "Loss: 0.42583855986595154\n",
      "Loss: 0.425821989774704\n",
      "Loss: 0.425229549407959\n",
      "Loss: 0.42581912875175476\n",
      "Loss: 0.42577624320983887\n",
      "Loss: 0.425386905670166\n",
      "Loss: 0.425447940826416\n",
      "Loss: 0.4253826141357422\n",
      "Loss: 0.4250344932079315\n",
      "Loss: 0.4248908460140228\n",
      "Loss: 0.4257994592189789\n",
      "Loss: 0.42500218749046326\n",
      "Loss: 0.4255494177341461\n",
      "Loss: 0.42544203996658325\n",
      "Loss: 0.42517563700675964\n",
      "Loss: 0.424500048160553\n",
      "Loss: 0.4255715012550354\n",
      "Loss: 0.4248717725276947\n",
      "Loss: 0.4247754216194153\n",
      "Loss: 0.4256543219089508\n",
      "Loss: 0.4250221252441406\n",
      "Loss: 0.4244687557220459\n",
      "Loss: 0.4256173074245453\n",
      "Loss: 0.4249531924724579\n",
      "Loss: 0.4243530333042145\n",
      "Loss: 0.4254825711250305\n",
      "Loss: 0.42493611574172974\n",
      "Loss: 0.42381033301353455\n",
      "Loss: 0.4255281984806061\n",
      "Loss: 0.42472514510154724\n",
      "Loss: 0.4238980710506439\n",
      "Loss: 0.42557117342948914\n",
      "Loss: 0.42480728030204773\n",
      "Loss: 0.4236709177494049\n",
      "Loss: 0.4254055917263031\n",
      "Loss: 0.4247381389141083\n",
      "Loss: 0.4232315123081207\n",
      "Loss: 0.4254336357116699\n",
      "Loss: 0.4246235489845276\n",
      "Loss: 0.4230530858039856\n",
      "Loss: 0.42539340257644653\n",
      "Loss: 0.42457881569862366\n",
      "Loss: 0.4227341115474701\n",
      "Loss: 0.42405304312705994\n",
      "Loss: 0.42440661787986755\n",
      "Loss: 0.4220729470252991\n",
      "Loss: 0.4338075816631317\n",
      "Loss: 0.4291023910045624\n",
      "Loss: 0.4279349446296692\n",
      "Loss: 0.4305996596813202\n",
      "Loss: 0.4227808117866516\n",
      "Loss: 0.4272685647010803\n",
      "Loss: 0.4219498634338379\n",
      "Loss: 0.43525075912475586\n",
      "Loss: 0.4251653254032135\n",
      "Loss: 0.43117672204971313\n",
      "Loss: 0.43107327818870544\n",
      "Loss: 0.43122830986976624\n",
      "Loss: 0.4305899739265442\n",
      "Loss: 0.42975932359695435\n",
      "Loss: 0.4352130889892578\n",
      "Loss: 0.4237689673900604\n",
      "Loss: 0.4333224296569824\n",
      "Loss: 0.437009334564209\n",
      "Loss: 0.44146308302879333\n",
      "Loss: 0.4405995309352875\n",
      "Loss: 0.43806192278862\n",
      "Loss: 0.437983900308609\n",
      "Loss: 0.43578240275382996\n",
      "Loss: 0.4368324279785156\n",
      "Loss: 0.43743377923965454\n",
      "Loss: 0.4370301365852356\n",
      "Loss: 0.437296599149704\n",
      "Loss: 0.43598148226737976\n",
      "Loss: 0.435284286737442\n",
      "Loss: 0.4350306987762451\n",
      "Loss: 0.43516770005226135\n",
      "Loss: 0.43496137857437134\n",
      "Loss: 0.43530845642089844\n",
      "Loss: 0.43514424562454224\n",
      "Loss: 0.434518426656723\n",
      "Loss: 0.4344049394130707\n",
      "Loss: 0.43361401557922363\n",
      "Loss: 0.4337310492992401\n",
      "Loss: 0.4336404800415039\n",
      "Loss: 0.43363887071609497\n",
      "Loss: 0.4336114525794983\n",
      "Loss: 0.43230924010276794\n",
      "Loss: 0.4315529763698578\n",
      "Loss: 0.4306733310222626\n",
      "Loss: 0.42934274673461914\n",
      "Loss: 0.4273117184638977\n",
      "Loss: 0.42867952585220337\n",
      "Loss: 0.4318626821041107\n",
      "Loss: 0.4336049258708954\n",
      "Loss: 0.4366453289985657\n",
      "Loss: 0.4354856014251709\n",
      "Loss: 0.43348851799964905\n",
      "Loss: 0.43237096071243286\n",
      "Loss: 0.43132758140563965\n",
      "Loss: 0.43102917075157166\n",
      "Loss: 0.43162956833839417\n",
      "Loss: 0.42946338653564453\n",
      "Loss: 0.4516158103942871\n",
      "Loss: 0.4338587820529938\n",
      "Loss: 0.4352879524230957\n",
      "Loss: 0.4429588317871094\n",
      "Loss: 0.4471568763256073\n",
      "Loss: 0.442864328622818\n",
      "Loss: 0.4390571713447571\n",
      "Loss: 0.43647947907447815\n",
      "Loss: 0.4337298572063446\n",
      "Loss: 0.4373631179332733\n",
      "Loss: 0.4389253258705139\n",
      "Loss: 0.4395983815193176\n",
      "Loss: 0.43875154852867126\n",
      "Loss: 0.4379103183746338\n",
      "Loss: 0.4358128607273102\n",
      "Loss: 0.4343477189540863\n",
      "Loss: 0.4346953332424164\n",
      "Loss: 0.43556639552116394\n",
      "Loss: 0.4364507794380188\n",
      "Loss: 0.43644386529922485\n",
      "Loss: 0.435549259185791\n",
      "Loss: 0.43418699502944946\n",
      "Loss: 0.43370911478996277\n",
      "Loss: 0.433826208114624\n",
      "Loss: 0.4345432221889496\n",
      "Loss: 0.4345208704471588\n",
      "Loss: 0.43373605608940125\n",
      "Loss: 0.4332504868507385\n",
      "Loss: 0.4330717623233795\n",
      "Loss: 0.4331028461456299\n",
      "Loss: 0.43314462900161743\n",
      "Loss: 0.43316397070884705\n",
      "Loss: 0.43297138810157776\n",
      "Loss: 0.4326709806919098\n",
      "Loss: 0.43239933252334595\n",
      "Loss: 0.4323025643825531\n",
      "Loss: 0.4323073923587799\n",
      "Loss: 0.4323280453681946\n",
      "Loss: 0.4321020245552063\n",
      "Loss: 0.43178173899650574\n",
      "Loss: 0.4310261905193329\n",
      "Loss: 0.4307684600353241\n",
      "Loss: 0.43074414134025574\n",
      "Loss: 0.43000683188438416\n",
      "Loss: 0.42995044589042664\n",
      "Loss: 0.4285927414894104\n",
      "Loss: 0.4271090626716614\n",
      "Loss: 0.43241262435913086\n",
      "Loss: 0.43141552805900574\n",
      "Loss: 0.4347773492336273\n",
      "Loss: 0.44073811173439026\n",
      "Loss: 0.4417073726654053\n",
      "Loss: 0.4393623471260071\n",
      "Loss: 0.4365668296813965\n",
      "Loss: 0.4355201721191406\n",
      "Loss: 0.4340244233608246\n",
      "Loss: 0.4346235692501068\n",
      "Loss: 0.43443164229393005\n",
      "Loss: 0.4338940680027008\n",
      "Loss: 0.43344685435295105\n",
      "Loss: 0.4334418475627899\n",
      "Loss: 0.43302980065345764\n",
      "Loss: 0.43366503715515137\n",
      "Loss: 0.43382006883621216\n",
      "Loss: 0.4336977005004883\n",
      "Loss: 0.4337519705295563\n",
      "Loss: 0.4334051311016083\n",
      "Loss: 0.4329589903354645\n",
      "Loss: 0.4326169490814209\n",
      "Loss: 0.4323279857635498\n",
      "Loss: 0.43195438385009766\n",
      "Loss: 0.43193578720092773\n",
      "Loss: 0.4318476617336273\n",
      "Loss: 0.4318080544471741\n",
      "Loss: 0.4317696988582611\n",
      "Loss: 0.4317595660686493\n",
      "Loss: 0.4316409230232239\n",
      "Loss: 0.43170902132987976\n",
      "Loss: 0.431744247674942\n",
      "Loss: 0.4316904544830322\n",
      "Loss: 0.4316217601299286\n",
      "Loss: 0.4315631091594696\n",
      "Loss: 0.43144065141677856\n",
      "Loss: 0.4311642646789551\n",
      "Loss: 0.43057987093925476\n",
      "Loss: 0.4304954707622528\n",
      "Loss: 0.43034037947654724\n",
      "Loss: 0.4300966262817383\n",
      "Loss: 0.430119127035141\n",
      "Loss: 0.4299619197845459\n",
      "Loss: 0.42978373169898987\n",
      "Loss: 0.4295136034488678\n",
      "Loss: 0.4270051419734955\n",
      "Loss: 0.4307214319705963\n",
      "Loss: 0.4316493570804596\n",
      "Loss: 0.43557658791542053\n",
      "Loss: 0.43933987617492676\n",
      "Loss: 0.4395773410797119\n",
      "Loss: 0.43807268142700195\n",
      "Loss: 0.4340638220310211\n",
      "Loss: 0.43366703391075134\n",
      "Loss: 0.4343373775482178\n",
      "Loss: 0.4346866309642792\n",
      "Loss: 0.4352608323097229\n",
      "Loss: 0.4344661831855774\n",
      "Loss: 0.4332399368286133\n",
      "Loss: 0.43245455622673035\n",
      "Loss: 0.4322468936443329\n",
      "Loss: 0.4323202669620514\n",
      "Loss: 0.4328480362892151\n",
      "Loss: 0.4331822395324707\n",
      "Loss: 0.4329175055027008\n",
      "Loss: 0.43239814043045044\n",
      "Loss: 0.43217936158180237\n",
      "Loss: 0.43197932839393616\n",
      "Loss: 0.43199214339256287\n",
      "Loss: 0.4321351945400238\n",
      "Loss: 0.4322715401649475\n",
      "Loss: 0.4321077764034271\n",
      "Loss: 0.4318905770778656\n",
      "Loss: 0.4316905438899994\n",
      "Loss: 0.4315250813961029\n",
      "Loss: 0.43140172958374023\n",
      "Loss: 0.4314349293708801\n",
      "Loss: 0.4314913749694824\n",
      "Loss: 0.43147459626197815\n",
      "Loss: 0.43141433596611023\n",
      "Loss: 0.43133702874183655\n",
      "Loss: 0.43122759461402893\n",
      "Loss: 0.4311716556549072\n",
      "Loss: 0.43119335174560547\n",
      "Loss: 0.4312211573123932\n",
      "Loss: 0.43123307824134827\n",
      "Loss: 0.43123432993888855\n",
      "Loss: 0.4311809539794922\n",
      "Loss: 0.4311281144618988\n",
      "Loss: 0.43110328912734985\n",
      "Loss: 0.43109211325645447\n",
      "Loss: 0.4310935139656067\n",
      "Loss: 0.43110400438308716\n",
      "Loss: 0.43108177185058594\n",
      "Loss: 0.4310533106327057\n",
      "Loss: 0.4310227930545807\n",
      "Loss: 0.43099555373191833\n",
      "Loss: 0.43098244071006775\n",
      "Loss: 0.43098345398902893\n",
      "Loss: 0.4309755265712738\n",
      "Loss: 0.43096333742141724\n",
      "Loss: 0.4309441149234772\n",
      "Loss: 0.4309212863445282\n",
      "Loss: 0.4309022128582001\n",
      "Loss: 0.43089398741722107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4308857023715973\n",
      "Loss: 0.43087682127952576\n",
      "Loss: 0.43086716532707214\n",
      "Loss: 0.4308602511882782\n",
      "Loss: 0.4308500289916992\n",
      "Loss: 0.4308426082134247\n",
      "Loss: 0.43083611130714417\n",
      "Loss: 0.43082910776138306\n",
      "Loss: 0.43082156777381897\n",
      "Loss: 0.43081504106521606\n",
      "Loss: 0.4308067858219147\n",
      "Loss: 0.4307992160320282\n",
      "Loss: 0.4307912290096283\n",
      "Loss: 0.4307463765144348\n",
      "Loss: 0.43044567108154297\n",
      "Loss: 0.4302522838115692\n",
      "Loss: 0.4302145540714264\n",
      "Loss: 0.43021222949028015\n",
      "Loss: 0.4301634728908539\n",
      "Loss: 0.4300857484340668\n",
      "Loss: 0.4299876391887665\n",
      "Loss: 0.42953696846961975\n",
      "Loss: 0.4292953908443451\n",
      "Loss: 0.4292401373386383\n",
      "Loss: 0.4292328357696533\n",
      "Loss: 0.4291853606700897\n",
      "Loss: 0.42911654710769653\n",
      "Loss: 0.4288499057292938\n",
      "Loss: 0.4262668788433075\n",
      "Loss: 0.43281012773513794\n",
      "Loss: 0.43223172426223755\n",
      "Loss: 0.435034841299057\n",
      "Loss: 0.4402187764644623\n",
      "Loss: 0.44090184569358826\n",
      "Loss: 0.43937644362449646\n",
      "Loss: 0.4348908066749573\n",
      "Loss: 0.43414339423179626\n",
      "Loss: 0.43311840295791626\n",
      "Loss: 0.43350887298583984\n",
      "Loss: 0.4354492127895355\n",
      "Loss: 0.4352082908153534\n",
      "Loss: 0.43509531021118164\n",
      "Loss: 0.4340085983276367\n",
      "Loss: 0.43377548456192017\n",
      "Loss: 0.4331434369087219\n",
      "Loss: 0.4335181415081024\n",
      "Loss: 0.43364962935447693\n",
      "Loss: 0.4332147240638733\n",
      "Loss: 0.4332675039768219\n",
      "Loss: 0.43281587958335876\n",
      "Loss: 0.43268510699272156\n",
      "Loss: 0.43221697211265564\n",
      "Loss: 0.43213769793510437\n",
      "Loss: 0.4322132170200348\n",
      "Loss: 0.4321298599243164\n",
      "Loss: 0.4323123097419739\n",
      "Loss: 0.43213969469070435\n",
      "Loss: 0.4319295883178711\n",
      "Loss: 0.43159720301628113\n",
      "Loss: 0.4314112365245819\n",
      "Loss: 0.4314699172973633\n",
      "Loss: 0.43130573630332947\n",
      "Loss: 0.4313342571258545\n",
      "Loss: 0.43125078082084656\n",
      "Loss: 0.4311632215976715\n",
      "Loss: 0.4310474395751953\n",
      "Loss: 0.43092823028564453\n",
      "Loss: 0.4308912456035614\n",
      "Loss: 0.43030738830566406\n",
      "Loss: 0.4303707778453827\n",
      "Loss: 0.43039342761039734\n",
      "Loss: 0.4303850829601288\n",
      "Loss: 0.42993101477622986\n",
      "Loss: 0.4295313060283661\n",
      "Loss: 0.4293517768383026\n",
      "Loss: 0.4292432963848114\n",
      "Loss: 0.4292139708995819\n",
      "Loss: 0.4291907250881195\n",
      "Loss: 0.4292363226413727\n",
      "Loss: 0.42917394638061523\n",
      "Loss: 0.42920494079589844\n",
      "Loss: 0.4290061593055725\n",
      "Loss: 0.42681318521499634\n",
      "Loss: 0.4489103853702545\n",
      "Loss: 0.4334718883037567\n",
      "Loss: 0.4390893578529358\n",
      "Loss: 0.444016695022583\n",
      "Loss: 0.44465571641921997\n",
      "Loss: 0.44391727447509766\n",
      "Loss: 0.4389088749885559\n",
      "Loss: 0.4353877604007721\n",
      "Loss: 0.43693748116493225\n",
      "Loss: 0.43523940443992615\n",
      "Loss: 0.43682727217674255\n",
      "Loss: 0.4381117820739746\n",
      "Loss: 0.43622827529907227\n",
      "Loss: 0.43609681725502014\n",
      "Loss: 0.4346526265144348\n",
      "Loss: 0.43448325991630554\n",
      "Loss: 0.43448376655578613\n",
      "Loss: 0.43452006578445435\n",
      "Loss: 0.4357818067073822\n",
      "Loss: 0.4353233277797699\n",
      "Loss: 0.4347855746746063\n",
      "Loss: 0.433960497379303\n",
      "Loss: 0.4333251416683197\n",
      "Loss: 0.43317294120788574\n",
      "Loss: 0.4330931305885315\n",
      "Loss: 0.4332641065120697\n",
      "Loss: 0.43326225876808167\n",
      "Loss: 0.4329527020454407\n",
      "Loss: 0.4328523278236389\n",
      "Loss: 0.43258604407310486\n",
      "Loss: 0.43243226408958435\n",
      "Loss: 0.43244943022727966\n",
      "Loss: 0.43244919180870056\n",
      "Loss: 0.4324363172054291\n",
      "Loss: 0.4323189854621887\n",
      "Loss: 0.43224191665649414\n",
      "Loss: 0.43212124705314636\n",
      "Loss: 0.4318758547306061\n",
      "Loss: 0.4317193627357483\n",
      "Loss: 0.43158942461013794\n",
      "Loss: 0.4315025508403778\n",
      "Loss: 0.43144121766090393\n",
      "Loss: 0.4313977360725403\n",
      "Loss: 0.43135061860084534\n",
      "Loss: 0.4312179684638977\n",
      "Loss: 0.43112045526504517\n",
      "Loss: 0.4310511648654938\n",
      "Loss: 0.43099212646484375\n",
      "Loss: 0.4309506416320801\n",
      "Loss: 0.43097057938575745\n",
      "Loss: 0.4309554100036621\n",
      "Loss: 0.4308817386627197\n",
      "Loss: 0.43084651231765747\n",
      "Loss: 0.4308205246925354\n",
      "Loss: 0.43078622221946716\n",
      "Loss: 0.43075570464134216\n",
      "Loss: 0.43078580498695374\n",
      "Loss: 0.43079814314842224\n",
      "Loss: 0.43076545000076294\n",
      "Loss: 0.43071627616882324\n",
      "Loss: 0.43070903420448303\n",
      "Loss: 0.4306812286376953\n",
      "Loss: 0.4306267201900482\n",
      "Loss: 0.43052369356155396\n",
      "Loss: 0.43062010407447815\n",
      "Loss: 0.4307004511356354\n",
      "Loss: 0.43067073822021484\n",
      "Loss: 0.43050262331962585\n",
      "Loss: 0.43048912286758423\n",
      "Loss: 0.4305875897407532\n",
      "Loss: 0.4306057393550873\n",
      "Loss: 0.43054085969924927\n",
      "Loss: 0.43038806319236755\n",
      "Loss: 0.4304695129394531\n",
      "Loss: 0.4304969310760498\n",
      "Loss: 0.4304828345775604\n",
      "Loss: 0.4302888512611389\n",
      "Loss: 0.4304523169994354\n",
      "Loss: 0.43042635917663574\n",
      "Loss: 0.4305478036403656\n",
      "Loss: 0.4303950369358063\n",
      "Loss: 0.43041905760765076\n",
      "Loss: 0.4302697777748108\n",
      "Loss: 0.4304482936859131\n",
      "Loss: 0.43031126260757446\n",
      "Loss: 0.4304339587688446\n",
      "Loss: 0.43021494150161743\n",
      "Loss: 0.43045663833618164\n",
      "Loss: 0.43037205934524536\n",
      "Loss: 0.430474191904068\n",
      "Loss: 0.43034178018569946\n",
      "Loss: 0.43029385805130005\n",
      "Loss: 0.4302116334438324\n",
      "Loss: 0.43027740716934204\n",
      "Loss: 0.4302414059638977\n",
      "Loss: 0.43016862869262695\n",
      "Loss: 0.4301302134990692\n",
      "Loss: 0.4301491677761078\n",
      "Loss: 0.430094450712204\n",
      "Loss: 0.4302181303501129\n",
      "Loss: 0.430103600025177\n",
      "Loss: 0.4300737977027893\n",
      "Loss: 0.4301608204841614\n",
      "Loss: 0.43018147349357605\n",
      "Loss: 0.43014732003211975\n",
      "Loss: 0.43008795380592346\n",
      "Loss: 0.43010756373405457\n",
      "Loss: 0.4301447868347168\n",
      "Loss: 0.43010401725769043\n",
      "Loss: 0.4302941858768463\n",
      "Loss: 0.4300456941127777\n",
      "Loss: 0.4300622045993805\n",
      "Loss: 0.42996320128440857\n",
      "Loss: 0.43020230531692505\n",
      "Loss: 0.430029958486557\n",
      "Loss: 0.4301985800266266\n",
      "Loss: 0.42994388937950134\n",
      "Loss: 0.43004241585731506\n",
      "Loss: 0.4299636483192444\n",
      "Loss: 0.4299681782722473\n",
      "Loss: 0.43000054359436035\n",
      "Loss: 0.4299662113189697\n",
      "Loss: 0.4299148619174957\n",
      "Loss: 0.42965051531791687\n",
      "Loss: 0.4298055171966553\n",
      "Loss: 0.4296848475933075\n",
      "Loss: 0.4296826422214508\n",
      "Loss: 0.42960405349731445\n",
      "Loss: 0.4295685887336731\n",
      "Loss: 0.4295840263366699\n",
      "Loss: 0.42939844727516174\n",
      "Loss: 0.4295573830604553\n",
      "Loss: 0.42925140261650085\n",
      "Loss: 0.42938539385795593\n",
      "Loss: 0.42921921610832214\n",
      "Loss: 0.42940232157707214\n",
      "Loss: 0.42915159463882446\n",
      "Loss: 0.42957860231399536\n",
      "Loss: 0.4291245937347412\n",
      "Loss: 0.4295904338359833\n",
      "Loss: 0.42913857102394104\n",
      "Loss: 0.4291628897190094\n",
      "Loss: 0.42866334319114685\n",
      "Loss: 0.429369181394577\n",
      "Loss: 0.42870283126831055\n",
      "Loss: 0.42892247438430786\n",
      "Loss: 0.4284941852092743\n",
      "Loss: 0.4286598265171051\n",
      "Loss: 0.4283563196659088\n",
      "Loss: 0.4284837245941162\n",
      "Loss: 0.4283985197544098\n",
      "Loss: 0.4283529818058014\n",
      "Loss: 0.42823049426078796\n",
      "Loss: 0.42801758646965027\n",
      "Loss: 0.42792877554893494\n",
      "Loss: 0.4279828667640686\n",
      "Loss: 0.42796269059181213\n",
      "Loss: 0.42782852053642273\n",
      "Loss: 0.42788171768188477\n",
      "Loss: 0.4279286563396454\n",
      "Loss: 0.42796969413757324\n",
      "Loss: 0.4277960956096649\n",
      "Loss: 0.42769813537597656\n",
      "Loss: 0.4278857707977295\n",
      "Loss: 0.4278021454811096\n",
      "Loss: 0.4277799725532532\n",
      "Loss: 0.4277559816837311\n",
      "Loss: 0.42752858996391296\n",
      "Loss: 0.4275282025337219\n",
      "Loss: 0.4275638163089752\n",
      "Loss: 0.42725619673728943\n",
      "Loss: 0.4255227744579315\n",
      "Loss: 0.4420461356639862\n",
      "Loss: 0.4326595366001129\n",
      "Loss: 0.4355832040309906\n",
      "Loss: 0.44002652168273926\n",
      "Loss: 0.44232073426246643\n",
      "Loss: 0.43926188349723816\n",
      "Loss: 0.43855246901512146\n",
      "Loss: 0.43405023217201233\n",
      "Loss: 0.4354911744594574\n",
      "Loss: 0.4356409013271332\n",
      "Loss: 0.4347756505012512\n",
      "Loss: 0.43692395091056824\n",
      "Loss: 0.43630725145339966\n",
      "Loss: 0.43380483984947205\n",
      "Loss: 0.4341321885585785\n",
      "Loss: 0.43346744775772095\n",
      "Loss: 0.43245741724967957\n",
      "Loss: 0.43346014618873596\n",
      "Loss: 0.43380412459373474\n",
      "Loss: 0.4331945478916168\n",
      "Loss: 0.43325814604759216\n",
      "Loss: 0.4320478141307831\n",
      "Loss: 0.43268346786499023\n",
      "Loss: 0.4317176938056946\n",
      "Loss: 0.4317290484905243\n",
      "Loss: 0.43188339471817017\n",
      "Loss: 0.4313068389892578\n",
      "Loss: 0.43145376443862915\n",
      "Loss: 0.43106624484062195\n",
      "Loss: 0.4310672879219055\n",
      "Loss: 0.43045854568481445\n",
      "Loss: 0.430548757314682\n",
      "Loss: 0.43006953597068787\n",
      "Loss: 0.430124968290329\n",
      "Loss: 0.43017226457595825\n",
      "Loss: 0.4300598204135895\n",
      "Loss: 0.4299549162387848\n",
      "Loss: 0.4295661151409149\n",
      "Loss: 0.42952805757522583\n",
      "Loss: 0.4295984208583832\n",
      "Loss: 0.4295181930065155\n",
      "Loss: 0.4292125403881073\n",
      "Loss: 0.42905402183532715\n",
      "Loss: 0.42903247475624084\n",
      "Loss: 0.429103821516037\n",
      "Loss: 0.4290767312049866\n",
      "Loss: 0.4287983477115631\n",
      "Loss: 0.4291086196899414\n",
      "Loss: 0.42878714203834534\n",
      "Loss: 0.4292992651462555\n",
      "Loss: 0.42904138565063477\n",
      "Loss: 0.42906761169433594\n",
      "Loss: 0.4291260242462158\n",
      "Loss: 0.4286493957042694\n",
      "Loss: 0.4287247657775879\n",
      "Loss: 0.4287126660346985\n",
      "Loss: 0.4287246763706207\n",
      "Loss: 0.4284277856349945\n",
      "Loss: 0.42830386757850647\n",
      "Loss: 0.4282810688018799\n",
      "Loss: 0.42852869629859924\n",
      "Loss: 0.42824050784111023\n",
      "Loss: 0.4281788766384125\n",
      "Loss: 0.4276794493198395\n",
      "Loss: 0.4278431832790375\n",
      "Loss: 0.42758890986442566\n",
      "Loss: 0.4277295768260956\n",
      "Loss: 0.4275369644165039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4279020428657532\n",
      "Loss: 0.4272925555706024\n",
      "Loss: 0.42729830741882324\n",
      "Loss: 0.4272356927394867\n",
      "Loss: 0.42707759141921997\n",
      "Loss: 0.42702850699424744\n",
      "Loss: 0.42700520157814026\n",
      "Loss: 0.4270939528942108\n",
      "Loss: 0.42723575234413147\n",
      "Loss: 0.4271114766597748\n",
      "Loss: 0.427308052778244\n",
      "Loss: 0.42694613337516785\n",
      "Loss: 0.42721039056777954\n",
      "Loss: 0.4271722435951233\n",
      "Loss: 0.4271012842655182\n",
      "Loss: 0.42742329835891724\n",
      "Loss: 0.4273340702056885\n",
      "Loss: 0.42786332964897156\n",
      "Loss: 0.42699310183525085\n",
      "Loss: 0.4273781478404999\n",
      "Loss: 0.4274516999721527\n",
      "Loss: 0.42731761932373047\n",
      "Loss: 0.42686089873313904\n",
      "Loss: 0.4427924156188965\n",
      "Loss: 0.4347112774848938\n",
      "Loss: 0.4398256838321686\n",
      "Loss: 0.44024354219436646\n",
      "Loss: 0.4473641812801361\n",
      "Loss: 0.4431036114692688\n",
      "Loss: 0.43939897418022156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fef08610b70>]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# repeatedly learning on same set of training data to make sure loss goes down\n",
    "# temp_loss = []\n",
    "\n",
    "for x in range(1000):\n",
    "    temp_curr_loss = update_step(input_tr, target_tr)[1].numpy()\n",
    "    print(f\"Loss: {temp_curr_loss}\")\n",
    "    temp_loss.append(temp_curr_loss)\n",
    "plt.plot(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "facial-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/mfong/anaconda3/envs/graph/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing update_step\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n",
      "Epoch: 0\tLoss value: 0.49605690229602617\n",
      "Epoch: 1\tLoss value: 0.469543155003777\n"
     ]
    }
   ],
   "source": [
    "# Data / training parameters.\n",
    "num_training_iterations = 20\n",
    "\n",
    "\n",
    "# for epoch in range(1000):\n",
    "#     total_loss = 0.\n",
    "#     num_batches = 0\n",
    "    \n",
    "#     for _ in range(num_training_iterations):\n",
    "#         input_tr, target_tr = next(training_data)\n",
    "#         total_loss += update_step(input_tr, target_tr)[1].numpy()\n",
    "#         num_batches += 1\n",
    "        \n",
    "#     loss_tr = total_loss / num_batches\n",
    "#     losses_tr.append(loss_tr)\n",
    "#     print(f\"Epoch: {epoch}\\tLoss value: {loss_tr}\")\n",
    "\n",
    "current_loss_list = []\n",
    "for epoch in range(2):\n",
    "    total_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for data in train_graphs[:10000]:\n",
    "        input_tr, target_tr = data\n",
    "        if input_tr is None:\n",
    "                continue\n",
    "        input_list.append(input_tr)\n",
    "        target_list.append(target_tr)\n",
    "        if len(input_list) >= batch_size:\n",
    "            input_tr = utils_tf.concat(input_list, axis=0)\n",
    "            target_tr = utils_tf.concat(target_list, axis=0)\n",
    "            \n",
    "            current_loss = update_step(input_tr, target_tr)[1].numpy()\n",
    "            total_loss += current_loss\n",
    "            \n",
    "            if num_batches % 10 == 0:\n",
    "                current_loss_list.append(current_loss)\n",
    "            \n",
    "            num_batches += 1\n",
    "            input_list = []\n",
    "            target_list = []\n",
    "            \n",
    "            # TODO add a checkpoint > save to disk\n",
    "    \n",
    "    loss_tr = total_loss / num_batches\n",
    "    losses_tr.append(loss_tr)\n",
    "    print(f\"Epoch: {epoch}\\tLoss value: {loss_tr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fuzzy-montgomery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb84b0cf8e0>]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 799.992x599.976 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(current_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fifth-imagination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6730337,\n",
       " 0.7149936,\n",
       " 0.5890162,\n",
       " 0.54679006,\n",
       " 0.58873975,\n",
       " 0.5885728,\n",
       " 0.5884215,\n",
       " 0.67305243,\n",
       " 0.63059044,\n",
       " 0.6305102,\n",
       " 0.5451983,\n",
       " 0.5449486,\n",
       " 0.5447013,\n",
       " 0.5444737,\n",
       " 0.5442756,\n",
       " 0.6730839,\n",
       " 0.5869217,\n",
       " 0.6299274,\n",
       " 0.67309844,\n",
       " 0.673104,\n",
       " 0.58632314,\n",
       " 0.67311335,\n",
       " 0.62958753,\n",
       " 0.67312133,\n",
       " 0.6294978,\n",
       " 0.5857421,\n",
       " 0.54178,\n",
       " 0.67314464,\n",
       " 0.6292023,\n",
       " 0.541086,\n",
       " 0.5408517,\n",
       " 0.54058236,\n",
       " 0.5846182,\n",
       " 0.62881887,\n",
       " 0.53988093,\n",
       " 0.6286879,\n",
       " 0.5394466,\n",
       " 0.49453974,\n",
       " 0.58367634,\n",
       " 0.58350027,\n",
       " 0.53846425,\n",
       " 0.6282753,\n",
       " 0.62824035,\n",
       " 0.53804016,\n",
       " 0.62812287,\n",
       " 0.6280557,\n",
       " 0.5374398,\n",
       " 0.5372395,\n",
       " 0.5370267,\n",
       " 0.5822889,\n",
       " 0.5821369,\n",
       " 0.5820322,\n",
       " 0.6276287,\n",
       " 0.62756103,\n",
       " 0.7191961,\n",
       " 0.67335516,\n",
       " 0.5355054,\n",
       " 0.5813291,\n",
       " 0.71946126,\n",
       " 0.48882872,\n",
       " 0.62718385,\n",
       " 0.5808379,\n",
       " 0.58070517,\n",
       " 0.5805603,\n",
       " 0.6269304,\n",
       " 0.62687194,\n",
       " 0.58020365,\n",
       " 0.72013485,\n",
       " 0.58002704,\n",
       " 0.67347527,\n",
       " 0.6266401,\n",
       " 0.57965595,\n",
       " 0.5794926,\n",
       " 0.5793506,\n",
       " 0.53208977,\n",
       " 0.67354333,\n",
       " 0.48442024,\n",
       " 0.53149307,\n",
       " 0.673577,\n",
       " 0.5311543,\n",
       " 0.5785109,\n",
       " 0.62599576,\n",
       " 0.6259381,\n",
       " 0.7213738,\n",
       " 0.6258321,\n",
       " 0.5299789,\n",
       " 0.48179,\n",
       " 0.52951294,\n",
       " 0.67369324,\n",
       " 0.5292563,\n",
       " 0.5290654,\n",
       " 0.6254316,\n",
       " 0.6737418,\n",
       " 0.5768945,\n",
       " 0.62528247,\n",
       " 0.52818245,\n",
       " 0.5280007,\n",
       " 0.6251327,\n",
       " 0.67380685,\n",
       " 0.7225715,\n",
       " 0.57621765,\n",
       " 0.52721924,\n",
       " 0.575976,\n",
       " 0.5758271,\n",
       " 0.57569367,\n",
       " 0.6738987,\n",
       " 0.6246727,\n",
       " 0.6246081,\n",
       " 0.52577174,\n",
       " 0.5255424,\n",
       " 0.52531564,\n",
       " 0.5251083,\n",
       " 0.52493083,\n",
       " 0.67402345,\n",
       " 0.57436967,\n",
       " 0.62414247,\n",
       " 0.674074,\n",
       " 0.6740924,\n",
       " 0.5738412,\n",
       " 0.6741224,\n",
       " 0.62387305,\n",
       " 0.6741461,\n",
       " 0.6238059,\n",
       " 0.5733432,\n",
       " 0.52268094,\n",
       " 0.6742152,\n",
       " 0.62356967,\n",
       " 0.52204764,\n",
       " 0.5218336,\n",
       " 0.5215844,\n",
       " 0.572343,\n",
       " 0.6232621,\n",
       " 0.52094316,\n",
       " 0.6231588,\n",
       " 0.5205492,\n",
       " 0.46897382,\n",
       " 0.5715061,\n",
       " 0.571348,\n",
       " 0.51964664,\n",
       " 0.6228315,\n",
       " 0.6228066,\n",
       " 0.51928383,\n",
       " 0.6227151,\n",
       " 0.622662,\n",
       " 0.51874393,\n",
       " 0.5185636,\n",
       " 0.5183709,\n",
       " 0.57030165,\n",
       " 0.57016695,\n",
       " 0.57007825,\n",
       " 0.622328,\n",
       " 0.6222746,\n",
       " 0.7271856,\n",
       " 0.6747216,\n",
       " 0.5170105,\n",
       " 0.5694731,\n",
       " 0.72746646,\n",
       " 0.4637834,\n",
       " 0.6219843,\n",
       " 0.56904763,\n",
       " 0.5689315,\n",
       " 0.56880385,\n",
       " 0.62178546,\n",
       " 0.62174,\n",
       " 0.568496,\n",
       " 0.72818935,\n",
       " 0.56835043,\n",
       " 0.6749606,\n",
       " 0.62156546,\n",
       " 0.5680286,\n",
       " 0.5678827,\n",
       " 0.5677576,\n",
       " 0.51395565,\n",
       " 0.6750912,\n",
       " 0.45977587,\n",
       " 0.5134188,\n",
       " 0.6751536,\n",
       " 0.5131199,\n",
       " 0.5670318,\n",
       " 0.6210649,\n",
       " 0.6210203,\n",
       " 0.7295169,\n",
       " 0.6209389,\n",
       " 0.51206386,\n",
       " 0.45737976,\n",
       " 0.5116372,\n",
       " 0.6753615,\n",
       " 0.5114207,\n",
       " 0.5112497,\n",
       " 0.62062883,\n",
       " 0.67544556,\n",
       " 0.5656276,\n",
       " 0.6205154,\n",
       " 0.510466,\n",
       " 0.510304,\n",
       " 0.62040144]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_loss_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
